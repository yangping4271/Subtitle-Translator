"""
é…ç½®ç®¡ç†æ¨¡å— - é…ç½®éªŒè¯å’Œåˆå§‹åŒ–
"""
import os
from pathlib import Path

import typer
from rich import print

from .env_setup import setup_environment, get_app_config_dir, get_global_env_path
from .translation_core.utils.test_openai import test_openai


def validate_existing_config_and_return_result(env_path: Path = None):
    """éªŒè¯ç°æœ‰é…ç½®ä¸­çš„æ‰€æœ‰æ¨¡å‹ï¼Œè¿”å›éªŒè¯ç»“æœ"""
    try:
        # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
        from .env_setup import _env_loaded
        
        if env_path and env_path.exists():
            # ä¸´æ—¶åŠ è½½æŒ‡å®šçš„ç¯å¢ƒæ–‡ä»¶
            from dotenv import load_dotenv
            load_dotenv(env_path, override=True)
        else:
            setup_environment()
        
        # æµ‹è¯•APIè¿æ¥
        base_url = os.getenv('OPENAI_BASE_URL')
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not base_url or not api_key:
            print("âŒ ç¼ºå°‘å¿…éœ€çš„ API é…ç½® (OPENAI_BASE_URL æˆ– OPENAI_API_KEY)")
            return False
        
        # è·å–æ‰€æœ‰éœ€è¦éªŒè¯çš„æ¨¡å‹
        split_model = os.getenv('SPLIT_MODEL')
        translation_model = os.getenv('TRANSLATION_MODEL')
        summary_model = os.getenv('SUMMARY_MODEL')
        llm_model = os.getenv('LLM_MODEL')
        
        # æ”¶é›†æ‰€æœ‰ä¸åŒçš„æ¨¡å‹
        unique_models = {}
        if split_model:
            unique_models['æ–­å¥æ¨¡å‹'] = split_model
        if translation_model:
            unique_models['ç¿»è¯‘æ¨¡å‹'] = translation_model
        if summary_model:
            unique_models['æ€»ç»“æ¨¡å‹'] = summary_model
        if llm_model:
            unique_models['é»˜è®¤æ¨¡å‹'] = llm_model
            
        if not unique_models:
            print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹é…ç½®")
            return False
            
        # å»é‡ï¼šåªæµ‹è¯•ä¸åŒçš„æ¨¡å‹
        tested_models = set()
        validation_results = []
        
        for model_type, model_name in unique_models.items():
            if model_name not in tested_models:
                print(f"ğŸ”Œ æµ‹è¯• {model_name}...")
                success, message = test_openai(base_url, api_key, model_name)
                tested_models.add(model_name)
                
                validation_results.append({
                    'model': model_name,
                    'success': success,
                    'message': message,
                    'types': [model_type]
                })
            else:
                # å¦‚æœæ¨¡å‹å·²ç»æµ‹è¯•è¿‡ï¼Œæ‰¾åˆ°ä¹‹å‰çš„ç»“æœå¹¶æ·»åŠ ç±»å‹
                for result in validation_results:
                    if result['model'] == model_name:
                        result['types'].append(model_type)
                        break
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœ
        print("\nğŸ“Š [bold blue]éªŒè¯ç»“æœ:[/bold blue]")
        all_success = True
        
        for result in validation_results:
            model_types = 'ã€'.join(result['types'])
            if result['success']:
                print(f"   âœ… {result['model']} ({model_types})")
                print(f"      å“åº”: {result['message'][:60]}...")
            else:
                print(f"   âŒ {result['model']} ({model_types})")
                print(f"      é”™è¯¯: {result['message']}")
                all_success = False
        
        return all_success
            
    except Exception as e:
        print(f"âš ï¸  é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False


def validate_existing_config(env_path: Path = None):
    """éªŒè¯ç°æœ‰é…ç½®ä¸­çš„æ‰€æœ‰æ¨¡å‹ï¼ˆä»…æ˜¾ç¤ºç»“æœï¼Œä¸è¿”å›ï¼‰"""
    result = validate_existing_config_and_return_result(env_path)
    if result:
        print("\nğŸ‰ [bold green]æ‰€æœ‰æ¨¡å‹éªŒè¯æˆåŠŸï¼[/bold green]")
    else:
        print("\nâš ï¸  [bold yellow]éƒ¨åˆ†æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œç½‘ç»œè¿æ¥[/bold yellow]")


def init_config():
    """åˆå§‹åŒ–å…¨å±€é…ç½® - æ£€æŸ¥å½“å‰ç›®å½•.envæ–‡ä»¶æˆ–äº¤äº’å¼è¾“å…¥é…ç½®"""
    print("[bold green]ğŸš€ å­—å¹•ç¿»è¯‘å·¥å…·é…ç½®åˆå§‹åŒ–[/bold green]")
    
    # è·å–å…¨å±€é…ç½®ç›®å½•å’Œæ–‡ä»¶è·¯å¾„
    app_dir = get_app_config_dir()
    global_env_path = get_global_env_path()
    current_env_path = Path(".env")
    
    # ç¡®ä¿å…¨å±€é…ç½®ç›®å½•å­˜åœ¨
    app_dir.mkdir(parents=True, exist_ok=True)
    
    # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æœ‰.envæ–‡ä»¶
    if current_env_path.exists():
        # æ˜¾ç¤ºå½“å‰.envæ–‡ä»¶å†…å®¹ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
        print("\nğŸ“‹ [bold cyan]å½“å‰é…ç½®æ–‡ä»¶å†…å®¹:[/bold cyan]")
        try:
            with open(current_env_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æé…ç½®ä¿¡æ¯
            config_info = {}
            for line in content.split('\n'):
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip()
                    config_info[key] = value
            
            # åˆ†ç±»æ˜¾ç¤ºé…ç½®
            if 'OPENAI_BASE_URL' in config_info:
                print(f"   ğŸŒ API URL: {config_info['OPENAI_BASE_URL']}")
            
            if 'OPENAI_API_KEY' in config_info:
                api_key = config_info['OPENAI_API_KEY']
                masked_value = api_key[:10] + '*' * (len(api_key) - 10) if len(api_key) > 10 else '*' * len(api_key)
                print(f"   ğŸ”‘ API Key: {masked_value}")
            
            # æ˜¾ç¤ºæ¨¡å‹é…ç½®
            model_configs = []
            if 'SPLIT_MODEL' in config_info:
                model_configs.append(f"æ–­å¥: {config_info['SPLIT_MODEL']}")
            if 'TRANSLATION_MODEL' in config_info:
                model_configs.append(f"ç¿»è¯‘: {config_info['TRANSLATION_MODEL']}")
            if 'SUMMARY_MODEL' in config_info:
                model_configs.append(f"æ€»ç»“: {config_info['SUMMARY_MODEL']}")
            if 'LLM_MODEL' in config_info:
                model_configs.append(f"é»˜è®¤: {config_info['LLM_MODEL']}")
            
            if model_configs:
                print("   ğŸ¤– æ¨¡å‹é…ç½®:")
                for model_config in model_configs:
                    print(f"      â€¢ {model_config}")
            
            # æ˜¾ç¤ºå…¶ä»–é…ç½®
            other_configs = []
            for key, value in config_info.items():
                if key not in ['OPENAI_BASE_URL', 'OPENAI_API_KEY', 'SPLIT_MODEL', 'TRANSLATION_MODEL', 'SUMMARY_MODEL', 'LLM_MODEL']:
                    other_configs.append(f"{key}: {value}")
            
            if other_configs:
                print("   âš™ï¸  å…¶ä»–é…ç½®:")
                for other_config in other_configs:
                    print(f"      â€¢ {other_config}")
                    
        except Exception as e:
            print(f"âš ï¸  è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # è¯¢é—®æ˜¯å¦å¤åˆ¶
        response = typer.prompt("æ˜¯å¦å°†æ­¤é…ç½®å¤åˆ¶åˆ°å…¨å±€é…ç½®? (y/N)", default="n", show_default=False).lower()
        
        if response in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
            # å…ˆéªŒè¯ç°æœ‰é…ç½®
            print("\nğŸ” [bold blue]æ­£åœ¨éªŒè¯ç°æœ‰é…ç½®...[/bold blue]")
            validation_success = validate_existing_config_and_return_result(current_env_path)
            
            if not validation_success:
                print("\nâš ï¸  [bold yellow]é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œç½‘ç»œè¿æ¥[/bold yellow]")
                continue_response = typer.prompt("æ˜¯å¦ä»ç„¶å¤åˆ¶é…ç½®? (y/N)", default="n", show_default=False).lower()
                if continue_response not in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
                    print("âŒ é…ç½®å¤åˆ¶å·²å–æ¶ˆ")
                    raise typer.Exit(code=1)
            
            # éªŒè¯é€šè¿‡åå†å¤åˆ¶
            try:
                import shutil
                shutil.copy2(current_env_path, global_env_path)
                print(f"\nâœ… [bold green]é…ç½®å·²ä¿å­˜åˆ°:[/bold green] [cyan]{global_env_path}[/cyan]")
                print("\nğŸ‰ [bold green]é…ç½®å®Œæˆï¼ç°åœ¨ä½ å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ subtitle-translate å‘½ä»¤ï¼[/bold green]")
                
            except Exception as e:
                print(f"[bold red]âŒ å¤åˆ¶å¤±è´¥: {e}[/bold red]")
                raise typer.Exit(code=1)
        else:
            print("â­ï¸  è·³è¿‡å¤åˆ¶ï¼Œé…ç½®æœªæ›´æ”¹")
            
            # å³ä½¿ä¸å¤åˆ¶ï¼Œä¹ŸéªŒè¯å½“å‰é…ç½®
            print("\nğŸ” [bold blue]éªŒè¯å½“å‰ç›®å½•çš„é…ç½®...[/bold blue]")
            validate_existing_config(current_env_path)
    
    else:
        # äº¤äº’å¼è¾“å…¥é…ç½®
        _interactive_config_input(global_env_path)


def _interactive_config_input(global_env_path: Path):
    """äº¤äº’å¼è¾“å…¥é…ç½®"""
    base_url = typer.prompt("ğŸŒ APIåŸºç¡€URL", default="https://api.openai.com/v1")
    
    # APIå¯†é’¥
    api_key = typer.prompt("ğŸ”‘ APIå¯†é’¥")
    
    if not api_key.strip():
        print("[bold red]âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º[/bold red]")
        raise typer.Exit(code=1)

    print("\nğŸ¤– [bold blue]æ¨¡å‹é…ç½®[/bold blue]")
    print("å­—å¹•ç¿»è¯‘å·¥å…·æ”¯æŒä¸ºä¸åŒåŠŸèƒ½ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ï¼š")
    print("â€¢ æ–­å¥æ¨¡å‹ï¼šå°†é•¿å¥åˆ†å‰²æˆé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥")
    print("â€¢ ç¿»è¯‘æ¨¡å‹ï¼šç¿»è¯‘å­—å¹•å†…å®¹")
    print("â€¢ æ€»ç»“æ¨¡å‹ï¼šåˆ†æå­—å¹•å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦")
    
    # è¯¢é—®æ˜¯å¦è¦åˆ†åˆ«é…ç½®æ¨¡å‹
    separate_models_response = typer.prompt("\nğŸ”§ æ˜¯å¦ä¸ºä¸åŒåŠŸèƒ½åˆ†åˆ«é…ç½®æ¨¡å‹? (y/N)", default="y", show_default=False).lower()
    use_separate_models = separate_models_response in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']
    
    if use_separate_models:
        # åˆ†åˆ«é…ç½®ä¸‰ä¸ªæ¨¡å‹
        print("\nğŸ”¤ [bold yellow]æ–­å¥æ¨¡å‹é…ç½®[/bold yellow]")
        split_model = typer.prompt("æ–­å¥æ¨¡å‹")
        while not split_model.strip():
            print("âŒ æ–­å¥æ¨¡å‹ä¸èƒ½ä¸ºç©º")
            split_model = typer.prompt("æ–­å¥æ¨¡å‹")
        
        print("\nğŸŒ [bold yellow]ç¿»è¯‘æ¨¡å‹é…ç½®[/bold yellow]")
        translation_model = typer.prompt("ç¿»è¯‘æ¨¡å‹")
        while not translation_model.strip():
            print("âŒ ç¿»è¯‘æ¨¡å‹ä¸èƒ½ä¸ºç©º")
            translation_model = typer.prompt("ç¿»è¯‘æ¨¡å‹")
        
        print("\nğŸ“Š [bold yellow]æ€»ç»“æ¨¡å‹é…ç½®[/bold yellow]")
        summary_model = typer.prompt("æ€»ç»“æ¨¡å‹")
        while not summary_model.strip():
            print("âŒ æ€»ç»“æ¨¡å‹ä¸èƒ½ä¸ºç©º")
            summary_model = typer.prompt("æ€»ç»“æ¨¡å‹")
        
        # å…¼å®¹æ€§é»˜è®¤æ¨¡å‹
        llm_model = split_model
    else:
        print("\nğŸ¤– [bold yellow]ç»Ÿä¸€æ¨¡å‹é…ç½®[/bold yellow]")
        llm_model = typer.prompt("LLMæ¨¡å‹")
        while not llm_model.strip():
            print("âŒ LLMæ¨¡å‹ä¸èƒ½ä¸ºç©º")
            llm_model = typer.prompt("LLMæ¨¡å‹")
        
        # ç»Ÿä¸€ä½¿ç”¨ä¸€ä¸ªæ¨¡å‹
        split_model = llm_model
        translation_model = llm_model
        summary_model = llm_model
    
    # éªŒè¯é…ç½®
    print("\nğŸ” [bold blue]æ­£åœ¨éªŒè¯ API é…ç½®...[/bold blue]")
    
    # è·å–æ‰€æœ‰éœ€è¦éªŒè¯çš„æ¨¡å‹
    unique_models = {}
    unique_models['æ–­å¥æ¨¡å‹'] = split_model
    unique_models['ç¿»è¯‘æ¨¡å‹'] = translation_model
    unique_models['æ€»ç»“æ¨¡å‹'] = summary_model
    unique_models['é»˜è®¤æ¨¡å‹'] = llm_model
        
    # å»é‡ï¼šåªæµ‹è¯•ä¸åŒçš„æ¨¡å‹
    tested_models = set()
    validation_results = []
    
    for model_type, model_name in unique_models.items():
        if model_name not in tested_models:
            print(f"ğŸ”Œ æµ‹è¯• {model_name}...")
            success, message = test_openai(base_url, api_key, model_name)
            tested_models.add(model_name)
            
            validation_results.append({
                'model': model_name,
                'success': success,
                'message': message,
                'types': [model_type]
            })
        else:
            # å¦‚æœæ¨¡å‹å·²ç»æµ‹è¯•è¿‡ï¼Œæ‰¾åˆ°ä¹‹å‰çš„ç»“æœå¹¶æ·»åŠ ç±»å‹
            for result in validation_results:
                if result['model'] == model_name:
                    result['types'].append(model_type)
                    break
    
    # æ˜¾ç¤ºéªŒè¯ç»“æœ
    print("\nğŸ“Š [bold blue]éªŒè¯ç»“æœ:[/bold blue]")
    all_success = True
    
    for result in validation_results:
        model_types = 'ã€'.join(result['types'])
        if result['success']:
            print(f"   âœ… {result['model']} ({model_types})")
            print(f"      å“åº”: {result['message'][:60]}...")
        else:
            print(f"   âŒ {result['model']} ({model_types})")
            print(f"      é”™è¯¯: {result['message']}")
            all_success = False
    
    if not all_success:
        print("\nâš ï¸  [bold yellow]éƒ¨åˆ†æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œç½‘ç»œè¿æ¥[/bold yellow]")
        continue_response = typer.prompt("æ˜¯å¦ç»§ç»­ä¿å­˜é…ç½®? (y/N)", default="n", show_default=False).lower()
        if continue_response not in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
            print("âŒ é…ç½®ä¿å­˜å·²å–æ¶ˆ")
            raise typer.Exit(code=1)
    
    # APIéªŒè¯é€šè¿‡åï¼Œç”Ÿæˆé…ç½®æ–‡ä»¶å†…å®¹
    config_content = f"""# Subtitle Translator é…ç½®æ–‡ä»¶
# ç”± subtitle-translate init å‘½ä»¤è‡ªåŠ¨ç”Ÿæˆ

# ======== API é…ç½® ========
# API åŸºç¡€URL
OPENAI_BASE_URL={base_url}

# API å¯†é’¥
OPENAI_API_KEY={api_key}

# ======== æ¨¡å‹é…ç½® ========
# æ–­å¥æ¨¡å‹ - è´Ÿè´£å°†é•¿å¥åˆ†å‰²æˆé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥
SPLIT_MODEL={split_model}

# ç¿»è¯‘æ¨¡å‹ - è´Ÿè´£å°†å­—å¹•ç¿»è¯‘æˆç›®æ ‡è¯­è¨€
TRANSLATION_MODEL={translation_model}

# æ€»ç»“æ¨¡å‹ - è´Ÿè´£åˆ†æå­—å¹•å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
SUMMARY_MODEL={summary_model}

# å…¼å®¹æ€§ï¼šé»˜è®¤æ¨¡å‹ (å¦‚æœä¸Šè¿°æ¨¡å‹æœªè®¾ç½®ï¼Œå°†ä½¿ç”¨æ­¤æ¨¡å‹)
LLM_MODEL={llm_model}

# ======== ä½¿ç”¨è¯´æ˜ ========
# 1. ä½ ç°åœ¨å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ subtitle-translate å‘½ä»¤
# 2. å¦‚éœ€ä¿®æ”¹é…ç½®ï¼Œå¯ä»¥ç¼–è¾‘æ­¤æ–‡ä»¶æˆ–é‡æ–°è¿è¡Œ subtitle-translate init
# 3. åˆ†åˆ«é…ç½®çš„æ¨¡å‹ä¼šä¼˜å…ˆä½¿ç”¨ï¼Œå¦‚æœªè®¾ç½®åˆ™å›é€€åˆ° LLM_MODEL
"""
    
    # ä¿å­˜åˆ°å…¨å±€é…ç½®
    try:
        with open(global_env_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        print(f"\nâœ… [bold green]é…ç½®å·²ä¿å­˜åˆ°:[/bold green] [cyan]{global_env_path}[/cyan]")
        
        # æ˜¾ç¤ºé…ç½®æ‘˜è¦
        print("\nğŸ“‹ [bold green]é…ç½®æ‘˜è¦:[/bold green]")
        print(f"   ğŸŒ API URL: {base_url}")
        print(f"   ğŸ”‘ API Key: {api_key[:10]}{'*' * (len(api_key) - 10)}")
        if use_separate_models:
            print(f"   ğŸ”¤ æ–­å¥æ¨¡å‹: [cyan]{split_model}[/cyan]")
            print(f"   ğŸŒ ç¿»è¯‘æ¨¡å‹: [cyan]{translation_model}[/cyan]")
            print(f"   ğŸ“Š æ€»ç»“æ¨¡å‹: [cyan]{summary_model}[/cyan]")
            print(f"   ğŸ¤– é»˜è®¤æ¨¡å‹: [cyan]{llm_model}[/cyan]")
        else:
            print(f"   ğŸ¤– ç»Ÿä¸€æ¨¡å‹: [cyan]{llm_model}[/cyan]")
        
        print("\nğŸ‰ [bold green]é…ç½®å®Œæˆï¼ç°åœ¨ä½ å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ subtitle-translate å‘½ä»¤ï¼[/bold green]")
        
    except Exception as e:
        print(f"[bold red]âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}[/bold red]")
        raise typer.Exit(code=1) 