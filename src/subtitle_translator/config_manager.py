"""
é…ç½®ç®¡ç†æ¨¡å— - é…ç½®éªŒè¯å’Œåˆå§‹åŒ–
"""
import os
from pathlib import Path
from functools import wraps

import typer
import click
from rich import print

from .env_setup import setup_environment, get_app_config_dir, get_global_env_path
from .translation_core.utils.test_openai import test_openai


def handle_user_abort(exit_message="âŒ é…ç½®å·²å–æ¶ˆ"):
    """è£…é¥°å™¨ï¼šç»Ÿä¸€å¤„ç†ç”¨æˆ·ä¸­æ–­æ“ä½œ"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except (KeyboardInterrupt, typer.Abort, click.exceptions.Abort):
                print(f"\n{exit_message}")
                import sys
                sys.exit(0)
        return wrapper
    return decorator


@handle_user_abort()
def safe_prompt(message, **kwargs):
    """å®‰å…¨çš„ typer.prompt åŒ…è£…å‡½æ•°ï¼Œè‡ªåŠ¨å¤„ç†ç”¨æˆ·å–æ¶ˆæ“ä½œ"""
    return typer.prompt(message, **kwargs)


@handle_user_abort("âŒ æ“ä½œå·²å–æ¶ˆ")
def safe_prompt_operation(message, **kwargs):
    """å®‰å…¨çš„ typer.prompt åŒ…è£…å‡½æ•°ï¼ˆç”¨äºæ“ä½œç±»æç¤ºï¼‰ï¼Œè‡ªåŠ¨å¤„ç†ç”¨æˆ·å–æ¶ˆæ“ä½œ"""
    return typer.prompt(message, **kwargs)


def validate_existing_config_and_return_result(env_path: Path = None):
    """éªŒè¯ç°æœ‰é…ç½®ä¸­çš„æ‰€æœ‰æ¨¡å‹ï¼Œè¿”å›éªŒè¯ç»“æœ"""
    try:
        # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
        from .env_setup import _env_loaded
        
        if env_path and env_path.exists():
            # ä¸´æ—¶åŠ è½½æŒ‡å®šçš„ç¯å¢ƒæ–‡ä»¶
            from dotenv import load_dotenv
            load_dotenv(env_path, override=True)
        else:
            setup_environment()
        
        # æµ‹è¯•APIè¿æ¥
        base_url = os.getenv('OPENAI_BASE_URL')
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not base_url or not api_key:
            print("âŒ ç¼ºå°‘å¿…éœ€çš„ API é…ç½® (OPENAI_BASE_URL æˆ– OPENAI_API_KEY)")
            return False
        
        # è·å–æ‰€æœ‰éœ€è¦éªŒè¯çš„æ¨¡å‹
        split_model = os.getenv('SPLIT_MODEL')
        translation_model = os.getenv('TRANSLATION_MODEL')
        summary_model = os.getenv('SUMMARY_MODEL')
        llm_model = os.getenv('LLM_MODEL')
        
        # æ”¶é›†æ‰€æœ‰ä¸åŒçš„æ¨¡å‹
        unique_models = {}
        if split_model:
            unique_models['æ–­å¥æ¨¡å‹'] = split_model
        if translation_model:
            unique_models['ç¿»è¯‘æ¨¡å‹'] = translation_model
        if summary_model:
            unique_models['æ€»ç»“æ¨¡å‹'] = summary_model
        if llm_model:
            unique_models['é»˜è®¤æ¨¡å‹'] = llm_model
            
        if not unique_models:
            print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹é…ç½®")
            return False
            
        # å»é‡ï¼šåªæµ‹è¯•ä¸åŒçš„æ¨¡å‹
        tested_models = set()
        validation_results = []
        
        for model_type, model_name in unique_models.items():
            if model_name not in tested_models:
                print(f"ğŸ”Œ æµ‹è¯• {model_name}...")
                success, message = test_openai(base_url, api_key, model_name)
                tested_models.add(model_name)
                
                validation_results.append({
                    'model': model_name,
                    'success': success,
                    'message': message,
                    'types': [model_type]
                })
            else:
                # å¦‚æœæ¨¡å‹å·²ç»æµ‹è¯•è¿‡ï¼Œæ‰¾åˆ°ä¹‹å‰çš„ç»“æœå¹¶æ·»åŠ ç±»å‹
                for result in validation_results:
                    if result['model'] == model_name:
                        result['types'].append(model_type)
                        break
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœ
        print("\nğŸ“Š [bold blue]éªŒè¯ç»“æœ:[/bold blue]")
        all_success = True
        
        for result in validation_results:
            model_types = 'ã€'.join(result['types'])
            if result['success']:
                print(f"   âœ… {result['model']} ({model_types})")
                print(f"      å“åº”: {result['message'][:60]}...")
            else:
                print(f"   âŒ {result['model']} ({model_types})")
                print(f"      é”™è¯¯: {result['message']}")
                all_success = False
        
        return all_success
            
    except Exception as e:
        print(f"âš ï¸  é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False


def validate_existing_config(env_path: Path = None):
    """éªŒè¯ç°æœ‰é…ç½®ä¸­çš„æ‰€æœ‰æ¨¡å‹ï¼ˆä»…æ˜¾ç¤ºç»“æœï¼Œä¸è¿”å›ï¼‰"""
    result = validate_existing_config_and_return_result(env_path)
    if result:
        print("\nğŸ‰ [bold green]æ‰€æœ‰æ¨¡å‹éªŒè¯æˆåŠŸï¼[/bold green]")
    else:
        print("\nâš ï¸  [bold yellow]éƒ¨åˆ†æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œç½‘ç»œè¿æ¥[/bold yellow]")


def _check_model_availability(model_id: str, detailed: bool = True) -> tuple[bool, str]:
    """
    æ£€æŸ¥è½¬å½•æ¨¡å‹å¯ç”¨æ€§çš„ç»Ÿä¸€å‡½æ•°
    
    Args:
        model_id: è½¬å½•æ¨¡å‹ID
        detailed: æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«ç¼“å­˜ä¿¡æ¯ã€ImportErrorå¤„ç†ç­‰ï¼‰
        
    Returns:
        tuple: (æ˜¯å¦å¯ç”¨, çŠ¶æ€æè¿°)
    """
    try:
        from .transcription_core.utils import _find_cached_model
        
        try:
            config_path, weight_path = _find_cached_model(model_id)
            if detailed:
                # è·å–ç¼“å­˜ç›®å½•åä½œä¸ºçŠ¶æ€ä¿¡æ¯
                cache_info = Path(config_path).parent.parent.name
                return True, f"å·²ç¼“å­˜ ({cache_info})"
            else:
                return True, "å·²ç¼“å­˜"
        except FileNotFoundError:
            return False, "æœªä¸‹è½½" if detailed else "æœªç¼“å­˜"
            
    except ImportError:
        # åªåœ¨éè¯¦ç»†æ¨¡å¼ä¸‹ç‰¹åˆ«å¤„ç†ImportError
        if not detailed:
            return False, "æ¨¡å—æœªå¯ç”¨"
        else:
            return False, "æ£€æµ‹å¤±è´¥: è½¬å½•æ¨¡å—å¯¼å…¥å¤±è´¥"
    except Exception as e:
        if detailed:
            # è¯¦ç»†æ¨¡å¼ä¸‹æˆªæ–­é”™è¯¯ä¿¡æ¯
            return False, f"æ£€æµ‹å¤±è´¥: {str(e)[:50]}..."
        else:
            # ç®€åŒ–æ¨¡å¼ä¸‹æ˜¾ç¤ºå®Œæ•´é”™è¯¯ä¿¡æ¯
            return False, f"æ£€æŸ¥å¤±è´¥: {str(e)}"


def _check_transcription_model_availability(model_id: str = "mlx-community/parakeet-tdt-0.6b-v2") -> tuple[bool, str]:
    """
    æ£€æŸ¥è½¬å½•æ¨¡å‹å¯ç”¨æ€§ (å…¼å®¹æ€§åŒ…è£…å‡½æ•°)
    
    Args:
        model_id: è½¬å½•æ¨¡å‹ID
        
    Returns:
        tuple: (æ˜¯å¦å¯ç”¨, çŠ¶æ€æè¿°)
    """
    return _check_model_availability(model_id, detailed=True)


def _display_model_download_guide(model_id: str = "mlx-community/parakeet-tdt-0.6b-v2"):
    """æ˜¾ç¤ºè½¬å½•æ¨¡å‹æ‰‹åŠ¨ä¸‹è½½æŒ‡å—"""
    print(f"\nğŸ“‹ [bold blue]è½¬å½•æ¨¡å‹ä¸‹è½½æŒ‡å—:[/bold blue]")
    print("å¦‚éœ€ä½¿ç”¨è½¬å½•åŠŸèƒ½ï¼Œå¯é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¸‹è½½æ¨¡å‹ï¼š")
    print("")
    print("1. ğŸ”§ [bold]è‡ªåŠ¨ä¸‹è½½ (æ¨è):[/bold]")
    print("   é¦–æ¬¡è¿è¡Œè½¬å½•å‘½ä»¤æ—¶è‡ªåŠ¨ä¸‹è½½")
    print("   [dim]translate -i audio.mp3[/dim]")
    print("")
    print("2. ğŸŒ [bold]åœ¨çº¿é¢„ä¸‹è½½:[/bold]")
    print("   é€šè¿‡ huggingface-cli å·¥å…·é¢„ä¸‹è½½")
    print(f"   [dim]huggingface-cli download {model_id}[/dim]")
    print("")
    print("3. ğŸ—ï¸  [bold]é•œåƒç«™ä¸‹è½½ (å›½å†…ç”¨æˆ·æ¨è):[/bold]")
    print("   é…ç½®é•œåƒç«™åä¸‹è½½æ›´å¿«æ›´ç¨³å®š")
    print("   [dim]export HF_ENDPOINT=https://hf-mirror.com[/dim]")
    print(f"   [dim]huggingface-cli download {model_id}[/dim]")
    print("")
    print("4. ğŸ“ [bold]æœ¬åœ°è·¯å¾„åŠ è½½:[/bold]")
    print("   æ”¯æŒä½¿ç”¨æœ¬åœ°ç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶")
    print("   è¦æ±‚ç›®å½•åŒ…å«: config.json å’Œ model.safetensors")
    print("   [dim]translate -i audio.mp3 --model /path/to/local/model[/dim]")
    print("   ğŸ’¡ [dim]é€‚ç”¨äºé¢„å…ˆä¸‹è½½çš„æ¨¡å‹æˆ–è‡ªå®šä¹‰æ¨¡å‹ç›®å½•[/dim]")
    print("")
    print("5. ğŸ”„ [bold]ä¸­æ–­æ¢å¤:[/bold]")
    print("   å¦‚æœä¸‹è½½è¢«ä¸­æ–­ï¼Œå¯ä»¥é‡æ–°è¿è¡Œä»»æ„ä¸‹è½½å‘½ä»¤ç»§ç»­")
    print("   [dim]translate -i audio.mp3  # è‡ªåŠ¨ç»§ç»­ä¸‹è½½[/dim]")
    print(f"   [dim]huggingface-cli download {model_id}  # æ‰‹åŠ¨ç»§ç»­ä¸‹è½½[/dim]")
    print("   [dim]translate init  # é€šè¿‡é…ç½®å‘å¯¼ç»§ç»­ä¸‹è½½[/dim]")
    print("")
    print("6. ğŸ—‚ï¸  [bold]ç¼“å­˜ä½ç½®:[/bold]")
    print("   ä¸‹è½½çš„æ¨¡å‹ç¼“å­˜åœ¨ ~/.cache/huggingface/")
    print("   å¦‚éœ€é‡æ–°å®Œæ•´ä¸‹è½½ï¼Œå¯åˆ é™¤å¯¹åº”ç¼“å­˜ç›®å½•")
    print("")
    print("ğŸ’¡ [dim]æ¨¡å‹å¤§å°çº¦ 1.2GBï¼Œé¦–æ¬¡ä¸‹è½½éœ€è¦ä¸€äº›æ—¶é—´[/dim]")
    print("ğŸ”„ [dim]æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œä¸‹è½½ä¸­æ–­åå¯ä»¥ç»§ç»­ä¸‹è½½[/dim]")


def _display_system_status_summary():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€æ€»ç»“"""
    print("\nğŸ“Š [bold green]ç³»ç»ŸçŠ¶æ€æ€»ç»“:[/bold green]")
    
    # API é…ç½®çŠ¶æ€
    print("   ğŸ”‘ API é…ç½®: âœ… å·²é…ç½®")
    
    # è½¬å½•æ¨¡å‹çŠ¶æ€
    model_available, model_status = _check_transcription_model_availability()
    status_icon = "âœ…" if model_available else "âš ï¸ "
    print(f"   ğŸ¤– è½¬å½•æ¨¡å‹: {status_icon} {model_status}")
    
    # åŠŸèƒ½å¯ç”¨æ€§
    print("   ğŸ“ ç¿»è¯‘åŠŸèƒ½: âœ… å¯ç”¨")
    transcription_status = "âœ… å¯ç”¨" if model_available else "âš ï¸  é¦–æ¬¡ä½¿ç”¨æ—¶ä¸‹è½½"
    print(f"   ğŸ™ï¸  è½¬å½•åŠŸèƒ½: {transcription_status}")


def _handle_model_download_suggestion():
    """å¤„ç†è½¬å½•æ¨¡å‹ä¸‹è½½å»ºè®®"""
    model_available, model_status = _check_transcription_model_availability()
    
    if not model_available:
        print(f"\nğŸ’¡ [bold yellow]å‘ç°è½¬å½•æ¨¡å‹æœªä¸‹è½½[/bold yellow]")
        print("è½¬å½•åŠŸèƒ½éœ€è¦ä¸‹è½½é»˜è®¤æ¨¡å‹ (mlx-community/parakeet-tdt-0.6b-v2)")
        print("æ¨¡å‹å¤§å°çº¦ 1.2GBï¼Œå»ºè®®åœ¨ç½‘ç»œè‰¯å¥½æ—¶é¢„ä¸‹è½½")
        print("ğŸ”„ [dim]å¦‚æœä¹‹å‰ä¸‹è½½è¢«ä¸­æ–­ï¼Œç°åœ¨å¯ä»¥ç»§ç»­å®Œæˆä¸‹è½½[/dim]")
        
        # æ£€æŸ¥ç½‘ç»œè¿æ¥
        try:
            from .transcription_core.utils import _check_network_connectivity
            has_network = _check_network_connectivity()
            
            if has_network:
                print("\nğŸ”§ [bold blue]ä¸‹è½½é€‰é¡¹:[/bold blue]")
                print("   1. ç°åœ¨é¢„ä¸‹è½½ (æ¨è)")
                print("   2. è·³è¿‡é¢„ä¸‹è½½")
                print("   3. æŸ¥çœ‹æ‰€æœ‰ä¸‹è½½æ–¹å¼")
                
                while True:
                    choice = safe_prompt_operation(
                        "è¯·é€‰æ‹© (1-3)", 
                        default="1", 
                        show_default=False
                    )
                    
                    if choice == "1":
                        # é¢„ä¸‹è½½
                        print("\n" + "="*50)
                        return _execute_predownload()
                    elif choice == "2":
                        # è·³è¿‡é¢„ä¸‹è½½
                        print("â­ï¸  [dim]è·³è¿‡é¢„ä¸‹è½½ï¼Œé¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½[/dim]")
                        return False
                    elif choice == "3":
                        # æ˜¾ç¤ºå®Œæ•´ä¸‹è½½æŒ‡å—
                        _display_model_download_guide()
                        
                        # æ˜¾ç¤ºæŒ‡å—åå†æ¬¡è¯¢é—®æ˜¯å¦è¦é¢„ä¸‹è½½
                        followup_choice = safe_prompt_operation(
                            "\nğŸ“¥ ç°åœ¨æ˜¯å¦è¦é¢„ä¸‹è½½é»˜è®¤æ¨¡å‹? (y/N)", 
                            default="n", 
                            show_default=False
                        ).lower()
                        
                        if followup_choice in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
                            print("\n" + "="*50)
                            return _execute_predownload()
                        else:
                            print("â­ï¸  [dim]è·³è¿‡é¢„ä¸‹è½½ï¼Œå¯ä»¥æŒ‰ç…§ä¸Šè¿°æŒ‡å—æ‰‹åŠ¨ä¸‹è½½[/dim]")
                            return False
                    else:
                        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆé€‰æ‹© (1-3)")
                        continue
            else:
                print("\nâŒ [bold red]ç½‘ç»œè¿æ¥ä¸å¯ç”¨[/bold red]")
                print("ğŸ’¡ [dim]ç½‘ç»œæ¢å¤åå¯é‡æ–°è¿è¡Œä¸‹è½½å‘½ä»¤ç»§ç»­[/dim]")
                _display_model_download_guide()
                return False
        except Exception:
            # ç½‘ç»œæ£€æµ‹å¤±è´¥ï¼Œæä¾›æ‰‹åŠ¨ä¸‹è½½æŒ‡å—
            print("ğŸ’¡ [dim]å¦‚æœä¹‹å‰æœ‰ä¸‹è½½ä¸­æ–­ï¼Œå¯é‡æ–°è¿è¡Œå‘½ä»¤ç»§ç»­[/dim]")
            _display_model_download_guide()
            return False
    
    return True


def init_config():
    """åˆå§‹åŒ–å…¨å±€é…ç½® - æ™ºèƒ½æ£€æµ‹å¹¶å¤„ç†å½“å‰ç›®å½•å’Œå…¨å±€é…ç½®çš„å„ç§ç»„åˆæƒ…å†µ"""
    print("[bold green]ğŸš€ å­—å¹•ç¿»è¯‘å·¥å…·é…ç½®åˆå§‹åŒ–[/bold green]")
    
    # è·å–å…¨å±€é…ç½®ç›®å½•å’Œæ–‡ä»¶è·¯å¾„
    app_dir = get_app_config_dir()
    global_env_path = get_global_env_path()
    current_env_path = Path(".env")
    
    # ç¡®ä¿å…¨å±€é…ç½®ç›®å½•å­˜åœ¨
    app_dir.mkdir(parents=True, exist_ok=True)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶å­˜åœ¨æƒ…å†µ
    current_exists = current_env_path.exists()
    global_exists = global_env_path.exists()
    
    print(f"\nğŸ“ [bold blue]é…ç½®æ–‡ä»¶æ£€æµ‹ç»“æœ:[/bold blue]")
    print(f"   ğŸ“„ å½“å‰ç›®å½•é…ç½®: {'âœ… å­˜åœ¨' if current_exists else 'âŒ ä¸å­˜åœ¨'} ([cyan].env[/cyan])")
    print(f"   ğŸŒ å…¨å±€é…ç½®: {'âœ… å­˜åœ¨' if global_exists else 'âŒ ä¸å­˜åœ¨'} ([cyan]{global_env_path}[/cyan])")
    
    default_model = "mlx-community/parakeet-tdt-0.6b-v2"
    
    # æ£€æŸ¥é»˜è®¤è½¬å½•æ¨¡å‹æ˜¯å¦å¯ç”¨
    model_available, model_status = _check_model_availability(default_model, detailed=False)
    
    if model_available:
        print(f"   âœ… é»˜è®¤è½¬å½•æ¨¡å‹: {model_status} ([cyan]{default_model}[/cyan])")
    else:
        print(f"   âŒ é»˜è®¤è½¬å½•æ¨¡å‹: {model_status} ([cyan]{default_model}[/cyan])")
        print(f"   ğŸ“ [dim]é¦–æ¬¡ä½¿ç”¨è½¬å½•åŠŸèƒ½æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ (~1.2GB)[/dim]")
    
    # æ ¹æ®ä¸åŒç»„åˆæƒ…å†µå¤„ç†
    if not current_exists and not global_exists:
        # æƒ…å†µ1: éƒ½ä¸å­˜åœ¨ - å¯åŠ¨äº¤äº’å¼é…ç½®è¾“å…¥
        print(f"\nğŸ’¡ [bold yellow]æœªæ‰¾åˆ°ä»»ä½•é…ç½®æ–‡ä»¶ï¼Œå°†å¯åŠ¨äº¤äº’å¼é…ç½®å‘å¯¼[/bold yellow]")
        _interactive_config_input(global_env_path)
        
    elif not current_exists and global_exists:
        # æƒ…å†µ2: åªæœ‰å…¨å±€é…ç½®å­˜åœ¨ - æ˜¾ç¤ºå…¨å±€é…ç½®ï¼Œè¯¢é—®æ˜¯å¦è¦é‡æ–°é…ç½®
        print(f"\nğŸ“‹ [bold cyan]æ£€æµ‹åˆ°å…¨å±€é…ç½®æ–‡ä»¶ï¼Œå½“å‰é…ç½®:[/bold cyan]")
        _display_config_content(global_env_path)
        
        choice = safe_prompt_operation(
            "\nğŸ”§ è¯·é€‰æ‹©æ“ä½œ:\n"
            "   1. ä¿æŒå½“å‰å…¨å±€é…ç½® (æ¨è)\n"
            "   2. é‡æ–°é…ç½® (ä¼šè¦†ç›–ç°æœ‰é…ç½®)\n"
            "   3. éªŒè¯å½“å‰é…ç½®\n"
            "è¯·è¾“å…¥é€‰æ‹© (1-3)", 
            default="1", 
            show_default=False
        )
        
        if choice == "1":
            print("âœ… [bold green]ä¿æŒå½“å‰å…¨å±€é…ç½®[/bold green]")
        elif choice == "2":
            confirm = safe_prompt_operation("âš ï¸  ç¡®è®¤è¦è¦†ç›–ç°æœ‰å…¨å±€é…ç½®å—? (y/N)", default="n", show_default=False).lower()
            if confirm in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
                _interactive_config_input(global_env_path)
            else:
                print("âŒ é‡æ–°é…ç½®å·²å–æ¶ˆ")
        elif choice == "3":
            print("\nğŸ” [bold blue]éªŒè¯å…¨å±€é…ç½®...[/bold blue]")
            validate_existing_config(global_env_path)
        else:
            print("âœ… [bold green]ä¿æŒå½“å‰å…¨å±€é…ç½®[/bold green]")
            
    elif current_exists and not global_exists:
        # æƒ…å†µ3: åªæœ‰å½“å‰ç›®å½•é…ç½®å­˜åœ¨ - æ˜¾ç¤ºå½“å‰é…ç½®ï¼Œè¯¢é—®æ˜¯å¦å¤åˆ¶åˆ°å…¨å±€
        print(f"\nğŸ“‹ [bold cyan]æ£€æµ‹åˆ°å½“å‰ç›®å½•é…ç½®æ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹:[/bold cyan]")
        _display_config_content(current_env_path)
        
        response = safe_prompt_operation("æ˜¯å¦å°†æ­¤é…ç½®å¤åˆ¶åˆ°å…¨å±€é…ç½®? (y/N)", default="y", show_default=False).lower()
        
        if response in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
            _copy_config_with_validation(current_env_path, global_env_path)
        else:
            print("â­ï¸  è·³è¿‡å¤åˆ¶ï¼Œä»…éªŒè¯å½“å‰ç›®å½•é…ç½®")
            print("\nğŸ” [bold blue]éªŒè¯å½“å‰ç›®å½•é…ç½®...[/bold blue]")
            validate_existing_config(current_env_path)
            
    else:
        # æƒ…å†µ4: ä¸¤ä¸ªé…ç½®éƒ½å­˜åœ¨ - æ˜¾ç¤ºä¸¤ä¸ªé…ç½®ï¼Œè®©ç”¨æˆ·é€‰æ‹©
        print(f"\nğŸ“‹ [bold cyan]æ£€æµ‹åˆ°ä¸¤ä¸ªé…ç½®æ–‡ä»¶:[/bold cyan]")
        
        print(f"\nğŸ  [bold yellow]å½“å‰ç›®å½•é…ç½® (.env):[/bold yellow]")
        _display_config_content(current_env_path)
        
        print(f"\nğŸŒ [bold yellow]å…¨å±€é…ç½® ({global_env_path}):[/bold yellow]")
        _display_config_content(global_env_path)
        
        choice = safe_prompt_operation(
            "\nğŸ”§ è¯·é€‰æ‹©æ“ä½œ:\n"
            "   1. ä¿æŒç°æœ‰é…ç½®ä¸å˜\n"
            "   2. ç”¨å½“å‰ç›®å½•é…ç½®è¦†ç›–å…¨å±€é…ç½®\n"
            "   3. é‡æ–°é…ç½® (è¦†ç›–å…¨å±€é…ç½®)\n"
            "   4. éªŒè¯ç°æœ‰é…ç½®\n"
            "è¯·è¾“å…¥é€‰æ‹© (1-4)", 
            default="1", 
            show_default=False
        )
        
        if choice == "1":
            print("âœ… [bold green]ä¿æŒç°æœ‰é…ç½®ä¸å˜[/bold green]")
        elif choice == "2":
            confirm = safe_prompt_operation("âš ï¸  ç¡®è®¤ç”¨å½“å‰ç›®å½•é…ç½®è¦†ç›–å…¨å±€é…ç½®å—? (y/N)", default="n", show_default=False).lower()
            if confirm in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
                _copy_config_with_validation(current_env_path, global_env_path)
            else:
                print("âŒ è¦†ç›–æ“ä½œå·²å–æ¶ˆ")
        elif choice == "3":
            confirm = safe_prompt_operation("âš ï¸  ç¡®è®¤è¦é‡æ–°é…ç½®å¹¶è¦†ç›–å…¨å±€é…ç½®å—? (y/N)", default="n", show_default=False).lower()
            if confirm in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
                _interactive_config_input(global_env_path)
            else:
                print("âŒ é‡æ–°é…ç½®å·²å–æ¶ˆ")
        elif choice == "4":
            validate_choice = safe_prompt_operation(
                "éªŒè¯å“ªä¸ªé…ç½®?\n"
                "   1. å½“å‰ç›®å½•é…ç½®\n"
                "   2. å…¨å±€é…ç½®\n"
                "   3. ä¸¤ä¸ªéƒ½éªŒè¯\n"
                "è¯·è¾“å…¥é€‰æ‹© (1-3)", 
                default="3", 
                show_default=False
            )
            if validate_choice == "1":
                print("\nğŸ” [bold blue]éªŒè¯å½“å‰ç›®å½•é…ç½®...[/bold blue]")
                validate_existing_config(current_env_path)
            elif validate_choice == "2":
                print("\nğŸ” [bold blue]éªŒè¯å…¨å±€é…ç½®...[/bold blue]")
                validate_existing_config(global_env_path)
            else:
                print("\nğŸ” [bold blue]éªŒè¯å½“å‰ç›®å½•é…ç½®...[/bold blue]")
                validate_existing_config(current_env_path)
                print("\nğŸ” [bold blue]éªŒè¯å…¨å±€é…ç½®...[/bold blue]")
                validate_existing_config(global_env_path)
        else:
            print("âœ… [bold green]ä¿æŒç°æœ‰é…ç½®ä¸å˜[/bold green]")
    
    # ğŸ†• ç»Ÿä¸€å¤„ç†è½¬å½•æ¨¡å‹ä¸‹è½½å»ºè®® (æ‰€æœ‰é…ç½®æƒ…å†µå¤„ç†å®Œæˆå)
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å…¨å±€é…ç½®
    has_valid_config = global_env_path.exists()
    
    if has_valid_config and not model_available:
        # æœ‰é…ç½®ä¸”æ¨¡å‹æœªä¸‹è½½ - æä¾›æ™ºèƒ½ä¸‹è½½å»ºè®®
        _handle_model_download_suggestion()
    elif not has_valid_config and not model_available:
        # æ— é…ç½®ä¸”æ¨¡å‹æœªä¸‹è½½ - ä»…æ˜¾ç¤ºä¸‹è½½æŒ‡å—
        _display_model_download_guide()
    
    # æ˜¾ç¤ºæœ€ç»ˆçš„ç³»ç»ŸçŠ¶æ€æ€»ç»“
    if has_valid_config:
        _display_system_status_summary()
    
    print("\nğŸ‰ [bold green]é…ç½®åˆå§‹åŒ–å®Œæˆï¼[/bold green]")


def _display_config_content(env_path: Path):
    """æ˜¾ç¤ºé…ç½®æ–‡ä»¶å†…å®¹ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰"""
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è§£æé…ç½®ä¿¡æ¯
        config_info = {}
        for line in content.split('\n'):
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip()
                config_info[key] = value
        
        # åˆ†ç±»æ˜¾ç¤ºé…ç½®
        if 'OPENAI_BASE_URL' in config_info:
            print(f"   ğŸŒ API URL: {config_info['OPENAI_BASE_URL']}")
        
        if 'OPENAI_API_KEY' in config_info:
            api_key = config_info['OPENAI_API_KEY']
            masked_value = api_key[:10] + '*' * (len(api_key) - 10) if len(api_key) > 10 else '*' * len(api_key)
            print(f"   ğŸ”‘ API Key: {masked_value}")
        
        # æ˜¾ç¤ºæ¨¡å‹é…ç½®
        model_configs = []
        if 'SPLIT_MODEL' in config_info:
            model_configs.append(f"æ–­å¥: {config_info['SPLIT_MODEL']}")
        if 'TRANSLATION_MODEL' in config_info:
            model_configs.append(f"ç¿»è¯‘: {config_info['TRANSLATION_MODEL']}")
        if 'SUMMARY_MODEL' in config_info:
            model_configs.append(f"æ€»ç»“: {config_info['SUMMARY_MODEL']}")
        if 'LLM_MODEL' in config_info:
            model_configs.append(f"é»˜è®¤: {config_info['LLM_MODEL']}")
        
        if model_configs:
            print("   ğŸ¤– æ¨¡å‹é…ç½®:")
            for model_config in model_configs:
                print(f"      â€¢ {model_config}")
        
        # æ˜¾ç¤ºå…¶ä»–é…ç½®
        other_configs = []
        for key, value in config_info.items():
            if key not in ['OPENAI_BASE_URL', 'OPENAI_API_KEY', 'SPLIT_MODEL', 'TRANSLATION_MODEL', 'SUMMARY_MODEL', 'LLM_MODEL']:
                if key == 'HF_ENDPOINT' and value:
                    other_configs.append(f"ğŸ—ï¸  HF é•œåƒç«™: {value}")
                else:
                    other_configs.append(f"{key}: {value}")
        
        if other_configs:
            print("   âš™ï¸  å…¶ä»–é…ç½®:")
            for other_config in other_configs:
                print(f"      â€¢ {other_config}")
                
    except Exception as e:
        print(f"âš ï¸  è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")


def _copy_config_with_validation(source_path: Path, target_path: Path):
    """éªŒè¯å¹¶å¤åˆ¶é…ç½®æ–‡ä»¶"""
    # å…ˆéªŒè¯ç°æœ‰é…ç½®
    print("\nğŸ” [bold blue]æ­£åœ¨éªŒè¯é…ç½®...[/bold blue]")
    validation_success = validate_existing_config_and_return_result(source_path)
    
    if not validation_success:
        print("\nâš ï¸  [bold yellow]é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œç½‘ç»œè¿æ¥[/bold yellow]")
        continue_response = safe_prompt_operation("æ˜¯å¦ä»ç„¶å¤åˆ¶é…ç½®? (y/N)", default="n", show_default=False).lower()
        if continue_response not in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
            print("âŒ é…ç½®å¤åˆ¶å·²å–æ¶ˆ")
            raise typer.Exit(code=1)
    
    # éªŒè¯é€šè¿‡åå†å¤åˆ¶
    try:
        import shutil
        shutil.copy2(source_path, target_path)
        print(f"\nâœ… [bold green]é…ç½®å·²ä¿å­˜åˆ°:[/bold green] [cyan]{target_path}[/cyan]")
        print("\nğŸ‰ [bold green]é…ç½®å®Œæˆï¼ç°åœ¨ä½ å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ translate å‘½ä»¤ï¼[/bold green]")
        
    except Exception as e:
        print(f"[bold red]âŒ å¤åˆ¶å¤±è´¥: {e}[/bold red]")
        raise typer.Exit(code=1)


def _save_config_immediately(global_env_path: Path, base_url: str, api_key: str, 
                           split_model: str, translation_model: str, summary_model: str, 
                           llm_model: str, hf_endpoint: str = None):
    """ç«‹å³ä¿å­˜é…ç½®æ–‡ä»¶"""
    # ç”Ÿæˆé…ç½®æ–‡ä»¶å†…å®¹
    hf_endpoint_config = f"\n# Hugging Face é•œåƒç«™åœ°å€ (ç”¨äºæ¨¡å‹ä¸‹è½½)\n# ç•™ç©ºä½¿ç”¨é»˜è®¤å®˜æ–¹åœ°å€ï¼Œè®¾ç½®åå¯æé«˜å›½å†…ä¸‹è½½æˆåŠŸç‡\nHF_ENDPOINT={hf_endpoint or ''}\n" if hf_endpoint else "\n# Hugging Face é•œåƒç«™åœ°å€ (ç”¨äºæ¨¡å‹ä¸‹è½½)\n# å–æ¶ˆæ³¨é‡Šå¹¶è®¾ç½®é•œåƒç«™å¯æé«˜å›½å†…ä¸‹è½½æˆåŠŸç‡\n# HF_ENDPOINT=https://hf-mirror.com\n"
    
    config_content = f"""# Subtitle Translator é…ç½®æ–‡ä»¶
# ç”± translate init å‘½ä»¤è‡ªåŠ¨ç”Ÿæˆ

# ======== API é…ç½® ========
# API åŸºç¡€URL
OPENAI_BASE_URL={base_url}

# API å¯†é’¥
OPENAI_API_KEY={api_key}
{hf_endpoint_config}
# ======== æ¨¡å‹é…ç½® ========
# æ–­å¥æ¨¡å‹ - è´Ÿè´£å°†é•¿å¥åˆ†å‰²æˆé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥
SPLIT_MODEL={split_model}

# ç¿»è¯‘æ¨¡å‹ - è´Ÿè´£å°†å­—å¹•ç¿»è¯‘æˆç›®æ ‡è¯­è¨€
TRANSLATION_MODEL={translation_model}

# æ€»ç»“æ¨¡å‹ - è´Ÿè´£åˆ†æå­—å¹•å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
SUMMARY_MODEL={summary_model}

# å…¼å®¹æ€§ï¼šé»˜è®¤æ¨¡å‹ (å¦‚æœä¸Šè¿°æ¨¡å‹æœªè®¾ç½®ï¼Œå°†ä½¿ç”¨æ­¤æ¨¡å‹)
LLM_MODEL={llm_model}

# ======== ä½¿ç”¨è¯´æ˜ ========
# 1. ä½ ç°åœ¨å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ translate å‘½ä»¤
# 2. å¦‚éœ€ä¿®æ”¹é…ç½®ï¼Œå¯ä»¥ç¼–è¾‘æ­¤æ–‡ä»¶æˆ–é‡æ–°è¿è¡Œ translate init
# 3. åˆ†åˆ«é…ç½®çš„æ¨¡å‹ä¼šä¼˜å…ˆä½¿ç”¨ï¼Œå¦‚æœªè®¾ç½®åˆ™å›é€€åˆ° LLM_MODEL
# 4. HF_ENDPOINT ç”¨äºè®¾ç½® Hugging Face é•œåƒç«™ï¼Œå¯æé«˜æ¨¡å‹ä¸‹è½½æˆåŠŸç‡
"""
    
    # ä¿å­˜åˆ°å…¨å±€é…ç½®
    try:
        with open(global_env_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        print(f"\nâœ… [bold green]é…ç½®å·²ä¿å­˜åˆ°:[/bold green] [cyan]{global_env_path}[/cyan]")
        return True
        
    except Exception as e:
        print(f"[bold red]âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}[/bold red]")
        return False


def _execute_predownload():
    """æ‰§è¡Œè½¬å½•æ¨¡å‹é¢„ä¸‹è½½ï¼ˆä¸æ˜¾ç¤ºä»‹ç»ä¿¡æ¯å’Œè¯¢é—®ï¼‰"""
    print("\nğŸ“¥ [bold blue]å¼€å§‹é¢„ä¸‹è½½é»˜è®¤è½¬å½•æ¨¡å‹...[/bold blue]")
    
    # ğŸ¯ å…³é”®ä¿®å¤ï¼šé‡æ–°åŠ è½½å…¨å±€é…ç½®ç¯å¢ƒå˜é‡
    from dotenv import load_dotenv
    global_env_path = get_global_env_path()
    if global_env_path.exists():
        load_dotenv(global_env_path, override=True)
        print("ğŸ”„ [dim]å·²é‡æ–°åŠ è½½å…¨å±€é…ç½®ç¯å¢ƒå˜é‡[/dim]")
    
    # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„ä¸‹è½½ç«¯ç‚¹
    import os
    current_hf_endpoint = os.getenv("HF_ENDPOINT", "https://huggingface.co")
    if current_hf_endpoint and current_hf_endpoint.strip() and current_hf_endpoint != "https://huggingface.co":
        print(f"ğŸ—ï¸  [cyan]ä½¿ç”¨é…ç½®çš„é•œåƒç«™: {current_hf_endpoint}[/cyan]")
    else:
        print("ğŸŒ [dim]ä½¿ç”¨å®˜æ–¹åœ°å€ä¸‹è½½[/dim]")
    
    try:
        default_model = "mlx-community/parakeet-tdt-0.6b-v2"
        
        # å°è¯•é¢„ä¸‹è½½æ¨¡å‹
        from_pretrained(default_model, show_progress=True)
        print("âœ… [bold green]é»˜è®¤è½¬å½•æ¨¡å‹é¢„ä¸‹è½½æˆåŠŸï¼[/bold green]")
        return True
        
    except Exception as e:
        print(f"âš ï¸  [bold yellow]æ¨¡å‹é¢„ä¸‹è½½å¤±è´¥: {e}[/bold yellow]")
        print("ğŸ’¡ [dim]ä¸ç”¨æ‹…å¿ƒï¼Œé…ç½®å·²ä¿å­˜æˆåŠŸï¼Œé¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹[/dim]")
        return False


def _handle_predownload():
    """å¤„ç†è½¬å½•æ¨¡å‹é¢„ä¸‹è½½"""
    print("\nğŸ¤– [bold blue]è½¬å½•æ¨¡å‹é¢„ä¸‹è½½[/bold blue]")
    print("å­—å¹•ç¿»è¯‘å·¥å…·éœ€è¦ä¸‹è½½è½¬å½•æ¨¡å‹æ¥å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼š")
    print("â€¢ é»˜è®¤æ¨¡å‹ï¼šmlx-community/parakeet-tdt-0.6b-v2")
    print("â€¢ æ¨¡å‹å¤§å°ï¼šçº¦ 1.2GB")
    print("â€¢ é¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œä½†å¯èƒ½å½±å“å¤„ç†é€Ÿåº¦")
    
    predownload_response = safe_prompt("\nğŸ“¥ æ˜¯å¦ç°åœ¨é¢„ä¸‹è½½é»˜è®¤è½¬å½•æ¨¡å‹? (y/N)", default="y", show_default=False).lower()
    should_predownload = predownload_response in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']
    
    if should_predownload:
        print("\nğŸ“¥ [bold blue]å¼€å§‹é¢„ä¸‹è½½é»˜è®¤è½¬å½•æ¨¡å‹...[/bold blue]")
        
        # ğŸ¯ å…³é”®ä¿®å¤ï¼šé‡æ–°åŠ è½½å…¨å±€é…ç½®ç¯å¢ƒå˜é‡
        from dotenv import load_dotenv
        global_env_path = get_global_env_path()
        if global_env_path.exists():
            load_dotenv(global_env_path, override=True)
            print("ğŸ”„ [dim]å·²é‡æ–°åŠ è½½å…¨å±€é…ç½®ç¯å¢ƒå˜é‡[/dim]")
        
        # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„ä¸‹è½½ç«¯ç‚¹
        import os
        current_hf_endpoint = os.getenv("HF_ENDPOINT", "https://huggingface.co")
        if current_hf_endpoint and current_hf_endpoint.strip() and current_hf_endpoint != "https://huggingface.co":
            print(f"ğŸ—ï¸  [cyan]ä½¿ç”¨é…ç½®çš„é•œåƒç«™: {current_hf_endpoint}[/cyan]")
        else:
            print("ğŸŒ [dim]ä½¿ç”¨å®˜æ–¹åœ°å€ä¸‹è½½[/dim]")
        
        try:
            default_model = "mlx-community/parakeet-tdt-0.6b-v2"
            
            # å°è¯•é¢„ä¸‹è½½æ¨¡å‹
            from_pretrained(default_model, show_progress=True)
            print("âœ… [bold green]é»˜è®¤è½¬å½•æ¨¡å‹é¢„ä¸‹è½½æˆåŠŸï¼[/bold green]")
            return True
            
        except Exception as e:
            print(f"âš ï¸  [bold yellow]æ¨¡å‹é¢„ä¸‹è½½å¤±è´¥: {e}[/bold yellow]")
            print("ğŸ’¡ [dim]ä¸ç”¨æ‹…å¿ƒï¼Œé…ç½®å·²ä¿å­˜æˆåŠŸï¼Œé¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹[/dim]")
            return False
    else:
        print("\nâ­ï¸  [dim]è·³è¿‡æ¨¡å‹é¢„ä¸‹è½½ï¼Œé¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½[/dim]")
        return True


def _display_config_summary(base_url: str, api_key: str, hf_endpoint: str, 
                          split_model: str, translation_model: str, summary_model: str, 
                          llm_model: str, use_separate_models: bool):
    """æ˜¾ç¤ºé…ç½®æ‘˜è¦"""
    print("\nğŸ“‹ [bold green]é…ç½®æ‘˜è¦:[/bold green]")
    print(f"   ğŸŒ API URL: {base_url}")
    print(f"   ğŸ”‘ API Key: {api_key[:10]}{'*' * (len(api_key) - 10)}")
    if hf_endpoint:
        print(f"   ğŸ—ï¸  HF é•œåƒç«™: [cyan]{hf_endpoint}[/cyan]")
    else:
        print(f"   ğŸ—ï¸  HF é•œåƒç«™: [dim]é»˜è®¤å®˜æ–¹åœ°å€[/dim]")
    if use_separate_models:
        print(f"   ğŸ”¤ æ–­å¥æ¨¡å‹: [cyan]{split_model}[/cyan]")
        print(f"   ğŸŒ ç¿»è¯‘æ¨¡å‹: [cyan]{translation_model}[/cyan]")
        print(f"   ğŸ“Š æ€»ç»“æ¨¡å‹: [cyan]{summary_model}[/cyan]")
        print(f"   ğŸ¤– é»˜è®¤æ¨¡å‹: [cyan]{llm_model}[/cyan]")
    else:
        print(f"   ğŸ¤– ç»Ÿä¸€æ¨¡å‹: [cyan]{llm_model}[/cyan]")


def _interactive_config_input(global_env_path: Path):
    """äº¤äº’å¼è¾“å…¥é…ç½®"""
    import sys
    
    # æ£€æŸ¥æ˜¯å¦åœ¨äº¤äº’å¼ç»ˆç«¯ä¸­
    if not sys.stdin.isatty():
        print("[bold red]âŒ å½“å‰ä¸åœ¨äº¤äº’å¼ç»ˆç«¯ä¸­ï¼Œæ— æ³•è¿›è¡Œé…ç½®è¾“å…¥[/bold red]")
        print("è¯·åœ¨æ”¯æŒäº¤äº’è¾“å…¥çš„ç»ˆç«¯ä¸­è¿è¡Œæ­¤å‘½ä»¤ï¼Œæˆ–æ‰‹åŠ¨åˆ›å»ºé…ç½®æ–‡ä»¶ï¼š")
        print(f"   é…ç½®æ–‡ä»¶è·¯å¾„: [cyan]{global_env_path}[/cyan]")
        print("   å¯å‚è€ƒé¡¹ç›®æ ¹ç›®å½•çš„ env.example æ–‡ä»¶")
        raise typer.Exit(code=1)
    
    base_url = safe_prompt("ğŸŒ APIåŸºç¡€URL")
    
    # APIå¯†é’¥
    api_key = safe_prompt("ğŸ”‘ APIå¯†é’¥")
    
    if not api_key.strip():
        print("[bold red]âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º[/bold red]")
        raise typer.Exit(code=1)

    # Hugging Face é•œåƒç«™é…ç½®
    print("\nğŸ—ï¸  [bold blue]Hugging Face ä¸‹è½½é…ç½®[/bold blue]")
    print("ä¸ºäº†æé«˜æ¨¡å‹ä¸‹è½½æˆåŠŸç‡ï¼Œå¯ä»¥é…ç½®é•œåƒç«™ï¼š")
    print("â€¢ å®˜æ–¹åœ°å€ï¼šhttps://huggingface.co (é»˜è®¤)")
    print("â€¢ é•œåƒç«™ï¼šhttps://hf-mirror.com (æ¨èå›½å†…ç”¨æˆ·)")
    
    hf_endpoint_response = safe_prompt("ğŸŒ æ˜¯å¦ä½¿ç”¨ Hugging Face é•œåƒç«™? (y/N)", default="n", show_default=False).lower()
        
    use_hf_mirror = hf_endpoint_response in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']
    
    if use_hf_mirror:
        # æä¾›å‡ ä¸ªé•œåƒç«™é€‰æ‹©
        print("\nğŸ“‹ å¯é€‰é•œåƒç«™ï¼š")
        print("1. https://hf-mirror.com (æ¨è)")
        print("2. https://huggingface.co (å®˜æ–¹ï¼Œé»˜è®¤)")
        print("3. æ‰‹åŠ¨è¾“å…¥å…¶ä»–é•œåƒç«™")
        
        mirror_choice = safe_prompt("è¯·é€‰æ‹©é•œåƒç«™ (1-3)", default="1", show_default=False)
        
        if mirror_choice == "1":
            hf_endpoint = "https://hf-mirror.com"
        elif mirror_choice == "2":
            hf_endpoint = "https://huggingface.co"
        elif mirror_choice == "3":
            hf_endpoint = safe_prompt("è¯·è¾“å…¥é•œåƒç«™åœ°å€")
        else:
            hf_endpoint = "https://hf-mirror.com"  # é»˜è®¤ä½¿ç”¨æ¨èé•œåƒç«™
    else:
        hf_endpoint = None

    print("\nğŸ¤– [bold blue]æ¨¡å‹é…ç½®[/bold blue]")
    print("å­—å¹•ç¿»è¯‘å·¥å…·æ”¯æŒä¸ºä¸åŒåŠŸèƒ½ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ï¼š")
    print("â€¢ æ–­å¥æ¨¡å‹ï¼šå°†é•¿å¥åˆ†å‰²æˆé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥")
    print("â€¢ ç¿»è¯‘æ¨¡å‹ï¼šç¿»è¯‘å­—å¹•å†…å®¹")
    print("â€¢ æ€»ç»“æ¨¡å‹ï¼šåˆ†æå­—å¹•å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦")
    
    # è¯¢é—®æ˜¯å¦è¦åˆ†åˆ«é…ç½®æ¨¡å‹
    separate_models_response = safe_prompt("\nğŸ”§ æ˜¯å¦ä¸ºä¸åŒåŠŸèƒ½åˆ†åˆ«é…ç½®æ¨¡å‹? (y/N)", default="y", show_default=False).lower()
    use_separate_models = separate_models_response in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']
    
    if use_separate_models:
        # åˆ†åˆ«é…ç½®ä¸‰ä¸ªæ¨¡å‹
        print("\nğŸ”¤ [bold yellow]æ–­å¥æ¨¡å‹é…ç½®[/bold yellow]")
        split_model = safe_prompt("æ–­å¥æ¨¡å‹")
        while not split_model.strip():
            print("âŒ æ–­å¥æ¨¡å‹ä¸èƒ½ä¸ºç©º")
            split_model = safe_prompt("æ–­å¥æ¨¡å‹")
        
        print("\nğŸŒ [bold yellow]ç¿»è¯‘æ¨¡å‹é…ç½®[/bold yellow]")
        translation_model = safe_prompt("ç¿»è¯‘æ¨¡å‹")
        while not translation_model.strip():
            print("âŒ ç¿»è¯‘æ¨¡å‹ä¸èƒ½ä¸ºç©º")
            translation_model = safe_prompt("ç¿»è¯‘æ¨¡å‹")
        
        print("\nğŸ“Š [bold yellow]æ€»ç»“æ¨¡å‹é…ç½®[/bold yellow]")
        summary_model = safe_prompt("æ€»ç»“æ¨¡å‹")
        while not summary_model.strip():
            print("âŒ æ€»ç»“æ¨¡å‹ä¸èƒ½ä¸ºç©º")
            summary_model = safe_prompt("æ€»ç»“æ¨¡å‹")
        
        # å…¼å®¹æ€§é»˜è®¤æ¨¡å‹
        llm_model = split_model
    else:
        print("\nğŸ¤– [bold yellow]ç»Ÿä¸€æ¨¡å‹é…ç½®[/bold yellow]")
        llm_model = safe_prompt("LLMæ¨¡å‹")
        while not llm_model.strip():
            print("âŒ LLMæ¨¡å‹ä¸èƒ½ä¸ºç©º")
            llm_model = safe_prompt("LLMæ¨¡å‹")
        
        # ç»Ÿä¸€ä½¿ç”¨ä¸€ä¸ªæ¨¡å‹
        split_model = llm_model
        translation_model = llm_model
        summary_model = llm_model
    
    # éªŒè¯é…ç½®
    print("\nğŸ” [bold blue]æ­£åœ¨éªŒè¯ API é…ç½®...[/bold blue]")
    
    # è·å–æ‰€æœ‰éœ€è¦éªŒè¯çš„æ¨¡å‹
    unique_models = {}
    unique_models['æ–­å¥æ¨¡å‹'] = split_model
    unique_models['ç¿»è¯‘æ¨¡å‹'] = translation_model
    unique_models['æ€»ç»“æ¨¡å‹'] = summary_model
    unique_models['é»˜è®¤æ¨¡å‹'] = llm_model
        
    # å»é‡ï¼šåªæµ‹è¯•ä¸åŒçš„æ¨¡å‹
    tested_models = set()
    validation_results = []
    
    for model_type, model_name in unique_models.items():
        if model_name not in tested_models:
            print(f"ğŸ”Œ æµ‹è¯• {model_name}...")
            success, message = test_openai(base_url, api_key, model_name)
            tested_models.add(model_name)
            
            validation_results.append({
                'model': model_name,
                'success': success,
                'message': message,
                'types': [model_type]
            })
        else:
            # å¦‚æœæ¨¡å‹å·²ç»æµ‹è¯•è¿‡ï¼Œæ‰¾åˆ°ä¹‹å‰çš„ç»“æœå¹¶æ·»åŠ ç±»å‹
            for result in validation_results:
                if result['model'] == model_name:
                    result['types'].append(model_type)
                    break
    
    # æ˜¾ç¤ºéªŒè¯ç»“æœ
    print("\nğŸ“Š [bold blue]éªŒè¯ç»“æœ:[/bold blue]")
    all_success = True
    
    for result in validation_results:
        model_types = 'ã€'.join(result['types'])
        if result['success']:
            print(f"   âœ… {result['model']} ({model_types})")
            print(f"      å“åº”: {result['message'][:60]}...")
        else:
            print(f"   âŒ {result['model']} ({model_types})")
            print(f"      é”™è¯¯: {result['message']}")
            all_success = False
    
    if not all_success:
        print("\nâš ï¸  [bold yellow]éƒ¨åˆ†æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œç½‘ç»œè¿æ¥[/bold yellow]")
        continue_response = safe_prompt("æ˜¯å¦ç»§ç»­ä¿å­˜é…ç½®? (y/N)", default="n", show_default=False).lower()
        if continue_response not in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
            print("âŒ é…ç½®ä¿å­˜å·²å–æ¶ˆ")
            raise typer.Exit(code=1)
    
    # ğŸ¯ å…³é”®æ”¹è¿›ï¼šAPIéªŒè¯é€šè¿‡åç«‹å³ä¿å­˜é…ç½®
    print("\nğŸ’¾ [bold blue]ä¿å­˜é…ç½®æ–‡ä»¶...[/bold blue]")
    config_saved = _save_config_immediately(global_env_path, base_url, api_key, 
                                           split_model, translation_model, summary_model, 
                                           llm_model, hf_endpoint)
    
    if not config_saved:
        print("[bold red]âŒ é…ç½®ä¿å­˜å¤±è´¥ï¼Œæ— æ³•ç»§ç»­[/bold red]")
        raise typer.Exit(code=1)
    
    # æ˜¾ç¤ºé…ç½®æ‘˜è¦
    _display_config_summary(base_url, api_key, hf_endpoint, split_model, 
                           translation_model, summary_model, llm_model, use_separate_models)
    
    # å¤„ç†è½¬å½•æ¨¡å‹é¢„ä¸‹è½½ (ç‹¬ç«‹æ­¥éª¤ï¼Œå¤±è´¥ä¸å½±å“é…ç½®)
    print("\n" + "="*50)
    predownload_success = _handle_predownload()
    
    # æœ€ç»ˆçŠ¶æ€æç¤º
    if predownload_success:
        print("\nğŸ‰ [bold green]é…ç½®å®Œæˆä¸”æ¨¡å‹é¢„ä¸‹è½½æˆåŠŸï¼ç°åœ¨ä½ å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ translate å‘½ä»¤ï¼[/bold green]")
    else:
        print("\nğŸ‰ [bold green]é…ç½®å·²å®Œæˆï¼ç°åœ¨ä½ å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ translate å‘½ä»¤ï¼[/bold green]")
        print("ğŸ’¡ [dim]è½¬å½•æ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½[/dim]") 