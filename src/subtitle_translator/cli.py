"""
ä¸»å‘½ä»¤è¡Œæ¥å£æ¨¡å— - ç®€æ´æ¸…æ™°çš„CLIå…¥å£
"""
import glob
import re
import typer
from pathlib import Path
from typing import Optional
from typing_extensions import Annotated

from rich import print

from .env_setup import setup_environment
from .processor import process_single_file
from .config_manager import init_config
from .logger import setup_logger, get_log_file_path, get_log_mode_info
from .transcription_core.utils import _find_cached_model, _check_network_connectivity, from_pretrained
from .transcription_core import utils as transcription_utils

# é»˜è®¤è½¬å½•æ¨¡å‹
DEFAULT_TRANSCRIPTION_MODEL = "mlx-community/parakeet-tdt-0.6b-v2"

# åˆå§‹åŒ–logger
logger = setup_logger(__name__)


app = typer.Typer(
    help="ä¸€ä¸ªé›†æˆäº†è¯­éŸ³è½¬å½•ã€å­—å¹•ç¿»è¯‘å’Œæ ¼å¼è½¬æ¢çš„å‘½ä»¤è¡Œå·¥å…·",
    epilog="ğŸ’¡ é¦–æ¬¡ä½¿ç”¨è¯·è¿è¡Œ: translate init æ¥é…ç½®APIå¯†é’¥"
)


@app.callback(invoke_without_command=True)
def main(
    ctx: typer.Context,
    input_file: Optional[Path] = typer.Option(None, "--input-file", "-i", help="è¦å¤„ç†çš„å•ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œå¦‚ä¸æŒ‡å®šåˆ™æ‰¹é‡å¤„ç†å½“å‰ç›®å½•ã€‚", exists=True, file_okay=True, dir_okay=False, readable=True),
    max_count: int = typer.Option(-1, "--count", "-n", help="æœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡ï¼Œ-1è¡¨ç¤ºå¤„ç†æ‰€æœ‰æ–‡ä»¶ã€‚"),
    target_lang: str = typer.Option("zh", "--target_lang", "-t", help="ç›®æ ‡ç¿»è¯‘è¯­è¨€ã€‚æ”¯æŒï¼šzh/zh-cn(ç®€ä¸­), zh-tw(ç¹ä¸­), ja(æ—¥), ko(éŸ©), fr(æ³•), de(å¾·), es(è¥¿), pt(è‘¡), it(æ„), ru(ä¿„), ar(é˜¿), th(æ³°), vi(è¶Š)ç­‰ã€‚"),
    output_dir: Optional[Path] = typer.Option(None, "--output_dir", "-o", help="è¾“å‡ºæ–‡ä»¶çš„ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚"),
    model: str = typer.Option(DEFAULT_TRANSCRIPTION_MODEL, "--model", help="ç”¨äºè½¬å½•çš„ Parakeet MLX æ¨¡å‹ã€‚"),
    llm_model: Optional[str] = typer.Option(None, "--llm-model", "-m", help="ç”¨äºç¿»è¯‘çš„LLMæ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ã€‚"),
    preserve_intermediate: bool = typer.Option(False, "--preserve-intermediate", "-p", help="ä¿ç•™ä¸­é—´çš„è‹±æ–‡å’Œç›®æ ‡è¯­è¨€SRTæ–‡ä»¶ï¼Œä¾¿äºè¿›ä¸€æ­¥å¤„ç†æˆ–è°ƒè¯•ã€‚"),
    version: bool = typer.Option(False, "--version", help="æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯å¹¶é€€å‡ºã€‚"),
):
    """å­—å¹•ç¿»è¯‘å·¥å…·ä¸»å‘½ä»¤"""
    # å¤„ç†ç‰ˆæœ¬ä¿¡æ¯è¯·æ±‚
    if version:
        from .version_utils import get_simple_version_info
        print(get_simple_version_info())
        raise typer.Exit()

    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return

    setup_environment()
    
    # æ˜¾ç¤ºæ—¥å¿—æ–‡ä»¶è·¯å¾„ä¿¡æ¯
    log_mode, log_location = get_log_mode_info()
    log_path = get_log_file_path()
    print(f"ğŸ“ [dim]æ—¥å¿—æ¨¡å¼: {log_mode} ({log_location})[/dim]")
    print(f"ğŸ“ [dim]æ—¥å¿—æ–‡ä»¶: {log_path}[/dim]")
    print()  # ç©ºè¡Œåˆ†éš”
    
    # æ—©æœŸéªŒè¯ç›®æ ‡è¯­è¨€ä»£ç ï¼Œæä¾›å‹å¥½é”™è¯¯ä¿¡æ¯
    try:
        _validate_target_language(target_lang)
    except ValueError as e:
        logger.error(f"âŒ å‘½ä»¤è¡Œå‚æ•°é”™è¯¯ - ç›®æ ‡è¯­è¨€: {str(e)}")
        print(f"[bold red]âŒ ç›®æ ‡è¯­è¨€å‚æ•°é”™è¯¯![/bold red]")
        print(str(e))
        print(f"\nğŸ’¡ [bold blue]ä½¿ç”¨ç¤ºä¾‹:[/bold blue]")
        print(f"   translate -t zh     # ç®€ä½“ä¸­æ–‡ï¼ˆé»˜è®¤ï¼‰")
        print(f"   translate -t ja     # æ—¥æ–‡")
        print(f"   translate -t ko     # éŸ©æ–‡")
        print(f"   translate -t fr     # æ³•æ–‡")
        raise typer.Exit(code=1)

    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = Path.cwd()
    
    output_dir = output_dir.resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    # è·å–è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    if input_file:
        files_to_process = [input_file]
        logger.info(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: {input_file.name}")
        print(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: [bold cyan]{input_file.name}[/bold cyan]")
    else:
        files_to_process = _get_batch_files(max_count, llm_model)

    # æ‰¹é‡å¤„ç†æ–‡ä»¶
    _process_files_batch(files_to_process, target_lang, output_dir, model, llm_model, preserve_intermediate)


def _validate_target_language(target_lang: str):
    """éªŒè¯ç›®æ ‡è¯­è¨€ä»£ç """
    from .translation_core.config import get_target_language
    target_language_name = get_target_language(target_lang)
    print(f"ğŸ¯ [bold green]ç›®æ ‡è¯­è¨€:[/bold green] [cyan]{target_language_name}[/cyan] ([dim]{target_lang}[/dim])")


def _natural_sort_key(s: str):
    """ç”¨äºè‡ªç„¶æ’åºçš„keyå‡½æ•°ï¼šå°†æ•°å­—ç‰‡æ®µæŒ‰æ•´æ•°æ¯”è¾ƒï¼Œå…¶ä»–ç‰‡æ®µæŒ‰ä¸åŒºåˆ†å¤§å°å†™çš„å­—ç¬¦ä¸²æ¯”è¾ƒ"""
    parts = re.split(r"(\d+)", s)
    return [int(p) if p.isdigit() else p.casefold() for p in parts]


def _get_batch_files(max_count: int, llm_model: Optional[str]) -> list:
    """è·å–æ‰¹é‡å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨"""
    MEDIA_EXTENSIONS = [
        "*.srt",  # å­—å¹•æ–‡ä»¶
        # éŸ³é¢‘æ ¼å¼ï¼ˆä¼˜å…ˆçº§é«˜äºè§†é¢‘ï¼‰
        "*.mp3", "*.m4a", "*.wav", "*.flac", "*.aac",
        "*.ogg", "*.wma", "*.aiff", "*.opus",
        # è§†é¢‘æ ¼å¼
        "*.mp4", "*.avi", "*.mov", "*.mkv", "*.webm",
        "*.flv", "*.wmv", "*.m4v", "*.mpeg", "*.mpg",
        "*.3gp", "*.ts"
    ]

    # æŸ¥æ‰¾æ‰€æœ‰åª’ä½“æ–‡ä»¶
    media_files = []
    for pattern in MEDIA_EXTENSIONS:
        media_files.extend(glob.glob(pattern))
    
    if not media_files:
        print("[bold red]å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„åª’ä½“æ–‡ä»¶ã€‚[/bold red]")
        print("[dim]æ”¯æŒçš„æ ¼å¼ï¼š[/dim]")
        print("[dim]  â€¢ å­—å¹•æ–‡ä»¶: .srt[/dim]")
        print("[dim]  â€¢ éŸ³é¢‘æ–‡ä»¶: .mp3, .m4a, .wav, .flac, .aac, .ogg, .wma, .aiff, .opus[/dim]")
        print("[dim]  â€¢ è§†é¢‘æ–‡ä»¶: .mp4, .avi, .mov, .mkv, .webm, .flv, .wmv, .m4v, .mpeg, .mpg, .3gp, .ts[/dim]")
        raise typer.Exit(code=1)
    
    # æå–åŸºç¡€æ–‡ä»¶åå¹¶å»é‡æ’åº
    base_names = set()
    for file in media_files:
        # ç§»é™¤æ‰©å±•å
        base_name = re.sub(
            r'\.(srt|mp3|m4a|wav|flac|aac|ogg|wma|aiff|opus|'
            r'mp4|avi|mov|mkv|webm|flv|wmv|m4v|mpeg|mpg|3gp|ts)$',
            '', file, flags=re.IGNORECASE
        )
        # ç§»é™¤å„ç§è¯­è¨€åç¼€
        language_suffixes = [
            r'\.zh$', r'\.zh-cn$', r'\.zh-tw$',  # ä¸­æ–‡
            r'\.ja$', r'\.ko$', r'\.th$', r'\.vi$',  # äºšæ´²è¯­è¨€
            r'\.fr$', r'\.de$', r'\.es$', r'\.pt$', r'\.it$', r'\.ru$',  # æ¬§æ´²è¯­è¨€
            r'\.ar$', r'\.en$'  # å…¶ä»–
        ]
        for suffix_pattern in language_suffixes:
            base_name = re.sub(suffix_pattern, '', base_name)
        base_names.add(base_name)
    
    # è‡ªç„¶æ’åºåŸºç¡€æ–‡ä»¶åï¼ˆEP2 åœ¨ EP10 ä¹‹å‰ï¼‰
    base_names = sorted(base_names, key=_natural_sort_key)
    
    # ä¸ºæ¯ä¸ªåŸºç¡€åç§°æ‰¾åˆ°å¯¹åº”çš„è¾“å…¥æ–‡ä»¶
    files_to_process = []
    for base_name in base_names:
        # è·³è¿‡å·²å­˜åœ¨.assæ–‡ä»¶çš„
        ass_file = Path(f"{base_name}.ass")
        if ass_file.exists():
            print(f"INFO: {base_name}.ass å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†ã€‚")
            continue
        
        # ç¡®å®šè¾“å…¥æ–‡ä»¶ä¼˜å…ˆçº§ï¼šsrt > éŸ³é¢‘ > è§†é¢‘ï¼ˆéŸ³é¢‘è½¬å½•æ›´å¿«ï¼‰
        input_file_found = None
        # éŸ³é¢‘æ ¼å¼åˆ—è¡¨ï¼ˆæŒ‰å¸¸ç”¨ç¨‹åº¦æ’åºï¼‰
        audio_exts = ['.mp3', '.m4a', '.wav', '.flac', '.aac',
                      '.ogg', '.wma', '.aiff', '.opus']
        # è§†é¢‘æ ¼å¼åˆ—è¡¨ï¼ˆæŒ‰å¸¸ç”¨ç¨‹åº¦æ’åºï¼‰
        video_exts = ['.mp4', '.avi', '.mov', '.mkv', '.webm',
                      '.flv', '.wmv', '.m4v', '.mpeg', '.mpg',
                      '.3gp', '.ts']

        for ext in ['.srt'] + audio_exts + video_exts:
            candidate = Path(f"{base_name}{ext}")
            if candidate.exists():
                input_file_found = candidate
                break
        
        if input_file_found:
            files_to_process.append(input_file_found)
            print(f"ğŸ“„ å‘ç°æ–‡ä»¶ [cyan]{input_file_found}[/cyan]")
        else:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ° [yellow]{base_name}[/yellow] çš„è¾“å…¥æ–‡ä»¶")
    
    if not files_to_process:
        print("[bold yellow]æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–°æ–‡ä»¶ã€‚[/bold yellow]")
        raise typer.Exit(code=0)
    
    # åº”ç”¨æ•°é‡é™åˆ¶
    if max_count > 0:
        files_to_process = files_to_process[:max_count]
    
    print(f"[bold green]å¼€å§‹æ‰¹é‡ç¿»è¯‘å¤„ç†ï¼Œå…±{len(files_to_process)}ä¸ªæ–‡ä»¶...[/bold green]")
    if llm_model:
        print(f"ä½¿ç”¨LLMæ¨¡å‹: [bold cyan]{llm_model}[/bold cyan]")
    
    return files_to_process


def _process_files_batch(files_to_process: list, target_lang: str, output_dir: Path,
                        model: str, llm_model: Optional[str], preserve_intermediate: bool):
    """æ‰¹é‡å¤„ç†æ–‡ä»¶"""
    from .transcription_core.model_cache import model_context
    
    count = 0
    generated_ass_files = []
    
    # å…¨å±€é¢„æ£€æŸ¥è½¬å½•æ¨¡å‹ï¼ˆåªå¯¹éœ€è¦è½¬å½•çš„æ–‡ä»¶æ‰§è¡Œï¼‰
    model_precheck_passed = None
    needs_transcription = any(f.suffix.lower() != '.srt' for f in files_to_process)
    
    if needs_transcription:
        from .processor import precheck_model_availability
        print("[bold blue]>>> é¢„æ£€æŸ¥è½¬å½•ç¯å¢ƒ...[/bold blue]")
        model_precheck_passed = precheck_model_availability(model, show_progress=True)
        
        if not model_precheck_passed:
            print("[bold red]âŒ è½¬å½•æ¨¡å‹ä¸å¯ç”¨ï¼Œæ— æ³•å¤„ç†éœ€è¦è½¬å½•çš„æ–‡ä»¶[/bold red]")
            # è¿‡æ»¤æ‰éœ€è¦è½¬å½•çš„æ–‡ä»¶ï¼Œåªå¤„ç† .srt æ–‡ä»¶
            srt_files = [f for f in files_to_process if f.suffix.lower() == '.srt']
            if srt_files:
                print(f"[bold yellow]å°†åªå¤„ç† {len(srt_files)} ä¸ª SRT æ–‡ä»¶[/bold yellow]")
                files_to_process = srt_files
            else:
                print("[bold red]æ²¡æœ‰å¯å¤„ç†çš„ SRT æ–‡ä»¶ï¼Œé€€å‡ºæ‰¹é‡å¤„ç†[/bold red]")
                return
    
    # åœ¨æ‰¹é‡å¤„ç†å¼€å§‹æ—¶åˆå§‹åŒ–ç¿»è¯‘æœåŠ¡å¹¶æ˜¾ç¤ºé…ç½®ï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡ï¼‰
    from .service import SubtitleTranslatorService
    try:
        translator_service = SubtitleTranslatorService()
        translator_service._init_translation_env(llm_model, show_config=True)
        print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    except Exception as init_error:
        print(f"[bold red]åˆ›å»ºç¿»è¯‘æœåŠ¡å¤±è´¥:[/bold red] {init_error}")
        raise
    
    # æ ¹æ®æ–‡ä»¶æ•°é‡å†³å®šä½¿ç”¨æ‰¹é‡æ¨¡å¼è¿˜æ˜¯å•æ–‡ä»¶æ¨¡å¼
    is_batch_mode = len(files_to_process) > 1
    
    with model_context(batch_mode=is_batch_mode):
        for i, current_input_file in enumerate(files_to_process):
            print()
            logger.info(f"ğŸ¯ å¤„ç†æ–‡ä»¶ ({i+1}/{len(files_to_process)}): {current_input_file.name}")
            if is_batch_mode:
                print(f"ğŸ¯ [bold cyan]å¼€å§‹å¤„ç†ç¬¬ {i+1}/{len(files_to_process)} ä¸ªæ–‡ä»¶...[/bold cyan]")
            else:
                print(f"ğŸ¯ [bold cyan]å¼€å§‹å¤„ç†æ–‡ä»¶...[/bold cyan]")
            
            try:
                # æ ¹æ®å®é™…æƒ…å†µä¼ é€’æ‰¹é‡æ¨¡å¼æ ‡å¿—
                process_single_file(
                    current_input_file, target_lang, output_dir, model,
                    llm_model, model_precheck_passed,
                    batch_mode=is_batch_mode, translator_service=translator_service,
                    preserve_intermediate=preserve_intermediate
                )
                count += 1
                
                # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ASSæ–‡ä»¶
                ass_file = output_dir / f"{current_input_file.stem}.ass"
                if ass_file.exists():
                    generated_ass_files.append(ass_file)
                    logger.info(f"ğŸ“º åŒè¯­ASSæ–‡ä»¶å·²ç”Ÿæˆ: {ass_file.name}")
                    print(f"ğŸ“º [cyan]åŒè¯­ASSæ–‡ä»¶å·²ç”Ÿæˆ[/cyan]")
                
                logger.info(f"âœ… {current_input_file.stem} å¤„ç†å®Œæˆï¼")
                print(f"[bold green]âœ… å¤„ç†å®Œæˆï¼[/bold green]")
            
            except Exception as e:
                from .translation_core.spliter import SmartSplitError, TranslationError, SummaryError
                if isinstance(e, (SmartSplitError, TranslationError, SummaryError)):
                    # è¿™äº›å¼‚å¸¸å·²ç»åœ¨processor.pyä¸­æ˜¾ç¤ºè¿‡äº†ï¼Œè¿™é‡Œä¸é‡å¤æ˜¾ç¤º
                    # ä½†éœ€è¦è®°å½•åˆ°æ—¥å¿—ä¸­ç”¨äºç»Ÿè®¡
                    logger.info(f"âŒ {current_input_file.stem} å¤„ç†å¤±è´¥: {e}")
                else:
                    logger.error(f"âŒ {current_input_file.stem} å¤„ç†å¤±è´¥: {e}")
                    print(f"[bold red]âŒ {current_input_file.stem} å¤„ç†å¤±è´¥ï¼{e}[/bold red]")
            
            print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    
    # å¤„ç†å®Œæˆï¼Œæ˜¾ç¤ºæ¨¡å‹ä¼˜åŒ–ä¿¡æ¯
    if needs_transcription and count > 0:
        if is_batch_mode:
            print("ğŸ¯ [dim]æ‰¹é‡å¤„ç†å®Œæˆï¼Œæ¨¡å‹å·²è‡ªåŠ¨é‡Šæ”¾ï¼Œå†…å­˜å·²ä¼˜åŒ–[/dim]")
        else:
            print("ğŸ¯ [dim]å¤„ç†å®Œæˆï¼Œæ¨¡å‹å·²è‡ªåŠ¨é‡Šæ”¾ï¼Œå†…å­˜å·²ä¼˜åŒ–[/dim]")
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    _show_results(count, generated_ass_files, output_dir, is_batch_mode)


def _show_results(count: int, generated_ass_files: list, output_dir: Path, is_batch_mode: bool):
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    print()
    if is_batch_mode:
        logger.info("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        logger.info(f"æ€»è®¡å¤„ç†æ–‡ä»¶æ•°: {count}")
        print(f"ğŸ‰ [bold green]æ‰¹é‡å¤„ç†å®Œæˆï¼[/bold green] (å¤„ç† [cyan]{count}[/cyan] ä¸ªæ–‡ä»¶)")
    else:
        logger.info("ğŸ‰ å¤„ç†å®Œæˆï¼")
        logger.info(f"æ€»è®¡å¤„ç†æ–‡ä»¶æ•°: {count}")
        print(f"ğŸ‰ [bold green]å¤„ç†å®Œæˆï¼[/bold green] (å¤„ç† [cyan]{count}[/cyan] ä¸ªæ–‡ä»¶)")
    
    # åªæ˜¾ç¤ºæœ¬æ¬¡ç”Ÿæˆçš„ASSæ–‡ä»¶ç»Ÿè®¡
    if count > 0:
        if generated_ass_files:
            logger.info("æœ¬æ¬¡ç”Ÿæˆçš„ASSæ–‡ä»¶ï¼š")
            for f in generated_ass_files:
                logger.info(f"  {f.name}")
            print(f"ğŸ“º [bold green]å·²ç”Ÿæˆ {len(generated_ass_files)} ä¸ªåŒè¯­ASSæ–‡ä»¶[/bold green]")
        
        # è¿‡æ»¤æ‰è¯­è¨€ç‰¹å®šçš„SRTæ–‡ä»¶
        language_patterns = [
            '.zh.', '.zh-cn.', '.zh-tw.',  # ä¸­æ–‡
            '.ja.', '.ko.', '.th.', '.vi.',  # äºšæ´²è¯­è¨€
            '.fr.', '.de.', '.es.', '.pt.', '.it.', '.ru.',  # æ¬§æ´²è¯­è¨€
            '.ar.', '.en.'  # å…¶ä»–
        ]
        srt_files = [f for f in output_dir.glob("*.srt") if not any(pattern in f.name for pattern in language_patterns)]
        if srt_files:
            logger.info("åŸå§‹å­—å¹•æ–‡ä»¶ï¼š")
            for f in srt_files:
                logger.info(f"  {f.name}")
    
    logger.info("å¤„ç†å®Œæ¯•ï¼")


@app.command("model")
def model_cmd(
    ctx: typer.Context,
    action: str = typer.Argument(..., help="è¦æ‰§è¡Œçš„æ“ä½œ: list(åˆ—å‡ºå·²ç¼“å­˜æ¨¡å‹), info(æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯), download(é¢„ä¸‹è½½æ¨¡å‹), clean(æ¸…ç†ç¼“å­˜)"),
    model_id: Optional[str] = typer.Argument(None, help=f"æ¨¡å‹ID (downloadå’Œinfoæ“ä½œé»˜è®¤: {DEFAULT_TRANSCRIPTION_MODEL})")
):
    """æ¨¡å‹ç®¡ç†å‘½ä»¤"""
    from rich.console import Console
    from rich.table import Table
    from pathlib import Path
    import os
    import shutil
    
    console = Console()
    
    if action == "list":
        """åˆ—å‡ºå·²ç¼“å­˜çš„æ¨¡å‹"""
        try:
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
            cache_dir = Path(cache_dir) / "hub"
            
            if not cache_dir.exists():
                console.print("[yellow]ğŸ“‚ è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•æ¨¡å‹[/yellow]")
                return
            
            # æŸ¥æ‰¾æ¨¡å‹ç¼“å­˜ç›®å½•
            model_dirs = [d for d in cache_dir.iterdir() if d.is_dir() and d.name.startswith("models--")]
            
            if not model_dirs:
                console.print("[yellow]ğŸ“‚ è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•æ¨¡å‹[/yellow]")
                return
            
            # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            table = Table(title="ğŸ¤– å·²ç¼“å­˜çš„æ¨¡å‹åˆ—è¡¨")
            table.add_column("æ¨¡å‹ID", style="cyan")
            table.add_column("ç¼“å­˜å¤§å°", style="green")
            table.add_column("æœ€åä¿®æ”¹æ—¶é—´", style="dim")
            
            for model_dir in sorted(model_dirs):
                # è§£ææ¨¡å‹ID
                model_id = model_dir.name.replace("models--", "").replace("--", "/")
                
                # è®¡ç®—ç›®å½•å¤§å°
                total_size = sum(f.stat().st_size for f in model_dir.rglob('*') if f.is_file())
                size_mb = total_size / (1024 * 1024)
                
                # è·å–æœ€åä¿®æ”¹æ—¶é—´
                import datetime
                mtime = datetime.datetime.fromtimestamp(model_dir.stat().st_mtime)
                
                table.add_row(
                    model_id,
                    f"{size_mb:.1f} MB",
                    mtime.strftime("%Y-%m-%d %H:%M")
                )
            
            console.print(table)
            console.print(f"\nğŸ“ ç¼“å­˜ä½ç½®: [dim]{cache_dir}[/dim]")
            
        except Exception as e:
            console.print(f"[red]âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}[/red]")
    
    elif action == "info":
        """æ˜¾ç¤ºæŒ‡å®šæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = DEFAULT_TRANSCRIPTION_MODEL
            console.print(f"[dim]ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_id}[/dim]")
        
        try:
            # å°è¯•æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜
            try:
                config_path, weight_path = _find_cached_model(model_id)
                console.print(f"âœ… [green]æ¨¡å‹å·²ç¼“å­˜[/green]: [bold]{model_id}[/bold]")
                console.print(f"ğŸ“„ é…ç½®æ–‡ä»¶: [dim]{config_path}[/dim]")
                console.print(f"âš–ï¸  æƒé‡æ–‡ä»¶: [dim]{weight_path}[/dim]")
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                config_size = Path(config_path).stat().st_size / 1024
                weight_size = Path(weight_path).stat().st_size / (1024 * 1024)
                console.print(f"ğŸ“Š å¤§å°: é…ç½® {config_size:.1f} KB, æƒé‡ {weight_size:.1f} MB")
                
            except FileNotFoundError:
                console.print(f"[yellow]âš ï¸  æ¨¡å‹æœªç¼“å­˜[/yellow]: [bold]{model_id}[/bold]")
                console.print("ğŸ’¡ ä½ å¯ä»¥ä½¿ç”¨ 'translate model download' å‘½ä»¤é¢„ä¸‹è½½æ¨¡å‹")
                
                # æ£€æŸ¥ç½‘ç»œè¿æ¥
                if _check_network_connectivity():
                    console.print("ğŸŒ ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œæ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½")
                else:
                    console.print("[red]ğŸŒ ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹[/red]")
                    
        except Exception as e:
            console.print(f"[red]âŒ è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}[/red]")
    
    elif action == "download":
        """é¢„ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = DEFAULT_TRANSCRIPTION_MODEL
            console.print(f"[dim]ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_id}[/dim]")
        
        try:
            console.print(f"ğŸš€ å¼€å§‹é¢„ä¸‹è½½æ¨¡å‹: [bold]{model_id}[/bold]")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ç¼“å­˜
            try:
                _find_cached_model(model_id)
                console.print(f"âœ… [green]æ¨¡å‹å·²å­˜åœ¨äºæœ¬åœ°ç¼“å­˜[/green]")
                return
            except FileNotFoundError:
                pass
            
            # ä¸‹è½½æ¨¡å‹
            model = from_pretrained(model_id, show_progress=True)
            console.print(f"\nğŸ‰ [bold green]æ¨¡å‹é¢„ä¸‹è½½å®Œæˆ![/bold green]")
            console.print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜ï¼Œåç»­ä½¿ç”¨æ—¶å°†ç›´æ¥åŠ è½½")
            
        except Exception as e:
            console.print(f"[red]âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {str(e)}[/red]")
    
    elif action == "clean":
        """æ¸…ç†æ¨¡å‹ç¼“å­˜"""
        try:
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
            cache_dir = Path(cache_dir) / "hub"
            
            if not cache_dir.exists():
                console.print("[yellow]ğŸ“‚ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†[/yellow]")
                return
            
            # è®¡ç®—ç¼“å­˜å¤§å°
            total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())
            size_mb = total_size / (1024 * 1024)
            
            # è¯¢é—®ç¡®è®¤
            if size_mb > 0:
                console.print(f"âš ï¸  [yellow]å³å°†æ¸…ç† {size_mb:.1f} MB çš„æ¨¡å‹ç¼“å­˜[/yellow]")
                console.print(f"ğŸ“ ç¼“å­˜ä½ç½®: [dim]{cache_dir}[/dim]")
                
                confirm = typer.confirm("ç¡®å®šè¦æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜å—ï¼Ÿ")
                if not confirm:
                    console.print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return
                
                # æ¸…ç†ç¼“å­˜
                shutil.rmtree(cache_dir)
                console.print("âœ… [green]æ¨¡å‹ç¼“å­˜æ¸…ç†å®Œæˆ[/green]")
            else:
                console.print("[yellow]ğŸ“‚ ç¼“å­˜ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†[/yellow]")
                
        except Exception as e:
            console.print(f"[red]âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}[/red]")
    
    else:
        console.print(f"[red]âŒ æœªçŸ¥æ“ä½œ: {action}[/red]")
        console.print("ğŸ’¡ æ”¯æŒçš„æ“ä½œ: list, info, download, clean")
        console.print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        console.print("   translate model list                                    # åˆ—å‡ºå·²ç¼“å­˜æ¨¡å‹")
        console.print("   translate model info                                    # æ˜¾ç¤ºé»˜è®¤æ¨¡å‹ä¿¡æ¯")
        console.print("   translate model info mlx-community/parakeet-tdt-0.6b-v2  # æ˜¾ç¤ºæŒ‡å®šæ¨¡å‹ä¿¡æ¯")
        console.print("   translate model download                                      # é¢„ä¸‹è½½é»˜è®¤æ¨¡å‹")
        console.print("   translate model download mlx-community/parakeet-tdt-0.6b-v2  # é¢„ä¸‹è½½æŒ‡å®šæ¨¡å‹")
        console.print("   translate model clean                                   # æ¸…ç†ç¼“å­˜")


@app.command("version")
def version():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    from rich.console import Console
    from .version_utils import display_version_info
    
    console = Console()
    display_version_info(console)


@app.command("init")
def init():
    """åˆå§‹åŒ–å…¨å±€é…ç½® - æ£€æŸ¥å½“å‰ç›®å½•.envæ–‡ä»¶æˆ–äº¤äº’å¼è¾“å…¥é…ç½®"""
    import traceback
    print("ğŸš€ å¼€å§‹åˆå§‹åŒ–é…ç½®...")
    try:
        # è®¾ç½®ç¯å¢ƒæ—¶å…è®¸ç¼ºå°‘é…ç½®
        setup_environment(allow_missing_config=True)
        init_config()
        print("âœ… é…ç½®åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}")
        print(f"[bold red]âŒ é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}[/bold red]")
        print(f"[bold red]è¯¦ç»†é”™è¯¯ä¿¡æ¯:[/bold red]")
        traceback.print_exc()
        raise typer.Exit(code=1)


if __name__ == "__main__":
    app() 
