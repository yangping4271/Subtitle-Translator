"""
ä¸»å‘½ä»¤è¡Œæ¥å£æ¨¡å— - ç®€æ´æ¸…æ™°çš„CLIå…¥å£
"""
import glob
import re
import typer
from pathlib import Path
from typing import Optional
from typing_extensions import Annotated

from rich import print

from .env_setup import setup_environment
from .processor import process_single_file
from .config_manager import init_config
from .logger import setup_logger

# åˆå§‹åŒ–logger
logger = setup_logger(__name__)


app = typer.Typer(
    help="ä¸€ä¸ªé›†æˆäº†è¯­éŸ³è½¬å½•ã€å­—å¹•ç¿»è¯‘å’Œæ ¼å¼è½¬æ¢çš„å‘½ä»¤è¡Œå·¥å…·",
    epilog="ğŸ’¡ é¦–æ¬¡ä½¿ç”¨è¯·è¿è¡Œ: subtitle-translate init æ¥é…ç½®APIå¯†é’¥"
)


@app.callback(invoke_without_command=True)
def main(
    ctx: typer.Context,
    input_file: Optional[Path] = typer.Option(None, "--input-file", "-i", help="è¦å¤„ç†çš„å•ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œå¦‚ä¸æŒ‡å®šåˆ™æ‰¹é‡å¤„ç†å½“å‰ç›®å½•ã€‚", exists=True, file_okay=True, dir_okay=False, readable=True),
    max_count: int = typer.Option(-1, "--count", "-n", help="æœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡ï¼Œ-1è¡¨ç¤ºå¤„ç†æ‰€æœ‰æ–‡ä»¶ã€‚"),
    target_lang: str = typer.Option("zh", "--target_lang", "-t", help="ç›®æ ‡ç¿»è¯‘è¯­è¨€ã€‚æ”¯æŒçš„è¯­è¨€ï¼šzh(ç®€ä½“ä¸­æ–‡), zh-tw(ç¹ä½“ä¸­æ–‡), ja(æ—¥æ–‡), ko(éŸ©æ–‡), en(è‹±æ–‡), fr(æ³•æ–‡), de(å¾·æ–‡), es(è¥¿ç­ç‰™æ–‡), pt(è‘¡è„ç‰™æ–‡), ru(ä¿„æ–‡), it(æ„å¤§åˆ©æ–‡), ar(é˜¿æ‹‰ä¼¯æ–‡), th(æ³°æ–‡), vi(è¶Šå—æ–‡)ç­‰ã€‚"),
    output_dir: Optional[Path] = typer.Option(None, "--output_dir", "-o", help="è¾“å‡ºæ–‡ä»¶çš„ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚"),
    model: str = typer.Option("mlx-community/parakeet-tdt-0.6b-v2", "--model", help="ç”¨äºè½¬å½•çš„ Parakeet MLX æ¨¡å‹ã€‚"),
    llm_model: Optional[str] = typer.Option(None, "--llm-model", "-m", help="ç”¨äºç¿»è¯‘çš„LLMæ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ã€‚"),
    reflect: bool = typer.Option(False, "--reflect", "-r", help="å¯ç”¨åæ€ç¿»è¯‘æ¨¡å¼ï¼Œæé«˜ç¿»è¯‘è´¨é‡ä½†ä¼šå¢åŠ å¤„ç†æ—¶é—´ã€‚"),
    debug: bool = typer.Option(False, "--debug", "-d", help="å¯ç”¨è°ƒè¯•æ—¥å¿—çº§åˆ«ï¼Œæ˜¾ç¤ºæ›´è¯¦ç»†çš„å¤„ç†ä¿¡æ¯ã€‚"),
):
    """å­—å¹•ç¿»è¯‘å·¥å…·ä¸»å‘½ä»¤"""
    setup_environment()
    
    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return
    
    # æ—©æœŸéªŒè¯ç›®æ ‡è¯­è¨€ä»£ç ï¼Œæä¾›å‹å¥½é”™è¯¯ä¿¡æ¯
    try:
        _validate_target_language(target_lang)
    except ValueError as e:
        logger.error(f"âŒ å‘½ä»¤è¡Œå‚æ•°é”™è¯¯ - ç›®æ ‡è¯­è¨€: {str(e)}")
        print(f"[bold red]âŒ ç›®æ ‡è¯­è¨€å‚æ•°é”™è¯¯![/bold red]")
        print(str(e))
        print(f"\nğŸ’¡ [bold blue]ä½¿ç”¨ç¤ºä¾‹:[/bold blue]")
        print(f"   subtitle-translate -t ja  # ç¿»è¯‘æˆæ—¥æ–‡")
        print(f"   subtitle-translate -t ko  # ç¿»è¯‘æˆéŸ©æ–‡")
        print(f"   subtitle-translate -t fr  # ç¿»è¯‘æˆæ³•æ–‡")
        raise typer.Exit(code=1)

    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = Path.cwd()
    
    output_dir = output_dir.resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    # è·å–è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    if input_file:
        files_to_process = [input_file]
        logger.info(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: {input_file.name}")
        print(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: [bold cyan]{input_file.name}[/bold cyan]")
    else:
        files_to_process = _get_batch_files(max_count, llm_model)

    # æ‰¹é‡å¤„ç†æ–‡ä»¶
    _process_files_batch(files_to_process, target_lang, output_dir, model, llm_model, reflect, debug)


def _validate_target_language(target_lang: str):
    """éªŒè¯ç›®æ ‡è¯­è¨€ä»£ç """
    from .translation_core.config import get_target_language
    target_language_name = get_target_language(target_lang)
    print(f"ğŸ¯ [bold green]ç›®æ ‡è¯­è¨€:[/bold green] [cyan]{target_language_name}[/cyan] ([dim]{target_lang}[/dim])")


def _get_batch_files(max_count: int, llm_model: Optional[str]) -> list:
    """è·å–æ‰¹é‡å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨"""
    MEDIA_EXTENSIONS = ["*.srt", "*.mp3", "*.mp4"]

    # æŸ¥æ‰¾æ‰€æœ‰åª’ä½“æ–‡ä»¶
    media_files = []
    for pattern in MEDIA_EXTENSIONS:
        media_files.extend(glob.glob(pattern))
    
    if not media_files:
        print("[bold red]å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶ (*.srt, *.mp3, *.mp4)ã€‚[/bold red]")
        raise typer.Exit(code=1)
    
    # æå–åŸºç¡€æ–‡ä»¶åå¹¶å»é‡æ’åº
    base_names = set()
    for file in media_files:
        # ç§»é™¤æ‰©å±•å
        base_name = re.sub(r'\.(srt|mp3|mp4)$', '', file)
        # ç§»é™¤å„ç§è¯­è¨€åç¼€
        language_suffixes = [r'\.zh$', r'\.zh-cn$', r'\.zh-tw$', r'\.ja$', r'\.en$', r'\.ko$', r'\.fr$', r'\.de$', r'\.es$', r'\.pt$', r'\.ru$', r'\.it$', r'\.ar$', r'\.th$', r'\.vi$']
        for suffix_pattern in language_suffixes:
            base_name = re.sub(suffix_pattern, '', base_name)
        base_names.add(base_name)
    
    base_names = sorted(base_names)
    
    # ä¸ºæ¯ä¸ªåŸºç¡€åç§°æ‰¾åˆ°å¯¹åº”çš„è¾“å…¥æ–‡ä»¶
    files_to_process = []
    for base_name in base_names:
        # è·³è¿‡å·²å­˜åœ¨.assæ–‡ä»¶çš„
        ass_file = Path(f"{base_name}.ass")
        if ass_file.exists():
            print(f"INFO: {base_name}.ass å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†ã€‚")
            continue
        
        # ç¡®å®šè¾“å…¥æ–‡ä»¶ä¼˜å…ˆçº§ï¼šsrt > mp3 > mp4
        input_file_found = None
        for ext in ['.srt', '.mp3', '.mp4']:
            candidate = Path(f"{base_name}{ext}")
            if candidate.exists():
                input_file_found = candidate
                break
        
        if input_file_found:
            files_to_process.append(input_file_found)
            print(f"ğŸ“„ å‘ç°æ–‡ä»¶ [cyan]{input_file_found}[/cyan]")
        else:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ° [yellow]{base_name}[/yellow] çš„è¾“å…¥æ–‡ä»¶")
    
    if not files_to_process:
        print("[bold yellow]æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–°æ–‡ä»¶ã€‚[/bold yellow]")
        raise typer.Exit(code=0)
    
    # åº”ç”¨æ•°é‡é™åˆ¶
    if max_count > 0:
        files_to_process = files_to_process[:max_count]
    
    print(f"[bold green]å¼€å§‹æ‰¹é‡ç¿»è¯‘å¤„ç†ï¼Œå…±{len(files_to_process)}ä¸ªæ–‡ä»¶...[/bold green]")
    if llm_model:
        print(f"ä½¿ç”¨LLMæ¨¡å‹: [bold cyan]{llm_model}[/bold cyan]")
    
    return files_to_process


def _process_files_batch(files_to_process: list, target_lang: str, output_dir: Path, 
                        model: str, llm_model: Optional[str], reflect: bool, debug: bool):
    """æ‰¹é‡å¤„ç†æ–‡ä»¶"""
    count = 0
    generated_ass_files = []
    
    for i, current_input_file in enumerate(files_to_process):
        print()
        logger.info(f"ğŸ¯ å¤„ç†æ–‡ä»¶ ({i+1}/{len(files_to_process)}): {current_input_file.name}")
        print(f"ğŸ¯ å¤„ç†æ–‡ä»¶ ({i+1}/{len(files_to_process)}): [bold cyan]{current_input_file.name}[/bold cyan]")
        
        try:
            process_single_file(
                current_input_file, target_lang, output_dir, model, 
                llm_model, reflect, debug
            )
            count += 1
            logger.info(f"âœ… {current_input_file.stem} å¤„ç†å®Œæˆï¼")
            print(f"[bold green]âœ… {current_input_file.stem} å¤„ç†å®Œæˆï¼[/bold green]")
            
            # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ASSæ–‡ä»¶
            ass_file = output_dir / f"{current_input_file.stem}.ass"
            if ass_file.exists():
                generated_ass_files.append(ass_file)
                logger.info(f"ğŸ“º åŒè¯­ASSæ–‡ä»¶å·²ç”Ÿæˆ: {ass_file.name}")
                print(f"ğŸ“º åŒè¯­ASSæ–‡ä»¶å·²ç”Ÿæˆ: [cyan]{ass_file.name}[/cyan]")
        
        except Exception as e:
            from .translation_core.spliter import SmartSplitError, TranslationError, SummaryError
            if isinstance(e, (SmartSplitError, TranslationError, SummaryError)):
                # è¿™äº›å¼‚å¸¸å·²ç»åœ¨processor.pyä¸­æ˜¾ç¤ºè¿‡äº†ï¼Œè¿™é‡Œä¸é‡å¤æ˜¾ç¤º
                pass
            else:
                print(f"[bold red]âŒ {current_input_file.stem} å¤„ç†å¤±è´¥ï¼{e}[/bold red]")
        
        print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    _show_batch_results(count, generated_ass_files, output_dir)


def _show_batch_results(count: int, generated_ass_files: list, output_dir: Path):
    """æ˜¾ç¤ºæ‰¹é‡å¤„ç†ç»“æœ"""
    print()
    logger.info("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    logger.info(f"æ€»è®¡å¤„ç†æ–‡ä»¶æ•°: {count}")
    print(f"ğŸ‰ [bold green]æ‰¹é‡å¤„ç†å®Œæˆï¼[/bold green] (å¤„ç† [cyan]{count}[/cyan] ä¸ªæ–‡ä»¶)")
    
    # åªæ˜¾ç¤ºæœ¬æ¬¡ç”Ÿæˆçš„ASSæ–‡ä»¶ç»Ÿè®¡
    if count > 0:
        if generated_ass_files:
            logger.info("æœ¬æ¬¡ç”Ÿæˆçš„ASSæ–‡ä»¶ï¼š")
            for f in generated_ass_files:
                logger.info(f"  {f.name}")
            print(f"ğŸ“º [bold green]å·²ç”Ÿæˆ {len(generated_ass_files)} ä¸ªåŒè¯­ASSæ–‡ä»¶[/bold green]")
        
        # è¿‡æ»¤æ‰è¯­è¨€ç‰¹å®šçš„SRTæ–‡ä»¶
        language_patterns = ['.zh.', '.zh-cn.', '.zh-tw.', '.ja.', '.en.', '.ko.', '.fr.', '.de.', '.es.', '.pt.', '.ru.', '.it.', '.ar.', '.th.', '.vi.']
        srt_files = [f for f in output_dir.glob("*.srt") if not any(pattern in f.name for pattern in language_patterns)]
        if srt_files:
            logger.info("åŸå§‹å­—å¹•æ–‡ä»¶ï¼š")
            for f in srt_files:
                logger.info(f"  {f.name}")
    
    logger.info("å¤„ç†å®Œæ¯•ï¼")


@app.command("init")
def init():
    """åˆå§‹åŒ–å…¨å±€é…ç½® - æ£€æŸ¥å½“å‰ç›®å½•.envæ–‡ä»¶æˆ–äº¤äº’å¼è¾“å…¥é…ç½®"""
    init_config()


if __name__ == "__main__":
    app() 