import os
from pathlib import Path

from dotenv import find_dotenv, load_dotenv

import typer
from typing_extensions import Annotated
import glob
import sys
import time


# åº”ç”¨åç§°ï¼Œç”¨äºé…ç½®æ–‡ä»¶ç›®å½•
APP_NAME = "subtitle_translator"

# å…¨å±€å˜é‡ï¼Œç”¨äºè·Ÿè¸ªç¯å¢ƒæ˜¯å¦å·²ç»åŠ è½½
_env_loaded = False

def setup_environment():
    """
    æ™ºèƒ½åŠ è½½ .env æ–‡ä»¶ï¼Œè§£å†³åœ¨ä¸åŒç›®å½•ä¸‹è¿è¡Œå‘½ä»¤çš„ç¯å¢ƒå˜é‡é—®é¢˜ã€‚
    åŠ è½½é¡ºåº (åè€…è¦†ç›–å‰è€…):
    1. ç”¨æˆ·å…¨å±€é…ç½®æ–‡ä»¶ (~/.config/subtitle_translator/.env)
    2. é¡¹ç›®é…ç½®æ–‡ä»¶ (ä»å½“å‰ç›®å½•å‘ä¸Šæ‰¾åˆ°çš„ç¬¬ä¸€ä¸ª .env)
    
    ç‰¹æ®ŠåŠŸèƒ½ï¼š
    - å¦‚æœå…¨å±€é…ç½®ä¸å­˜åœ¨ï¼Œä½†æ‰¾åˆ°é¡¹ç›®é…ç½®ï¼Œä¼šè‡ªåŠ¨å¤åˆ¶é¡¹ç›®é…ç½®ä½œä¸ºå…¨å±€é…ç½®
    - ä½¿ç”¨æ ‡å‡†çš„ .config ç›®å½•å­˜å‚¨å…¨å±€é…ç½®
    """
    global _env_loaded, logger
    
    # å¦‚æœå·²ç»åŠ è½½è¿‡ç¯å¢ƒé…ç½®ï¼Œç›´æ¥è¿”å›
    if _env_loaded:
        return
    
    env_loaded = False
    
    # å‡†å¤‡è·¯å¾„ - ä½¿ç”¨æ ‡å‡†çš„ .config ç›®å½•
    app_dir = Path.home() / ".config" / APP_NAME
    user_env_path = app_dir / ".env"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    app_dir.mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾é¡¹ç›®æœ¬åœ°çš„ .env æ–‡ä»¶
    project_env_path_str = find_dotenv(usecwd=True)
    project_env_path = Path(project_env_path_str) if project_env_path_str else None
    
    # ğŸ¯ æ™ºèƒ½é…ç½®å¤åˆ¶ï¼šå¦‚æœå…¨å±€é…ç½®ä¸å­˜åœ¨ä½†é¡¹ç›®é…ç½®å­˜åœ¨ï¼Œè‡ªåŠ¨å¤åˆ¶
    config_copied = False
    if not user_env_path.is_file() and project_env_path and project_env_path.is_file():
        try:
            import shutil
            shutil.copy2(project_env_path, user_env_path)
            config_copied = True
        except Exception as e:
            print(f"âš ï¸  å¤åˆ¶é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    # 1. åŠ è½½ç”¨æˆ·å…¨å±€é…ç½®æ–‡ä»¶ (é€‚ç”¨äºå·²å®‰è£…çš„åº”ç”¨)
    if user_env_path.is_file():
        # åŠ è½½å…¨å±€é…ç½®ï¼Œä½†ä¸è¦†ç›–å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡ï¼Œå…³é—­verboseè¾“å‡º
        load_dotenv(user_env_path, verbose=False)
        env_loaded = True
        
    # 2. åŠ è½½é¡¹ç›®æœ¬åœ°çš„ .env æ–‡ä»¶ (æ–¹ä¾¿å¼€å‘ï¼Œå¹¶å¯è¦†ç›–å…¨å±€é…ç½®)
    if project_env_path and project_env_path.is_file():
        # ä½¿ç”¨ override=True æ¥è¦†ç›–ä»»ä½•å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿é¡¹ç›®é…ç½®ä¼˜å…ˆï¼Œå…³é—­verboseè¾“å‡º
        load_dotenv(project_env_path, verbose=False, override=True)
        env_loaded = True
    
    # æ ‡è®°ç¯å¢ƒå·²åŠ è½½
    _env_loaded = True
    
    # åˆå§‹åŒ–loggerï¼ˆéœ€è¦åœ¨ç¯å¢ƒå˜é‡åŠ è½½åè¿›è¡Œï¼‰
    if logger is None:
        # æ£€æµ‹debugæ¨¡å¼ï¼šæ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°å’Œç¯å¢ƒå˜é‡
        debug_mode = ('-d' in sys.argv or '--debug' in sys.argv or 
                     os.environ.get('DEBUG', '').lower() in ('1', 'true', 'yes'))
        
        from .logger import setup_logger
        logger = setup_logger(__name__, debug_mode=debug_mode)
        
        # åªåœ¨éœ€è¦æé†’ç”¨æˆ·æˆ–å‡ºç°é—®é¢˜æ—¶è¾“å‡ºæ—¥å¿—ä¿¡æ¯
        if config_copied:
            logger.info(f"âœ… é¦–æ¬¡è¿è¡Œæ£€æµ‹åˆ°é¡¹ç›®é…ç½®æ–‡ä»¶ï¼Œå·²è‡ªåŠ¨å¤åˆ¶åˆ°å…¨å±€é…ç½®:")
            logger.info(f"   æºæ–‡ä»¶: {project_env_path}")
            logger.info(f"   ç›®æ ‡æ–‡ä»¶: {user_env_path}")
            logger.info(f"   ç°åœ¨ä½ å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ subtitle-translate å‘½ä»¤ï¼")
        elif not env_loaded:
            logger.warning(
                f"æœªæ‰¾åˆ°ä»»ä½• .env æ–‡ä»¶ã€‚ç¨‹åºå°†ä¾èµ–äºç³»ç»Ÿç¯å¢ƒå˜é‡ã€‚\n"
                f"å¦‚éœ€é€šè¿‡æ–‡ä»¶é…ç½®ï¼Œè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•æˆ–ç”¨æˆ·é…ç½®ç›®å½• "
                f"({app_dir}) ä¸­åˆ›å»ºä¸€ä¸ª .env æ–‡ä»¶ã€‚"
            )
            
            # æ£€æŸ¥å…³é”®ç¯å¢ƒå˜é‡æ˜¯å¦å­˜åœ¨
            required_vars = ['OPENAI_BASE_URL', 'OPENAI_API_KEY', 'LLM_MODEL']
            missing_vars = []
            for var in required_vars:
                if not os.environ.get(var):
                    missing_vars.append(var)
            
            if missing_vars:
                logger.error(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
                logger.error("è¯·è¿è¡Œ 'subtitle-translate init' æ¥é…ç½®APIå¯†é’¥ï¼Œæˆ–è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡ã€‚")
                sys.exit(1)

# åœ¨æ‰€æœ‰å…¶ä»–é¡¹ç›®å¯¼å…¥ä¹‹å‰ï¼Œé¦–å…ˆåŠ è½½ç¯å¢ƒå˜é‡
# setup_environment()  <-- æˆ‘å°†åˆ é™¤è¿™ä¸€è¡Œ


from typing import Optional

from rich import print
import logging

# å¯¼å…¥è½¬å½•æ ¸å¿ƒ
from .transcription_core import from_pretrained
from .transcription_core.cli import to_srt

# å¯¼å…¥ç¿»è¯‘æ ¸å¿ƒ
from .translation_core.optimizer import SubtitleOptimizer
from .translation_core.summarizer import SubtitleSummarizer
from .translation_core.spliter import merge_segments
from .translation_core.config import get_default_config, SubtitleConfig
from .translation_core.data import load_subtitle, SubtitleData
from .translation_core.utils.test_openai import test_openai
from .logger import setup_logger, log_section_start, log_section_end, log_stats, create_progress_logger


# é…ç½®æ—¥å¿—
# logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s') # è¿™ä¸€è¡Œå·²è¢«ç§»é™¤
# å»¶è¿Ÿåˆå§‹åŒ–loggerï¼Œåœ¨setup_environmentä¸­åˆå§‹åŒ–
logger = None

class OpenAIAPIError(Exception):
    """OpenAI API ç›¸å…³é”™è¯¯"""
    pass

class SubtitleTranslatorService:
    def __init__(self):
        self.config = SubtitleConfig()
        self.summarizer = SubtitleSummarizer(self.config)

    def _init_translation_env(self, llm_model: str) -> None:
        """åˆå§‹åŒ–ç¿»è¯‘ç¯å¢ƒå¹¶æµ‹è¯•è¿æ¥"""
        start_time = time.time()
        log_section_start(logger, "ç¿»è¯‘ç¯å¢ƒåˆå§‹åŒ–", "âš™ï¸")
        
        if llm_model:
            self.config.split_model = llm_model
            self.config.summary_model = llm_model
            self.config.translation_model = llm_model

        logger.info(f"ğŸŒ APIç«¯ç‚¹: {self.config.openai_base_url}")
        
        model_config = {
            "æ–­å¥æ¨¡å‹": self.config.split_model,
            "æ€»ç»“æ¨¡å‹": self.config.summary_model,
            "ç¿»è¯‘æ¨¡å‹": self.config.translation_model
        }
        log_stats(logger, model_config, "æ¨¡å‹é…ç½®")
        
        # ä½¿ç”¨ç¿»è¯‘æ¨¡å‹è¿›è¡Œè¿æ¥æµ‹è¯•
        logger.info("ğŸ”Œ æ­£åœ¨æµ‹è¯•APIè¿æ¥...")
        print("ğŸ”Œ [bold yellow]æµ‹è¯•APIè¿æ¥...[/bold yellow]")
        success, error_msg = test_openai(self.config.openai_base_url, self.config.openai_api_key, self.config.translation_model)
        if not success:
            logger.error(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {error_msg}")
            print(f"[bold red]âŒ APIè¿æ¥å¤±è´¥: {error_msg}[/bold red]")
            raise OpenAIAPIError(error_msg)
        
        logger.info("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ")
        print("âœ… [bold green]APIè¿æ¥æˆåŠŸ[/bold green]")
        
        # æ˜¾ç¤ºæ¨¡å‹é…ç½®
        print(f"ğŸ¤– [bold blue]æ¨¡å‹é…ç½®:[/bold blue]")
        print(f"   æ–­å¥: [cyan]{self.config.split_model}[/cyan]")
        print(f"   æ€»ç»“: [cyan]{self.config.summary_model}[/cyan]")
        print(f"   ç¿»è¯‘: [cyan]{self.config.translation_model}[/cyan]")
        
        elapsed_time = time.time() - start_time
        log_section_end(logger, "ç¿»è¯‘ç¯å¢ƒåˆå§‹åŒ–", elapsed_time, "âœ…")

    def translate_srt(self, input_srt_path: Path, target_lang: str, output_dir: Path, 
                      llm_model: Optional[str] = None, reflect: bool = False) -> Path:
        """ç¿»è¯‘å­—å¹•æ–‡ä»¶"""
        try:
            task_start_time = time.time()
            log_section_start(logger, "å­—å¹•ç¿»è¯‘ä»»åŠ¡", "ğŸ¬")
            
            # ç”¨äºæ”¶é›†å„é˜¶æ®µè€—æ—¶çš„å­—å…¸
            stage_times = {}
            
            # åˆå§‹åŒ–ç¿»è¯‘ç¯å¢ƒ
            init_start_time = time.time()
            self._init_translation_env(llm_model)
            stage_times["ğŸ”§ ç¯å¢ƒåˆå§‹åŒ–"] = time.time() - init_start_time
            
            # åŠ è½½å­—å¹•æ–‡ä»¶
            logger.info("ğŸ“‚ æ­£åœ¨åŠ è½½å­—å¹•æ–‡ä»¶...")
            asr_data = load_subtitle(str(input_srt_path))
            logger.info(f"ğŸ“Š å­—å¹•ç»Ÿè®¡: å…± {len(asr_data.segments)} æ¡å­—å¹•")
            logger.debug(f"å­—å¹•å†…å®¹é¢„è§ˆ: {asr_data.to_txt()[:100]}...")  
            
            print(f"ğŸ“Š [bold blue]åŠ è½½å®Œæˆ[/bold blue] (å…± [cyan]{len(asr_data.segments)}[/cyan] æ¡å­—å¹•)")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°æ–­å¥
            split_time = 0
            if asr_data.is_word_timestamp():
                section_start_time = time.time()
                log_section_start(logger, "å­—å¹•æ–­å¥å¤„ç†", "âœ‚ï¸")
                print(f"âœ‚ï¸ [bold yellow]æ™ºèƒ½æ–­å¥å¤„ç†ä¸­...[/bold yellow]")
                
                model = self.config.split_model
                logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
                logger.info(f"ğŸ“ å¥å­é•¿åº¦é™åˆ¶: {self.config.max_word_count_english} å­—")
                
                asr_data = merge_segments(asr_data, model=model, 
                                       num_threads=self.config.thread_num, 
                                       save_split=None)
                
                split_time = time.time() - section_start_time
                log_section_end(logger, "å­—å¹•æ–­å¥å¤„ç†", split_time, "âœ…")
                print(f"âœ… [bold green]æ–­å¥å®Œæˆ[/bold green] (ä¼˜åŒ–ä¸º [cyan]{len(asr_data.segments)}[/cyan] å¥)")
            
            if split_time > 0:
                stage_times["âœ‚ï¸ æ™ºèƒ½æ–­å¥"] = split_time
            
            # è·å–å­—å¹•æ‘˜è¦
            summary_start_time = time.time()
            summarize_result = self._get_subtitle_summary(asr_data, str(input_srt_path))
            summary_time = time.time() - summary_start_time
            stage_times["ğŸ” å†…å®¹åˆ†æ"] = summary_time
            
            # ç¿»è¯‘å­—å¹•
            translate_start_time = time.time()
            translate_result = self._translate_subtitles(asr_data, summarize_result, reflect)
            translate_time = time.time() - translate_start_time
            mode_name = "ğŸ¤” åæ€ç¿»è¯‘" if reflect else "ğŸŒ å¸¸è§„ç¿»è¯‘"
            stage_times[mode_name] = translate_time
            
            # ä¿å­˜å­—å¹•
            logger.info("ğŸ’¾ æ­£åœ¨ä¿å­˜ç¿»è¯‘ç»“æœ...")
            base_name = input_srt_path.stem
            zh_output_path = output_dir / f"{base_name}.{target_lang}.srt"
            en_output_path = output_dir / f"{base_name}.en.srt"

            asr_data.save_translations_to_files(
                translate_result,
                str(en_output_path),
                str(zh_output_path)
            )
            
            total_elapsed = time.time() - task_start_time
            
            # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
            print()
            self._format_time_stats(stage_times, total_elapsed)
            
            # ä»»åŠ¡å®Œæˆç»Ÿè®¡
            final_stats = {
                "è¾“å…¥æ–‡ä»¶": input_srt_path.name,
                "å­—å¹•æ•°é‡": len(asr_data.segments),
                "ç›®æ ‡è¯­è¨€": target_lang,
                "ç¿»è¯‘æ¨¡å¼": "åæ€ç¿»è¯‘" if reflect else "å¸¸è§„ç¿»è¯‘",
                "æ€»è€—æ—¶": f"{total_elapsed:.1f}ç§’"
            }
            log_stats(logger, final_stats, "ä»»åŠ¡å®Œæˆç»Ÿè®¡")
            log_section_end(logger, "å­—å¹•ç¿»è¯‘ä»»åŠ¡", total_elapsed, "ğŸ‰")
            
            return zh_output_path
                
        except OpenAIAPIError as e:
            logger.error(f"ğŸš¨ APIé”™è¯¯: {str(e)}")
            raise typer.Exit(code=1)
            
        except Exception as e:
            logger.error(f"ğŸ’¥ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            raise typer.Exit(code=1)

    def _get_subtitle_summary(self, asr_data: SubtitleData, input_file: str) -> dict:
        """è·å–å­—å¹•å†…å®¹æ‘˜è¦"""
        section_start_time = time.time()
        log_section_start(logger, "å­—å¹•å†…å®¹åˆ†æ", "ğŸ”")
        print(f"ğŸ” [bold cyan]å†…å®¹åˆ†æä¸­...[/bold cyan]")
        
        logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.config.summary_model}")
        summarize_result = self.summarizer.summarize(asr_data.to_txt(), input_file)
        logger.info(f"æ€»ç»“å­—å¹•å†…å®¹:\n{summarize_result.get('summary')}\n")
        
        section_elapsed = time.time() - section_start_time
        log_section_end(logger, "å­—å¹•å†…å®¹åˆ†æ", section_elapsed, "âœ…")
        print(f"âœ… [bold green]å†…å®¹åˆ†æå®Œæˆ[/bold green]")
        
        return summarize_result

    def _translate_subtitles(self, asr_data: SubtitleData, summarize_result: dict, reflect: bool = False) -> list:
        """ç¿»è¯‘å­—å¹•å†…å®¹"""
        section_start_time = time.time()
        mode_name = "åæ€ç¿»è¯‘" if reflect else "å¸¸è§„ç¿»è¯‘"
        log_section_start(logger, f"å­—å¹•{mode_name}", "ğŸŒ")
        
        print(f"ğŸŒ [bold magenta]{mode_name}ä¸­...[/bold magenta] ({len(asr_data.segments)} å¥)")
        
        logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.config.translation_model}")
        logger.info(f"âš¡ çº¿ç¨‹æ•°: {self.config.thread_num}")
        
        try:
            translator = SubtitleOptimizer(
                config=self.config,
                need_reflect=reflect
            )
            translate_result = translator.translate(asr_data, summarize_result)
            
            # è·å–ä¼˜åŒ–ç»Ÿè®¡
            stats = self._get_optimization_stats(translator.batch_logs, reflect)
            
            section_elapsed = time.time() - section_start_time
            log_section_end(logger, f"å­—å¹•{mode_name}", section_elapsed, "ğŸ‰")
            print(f"âœ… [bold green]{mode_name}å®Œæˆ[/bold green]")
            
            # æ˜¾ç¤ºä¼˜åŒ–ç»Ÿè®¡
            if stats['total_changes'] > 0:
                print(f"ğŸ“Š [bold blue]ä¼˜åŒ–ç»Ÿè®¡:[/bold blue]")
                if stats['format_changes'] > 0:
                    print(f"   æ ¼å¼ä¼˜åŒ–: [cyan]{stats['format_changes']}[/cyan] é¡¹")
                if stats['content_changes'] > 0:
                    print(f"   å†…å®¹ä¿®æ”¹: [cyan]{stats['content_changes']}[/cyan] é¡¹")
                if stats['reflect_changes'] > 0:
                    print(f"   åæ€ä¼˜åŒ–: [cyan]{stats['reflect_changes']}[/cyan] é¡¹")
                if stats['wrong_changes'] > 0:
                    print(f"   [yellow]å¯ç–‘æ›¿æ¢: {stats['wrong_changes']} é¡¹[/yellow]")
                print(f"   æ€»è®¡: [cyan]{stats['total_changes']}[/cyan] é¡¹ä¼˜åŒ–")
            else:
                print("ğŸ“Š [dim]æ— éœ€ä¼˜åŒ–è°ƒæ•´[/dim]")
            
            return translate_result
        except Exception as e:
            logger.error(f"âŒ ç¿»è¯‘å¤±è´¥: {str(e)}")
            print(f"[bold red]âŒ ç¿»è¯‘å¤±è´¥: {str(e)}[/bold red]")
            raise

    def _get_optimization_stats(self, batch_logs: list, reflect: bool) -> dict:
        """ä»batch_logsä¸­è·å–ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        import string
        
        def is_format_change_only(original, optimized):
            """åˆ¤æ–­æ˜¯å¦åªæœ‰æ ¼å¼å˜åŒ–ï¼ˆå¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·ï¼‰"""
            # å¿½ç•¥å¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·åæ¯”è¾ƒ
            original_normalized = original.lower().translate(str.maketrans('', '', string.punctuation))
            optimized_normalized = optimized.lower().translate(str.maketrans('', '', string.punctuation))
            return original_normalized == optimized_normalized

        def is_wrong_replacement(original, optimized):
            """æ£€æµ‹æ˜¯å¦å­˜åœ¨é”™è¯¯çš„æ›¿æ¢ï¼ˆæ›¿æ¢äº†ä¸ç›¸å…³çš„è¯ï¼‰"""
            import re
            # æå–æ‰€æœ‰å•è¯
            original_words = set(re.findall(r'\b\w+\b', original.lower()))
            optimized_words = set(re.findall(r'\b\w+\b', optimized.lower()))
            # æ‰¾å‡ºè¢«æ›¿æ¢çš„è¯
            removed_words = original_words - optimized_words
            added_words = optimized_words - original_words
            # å¦‚æœæ›¿æ¢å‰åçš„è¯æ²¡æœ‰ç›¸ä¼¼æ€§ï¼Œå¯èƒ½æ˜¯é”™è¯¯æ›¿æ¢
            if removed_words and added_words:
                for removed in removed_words:
                    for added in added_words:
                        # å¦‚æœåŸè¯å’Œæ–°è¯å®Œå…¨ä¸åŒï¼ˆç¼–è¾‘è·ç¦»è¿‡å¤§ï¼‰ï¼Œåˆ¤å®šä¸ºé”™è¯¯æ›¿æ¢
                        if len(removed) > 3 and len(added) > 3 and not any(c in removed for c in added):
                            return True
            return False

        # ç»Ÿè®¡å˜æ›´ç±»å‹
        format_changes = 0
        content_changes = 0
        wrong_changes = 0
        reflect_changes = 0

        # éå†æ‰€æœ‰æ—¥å¿—
        for log in batch_logs:
            if log["type"] == "content_optimization":
                original = log["original"]
                optimized = log["optimized"]
                
                # åˆ†ç±»ç»Ÿè®¡
                if is_format_change_only(original, optimized):
                    format_changes += 1
                elif is_wrong_replacement(original, optimized):
                    wrong_changes += 1
                else:
                    content_changes += 1
            
            elif log["type"] == "reflect_translation":
                reflect_changes += 1

        total_changes = format_changes + content_changes + wrong_changes + reflect_changes
        
        return {
            'format_changes': format_changes,
            'content_changes': content_changes,
            'wrong_changes': wrong_changes,
            'reflect_changes': reflect_changes,
            'total_changes': total_changes
        }

    def _format_time_stats(self, stages: dict, total_time: float) -> None:
        """æ ¼å¼åŒ–æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡"""
        print(f"â±ï¸  [bold blue]è€—æ—¶ç»Ÿè®¡:[/bold blue]")
        
        # æŒ‰æ—¶é—´æ’åºæ˜¾ç¤ºå„é˜¶æ®µ
        sorted_stages = sorted(stages.items(), key=lambda x: x[1], reverse=True)
        
        for stage_name, elapsed_time in sorted_stages:
            if elapsed_time > 0:
                percentage = (elapsed_time / total_time) * 100
                print(f"   {stage_name}: [cyan]{elapsed_time:.1f}s[/cyan] ([dim]{percentage:.0f}%[/dim])")
        
        print(f"   [bold]æ€»è®¡: [cyan]{total_time:.1f}s[/cyan][/bold]")

app = typer.Typer(
    help="ä¸€ä¸ªé›†æˆäº†è¯­éŸ³è½¬å½•ã€å­—å¹•ç¿»è¯‘å’Œæ ¼å¼è½¬æ¢çš„å‘½ä»¤è¡Œå·¥å…·",
    epilog="ğŸ’¡ é¦–æ¬¡ä½¿ç”¨è¯·è¿è¡Œ: subtitle-translate init æ¥é…ç½®APIå¯†é’¥"
)

@app.callback(invoke_without_command=True)
def main(
    ctx: typer.Context,
    input_file: Optional[Path] = typer.Option(None, "--input-file", "-i", help="è¦å¤„ç†çš„å•ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œå¦‚ä¸æŒ‡å®šåˆ™æ‰¹é‡å¤„ç†å½“å‰ç›®å½•ã€‚", exists=True, file_okay=True, dir_okay=False, readable=True),
    max_count: int = typer.Option(-1, "--count", "-n", help="æœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡ï¼Œ-1è¡¨ç¤ºå¤„ç†æ‰€æœ‰æ–‡ä»¶ã€‚"),
    target_lang: str = typer.Option("zh", "--target_lang", "-t", help="ç›®æ ‡ç¿»è¯‘è¯­è¨€ï¼Œä¾‹å¦‚ 'zh' (ä¸­æ–‡), 'en' (è‹±æ–‡)ã€‚"),
    output_dir: Optional[Path] = typer.Option(None, "--output_dir", "-o", help="è¾“å‡ºæ–‡ä»¶çš„ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚"),
    model: str = typer.Option("mlx-community/parakeet-tdt-0.6b-v2", "--model", help="ç”¨äºè½¬å½•çš„ Parakeet MLX æ¨¡å‹ã€‚"),
    llm_model: Optional[str] = typer.Option(None, "--llm-model", "-m", help="ç”¨äºç¿»è¯‘çš„LLMæ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ã€‚"),
    reflect: bool = typer.Option(False, "--reflect", "-r", help="å¯ç”¨åæ€ç¿»è¯‘æ¨¡å¼ï¼Œæé«˜ç¿»è¯‘è´¨é‡ä½†ä¼šå¢åŠ å¤„ç†æ—¶é—´ã€‚"),
    debug: bool = typer.Option(False, "--debug", "-d", help="å¯ç”¨è°ƒè¯•æ—¥å¿—çº§åˆ«ï¼Œæ˜¾ç¤ºæ›´è¯¦ç»†çš„å¤„ç†ä¿¡æ¯ã€‚"),
):
    """å­—å¹•ç¿»è¯‘å·¥å…·ä¸»å‘½ä»¤"""
    setup_environment()
    
    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return


        
    

    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰ç›®å½•
    if output_dir is None:
        output_dir = Path.cwd()
    
    # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…ç›¸å¯¹è·¯å¾„åœ¨ä¸åŒå·¥ä½œç›®å½•ä¸‹çš„é—®é¢˜
    output_dir = output_dir.resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    # è·å–è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    if input_file:
        # å•æ–‡ä»¶æ¨¡å¼
        files_to_process = [input_file]
        logger.info(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: {input_file.name}")
        print(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: [bold cyan]{input_file.name}[/bold cyan]")
    else:
        # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼šæŸ¥æ‰¾å½“å‰ç›®å½•ä¸­çš„åª’ä½“æ–‡ä»¶
        import re
        
        MEDIA_EXTENSIONS = ["*.srt", "*.mp3", "*.mp4"]

        # æŸ¥æ‰¾æ‰€æœ‰åª’ä½“æ–‡ä»¶
        media_files = []
        for pattern in MEDIA_EXTENSIONS:
            media_files.extend(glob.glob(pattern))
        
        if not media_files:
            print("[bold red]å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶ (*.srt, *.mp3, *.mp4)ã€‚[/bold red]")
            raise typer.Exit(code=1)
        
        # æå–åŸºç¡€æ–‡ä»¶åå¹¶å»é‡æ’åº
        base_names = set()
        for file in media_files:
            # ç§»é™¤æ‰©å±•åå’Œè¯­è¨€åç¼€
            base_name = re.sub(r'\.(srt|mp3|mp4)$', '', file)
            base_name = re.sub(r'_(en|zh)$', '', base_name)
            base_names.add(base_name)
        
        base_names = sorted(base_names)
        
        # ä¸ºæ¯ä¸ªåŸºç¡€åç§°æ‰¾åˆ°å¯¹åº”çš„è¾“å…¥æ–‡ä»¶
        files_to_process = []
        for base_name in base_names:
            # è·³è¿‡å·²å­˜åœ¨.assæ–‡ä»¶çš„
            ass_file = Path(f"{base_name}.ass")
            if ass_file.exists():
                print(f"INFO: {base_name}.ass å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†ã€‚")
                continue
            
            # ç¡®å®šè¾“å…¥æ–‡ä»¶ä¼˜å…ˆçº§ï¼šsrt > mp3 > mp4
            input_file_found = None
            for ext in ['.srt', '.mp3', '.mp4']:
                candidate = Path(f"{base_name}{ext}")
                if candidate.exists():
                    input_file_found = candidate
                    break
            
            if input_file_found:
                files_to_process.append(input_file_found)
                print(f"ğŸ“„ å‘ç°æ–‡ä»¶ [cyan]{input_file_found}[/cyan]")
            else:
                print(f"âŒ æ²¡æœ‰æ‰¾åˆ° [yellow]{base_name}[/yellow] çš„è¾“å…¥æ–‡ä»¶")
        
        if not files_to_process:
            print("[bold yellow]æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–°æ–‡ä»¶ã€‚[/bold yellow]")
            raise typer.Exit(code=0)
        
        # åº”ç”¨æ•°é‡é™åˆ¶
        if max_count > 0:
            files_to_process = files_to_process[:max_count]
        
        print(f"[bold green]å¼€å§‹æ‰¹é‡ç¿»è¯‘å¤„ç†ï¼Œå…±{len(files_to_process)}ä¸ªæ–‡ä»¶...[/bold green]")
        if llm_model:
            print(f"ä½¿ç”¨LLMæ¨¡å‹: [bold cyan]{llm_model}[/bold cyan]")

    # å¤„ç†æ–‡ä»¶
    count = 0
    for i, current_input_file in enumerate(files_to_process):
        print()
        logger.info(f"ğŸ¯ å¤„ç†æ–‡ä»¶ ({i+1}/{len(files_to_process)}): {current_input_file.name}")
        print(f"ğŸ¯ å¤„ç†æ–‡ä»¶ ({i+1}/{len(files_to_process)}): [bold cyan]{current_input_file.name}[/bold cyan]")
        
        try:
            _process_single_file(
                current_input_file, target_lang, output_dir, model, 
                llm_model, reflect, debug
            )
            count += 1
            logger.info(f"âœ… {current_input_file.stem} å¤„ç†å®Œæˆï¼")
            print(f"[bold green]âœ… {current_input_file.stem} å¤„ç†å®Œæˆï¼[/bold green]")
            
            # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ASSæ–‡ä»¶
            ass_file = output_dir / f"{current_input_file.stem}.ass"
            if ass_file.exists():
                logger.info(f"ğŸ“º åŒè¯­ASSæ–‡ä»¶å·²ç”Ÿæˆ: {ass_file.name}")
                print(f"ğŸ“º åŒè¯­ASSæ–‡ä»¶å·²ç”Ÿæˆ: [cyan]{ass_file.name}[/cyan]")
        
        except Exception as e:
            print(f"[bold red]âŒ {current_input_file.stem} å¤„ç†å¤±è´¥ï¼{e}[/bold red]")
        
        print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ - ç®€åŒ–è¾“å‡º
    print()
    logger.info("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    logger.info(f"æ€»è®¡å¤„ç†æ–‡ä»¶æ•°: {count}")
    print(f"ğŸ‰ [bold green]æ‰¹é‡å¤„ç†å®Œæˆï¼[/bold green] (å¤„ç† [cyan]{count}[/cyan] ä¸ªæ–‡ä»¶)")
    
    # åªæ˜¾ç¤ºç”Ÿæˆçš„ASSæ–‡ä»¶ç»Ÿè®¡ï¼Œä¸æ˜¾ç¤ºè¯¦ç»†åˆ—è¡¨
    if count > 0:
        ass_files = list(output_dir.glob("*.ass"))
        if ass_files:
            logger.info("ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
            for f in ass_files:
                logger.info(f"  {f.name}")
            print(f"ğŸ“º [bold green]å·²ç”Ÿæˆ {len(ass_files)} ä¸ªåŒè¯­ASSæ–‡ä»¶[/bold green]")
        
        srt_files = [f for f in output_dir.glob("*.srt") if not ("_zh" in f.name or "_en" in f.name)]
        if srt_files:
            logger.info("åŸå§‹å­—å¹•æ–‡ä»¶ï¼š")
            for f in srt_files:
                logger.info(f"  {f.name}")
    
    logger.info("å¤„ç†å®Œæ¯•ï¼")


def _process_single_file(
    input_file: Path, target_lang: str, output_dir: Path, 
    model: str, llm_model: Optional[str], reflect: bool, debug: bool
):
    """å¤„ç†å•ä¸ªæ–‡ä»¶çš„æ ¸å¿ƒé€»è¾‘"""

    # æ£€æµ‹è¾“å…¥æ–‡ä»¶ç±»å‹
    if input_file.suffix.lower() == '.srt':
        print("[bold yellow]>>> æ£€æµ‹åˆ°SRTæ–‡ä»¶ï¼Œè·³è¿‡è½¬å½•æ­¥éª¤...[/bold yellow]")
        temp_srt_path = input_file
    else:
        # --- è½¬å½•é˜¶æ®µ ---
        logger.info(">>> å¼€å§‹è½¬å½•...")
        print("[bold green]>>> å¼€å§‹è½¬å½•...[/bold green]")
        temp_srt_path = output_dir / f"{input_file.stem}.srt"
        try:
            # æ¨¡æ‹Ÿ parakeet-mlx çš„è½¬å½•è¿‡ç¨‹
            # å®é™…è¿™é‡Œéœ€è¦è°ƒç”¨ parakeet-mlx çš„æ ¸å¿ƒè½¬å½•å‡½æ•°
            # ç”±äº parakeet-mlx çš„ cli.py ä¸­çš„ main å‡½æ•°ç›´æ¥å¤„ç†æ–‡ä»¶å¹¶ä¿å­˜ï¼Œ
            # æˆ‘ä»¬éœ€è¦å°†å…¶æ ¸å¿ƒé€»è¾‘æå–å‡ºæ¥ï¼Œæˆ–è€…ç›´æ¥è°ƒç”¨å…¶å†…éƒ¨çš„ transcribe æ–¹æ³•ã€‚
            # è¿™é‡Œæš‚æ—¶ç”¨ä¸€ä¸ªå ä½ç¬¦ï¼Œåç»­éœ€è¦å°† parakeet-mlx çš„è½¬å½•é€»è¾‘å°è£…æˆä¸€ä¸ªå¯è°ƒç”¨çš„å‡½æ•°ã€‚
            
            # å‡è®¾ from_pretrained è¿”å›ä¸€ä¸ªæ¨¡å‹å®ä¾‹ï¼Œå¹¶ä¸”è¯¥å®ä¾‹æœ‰ transcribe æ–¹æ³•
            # å¹¶ä¸” transcribe æ–¹æ³•è¿”å› AlignedResult
            loaded_model = from_pretrained(model)
            
            # å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨åˆ†å—å¤„ç†é¿å…å†…å­˜æº¢å‡º
            # ä½¿ç”¨ä¸åŸå§‹parakeet-mlxç›¸åŒçš„é»˜è®¤å€¼ï¼š120ç§’åˆ†å—ï¼Œ15ç§’é‡å 
            result = loaded_model.transcribe(input_file, chunk_duration=120.0, overlap_duration=15.0)
            
            # å°†è½¬å½•ç»“æœä¿å­˜ä¸º SRTï¼Œä½¿ç”¨ timestamps=True è·å¾—æ›´ç²¾ç»†çš„æ—¶é—´æˆ³
            srt_content = to_srt(result, timestamps=True)
            with open(temp_srt_path, "w", encoding="utf-8") as f:
                f.write(srt_content)
            
            # ç»Ÿè®¡å­—å¹•æ•°é‡
            subtitle_count = len(srt_content.strip().split('\n\n'))
            logger.info(f"è½¬å½•å®Œæˆï¼ŒSRTæ–‡ä»¶ä¿å­˜è‡³: {temp_srt_path}")
            print(f"âœ… [bold green]è½¬å½•å®Œæˆ[/bold green] (å…± [cyan]{subtitle_count}[/cyan] æ¡å­—å¹•)")

        except Exception as e:
            print(f"[bold red]è½¬å½•å¤±è´¥:[/bold red] {e}")
            raise typer.Exit(code=1)

    final_translated_zh_path = None
    final_translated_en_path = None

    # --- ç¿»è¯‘é˜¶æ®µ ---
    logger.info(">>> å¼€å§‹ç¿»è¯‘...")
    print("[bold green]>>> å¼€å§‹ç¿»è¯‘...[/bold green]")
    try:
        translator_service = SubtitleTranslatorService()
    except Exception as init_error:
        print(f"[bold red]åˆ›å»ºç¿»è¯‘æœåŠ¡å¤±è´¥:[/bold red] {init_error}")
        raise
    try:
        final_translated_zh_path = translator_service.translate_srt(
            input_srt_path=temp_srt_path,
            target_lang=target_lang,
            output_dir=output_dir,
            llm_model=llm_model,
            reflect=reflect
        )
        # ç¡®ä¿è¿™é‡Œæ­£ç¡®èµ‹å€¼
        final_translated_en_path = output_dir / f"{temp_srt_path.stem}.en.srt"

        logger.info(f"ç¿»è¯‘å®Œæˆï¼Œä¸­æ–‡ç¿»è¯‘æ–‡ä»¶ä¿å­˜è‡³: {final_translated_zh_path}")
        logger.info(f"è‹±æ–‡ç¿»è¯‘æ–‡ä»¶ä¿å­˜è‡³: {final_translated_en_path}")

        # --- è½¬æ¢ä¸º ASS ---
        print(">>> [bold green]ç”ŸæˆåŒè¯­ASSæ–‡ä»¶...[/bold green]")
        logger.info(">>> æ­£åœ¨è½¬æ¢ä¸º ASS æ ¼å¼...")

        # æå– srt2ass.py çš„æ ¸å¿ƒé€»è¾‘
        from .translation_core.utils.ass_converter import convert_srt_to_ass

        final_ass_path = convert_srt_to_ass(final_translated_zh_path, final_translated_en_path, output_dir)
        logger.info(f"ASS æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {final_ass_path}")

    except Exception as e:
        print(f"[bold red]ç¿»è¯‘æˆ– ASS è½¬æ¢å¤±è´¥:[/bold red] {e}")
        raise typer.Exit(code=1)
    finally:
        # --- æ¸…ç†ä¸­é—´ç¿»è¯‘æ–‡ä»¶ï¼Œä¿ç•™åŸå§‹è½¬å½•æ–‡ä»¶ ---
        logger.info(">>> æ­£åœ¨æ¸…ç†ä¸­é—´ç¿»è¯‘æ–‡ä»¶...")
        cleaned_files = 0
        if final_translated_zh_path and final_translated_zh_path.exists():
            os.remove(final_translated_zh_path)
            logger.info(f"å·²åˆ é™¤ä¸­é—´æ–‡ä»¶: {final_translated_zh_path}")
            cleaned_files += 1
        if final_translated_en_path and final_translated_en_path.exists():
            os.remove(final_translated_en_path)
            logger.info(f"å·²åˆ é™¤ä¸­é—´æ–‡ä»¶: {final_translated_en_path}")
            cleaned_files += 1
        
        if cleaned_files > 0:
            print(f"ğŸ§¹ å·²æ¸…ç† {cleaned_files} ä¸ªä¸­é—´æ–‡ä»¶")
        
        # å¤„ç†åŸå§‹SRTæ–‡ä»¶
        if temp_srt_path and temp_srt_path.exists():
            if input_file.suffix.lower() != '.srt':
                logger.info(f"ä¿ç•™åŸå§‹è½¬å½•æ–‡ä»¶: {temp_srt_path}")
                print(f"ğŸ’¾ [bold green]ä¿ç•™è½¬å½•æ–‡ä»¶:[/bold green] [cyan]{temp_srt_path.name}[/cyan]")

@app.command("init")
def init():
    """åˆå§‹åŒ–å…¨å±€é…ç½® - æ£€æŸ¥å½“å‰ç›®å½•.envæ–‡ä»¶æˆ–äº¤äº’å¼è¾“å…¥é…ç½®"""
    print("[bold green]ğŸš€ å­—å¹•ç¿»è¯‘å·¥å…·é…ç½®åˆå§‹åŒ–[/bold green]")
    
    # è·å–å…¨å±€é…ç½®ç›®å½•å’Œæ–‡ä»¶è·¯å¾„ - ä½¿ç”¨æ ‡å‡†çš„ .config ç›®å½•
    app_dir = Path.home() / ".config" / APP_NAME
    global_env_path = app_dir / ".env"
    current_env_path = Path(".env")
    
    # ç¡®ä¿å…¨å±€é…ç½®ç›®å½•å­˜åœ¨
    app_dir.mkdir(parents=True, exist_ok=True)
    
    
    
    # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦æœ‰.envæ–‡ä»¶
    if current_env_path.exists():
        
        
        # æ˜¾ç¤ºå½“å‰.envæ–‡ä»¶å†…å®¹ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
        try:
            with open(current_env_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            
            for line in content.split('\n'):
                if line.strip() and not line.strip().startswith('#'):
                    if 'API_KEY' in line:
                        key, value = line.split('=', 1)
                        masked_value = value[:10] + '*' * (len(value) - 10) if len(value) > 10 else '*' * len(value)
                        print(f"   {key}={masked_value}")
                    else:
                        print(f"   {line}")
        except Exception as e:
            print(f"âš ï¸  è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # è¯¢é—®æ˜¯å¦å¤åˆ¶
        
        
        # ä½¿ç”¨æ ‡å‡†è¾“å…¥è¯»å–ç”¨æˆ·é€‰æ‹©
        response = typer.prompt("æ˜¯å¦å°†æ­¤é…ç½®å¤åˆ¶åˆ°å…¨å±€é…ç½®? (y/N)", default="n", show_default=False).lower()
        
        if response in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']:
            try:
                import shutil
                shutil.copy2(current_env_path, global_env_path)
                print(f"âœ… é…ç½®å·²å¤åˆ¶åˆ°: [bold green]{global_env_path}[/bold green]")
                print("ğŸ‰ ç°åœ¨ä½ å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ subtitle-translate å‘½ä»¤ï¼")
            except Exception as e:
                print(f"[bold red]âŒ å¤åˆ¶å¤±è´¥: {e}[/bold red]")
                raise typer.Exit(code=1)
        else:
            print("â­ï¸  è·³è¿‡å¤åˆ¶ï¼Œé…ç½®æœªæ›´æ”¹")
    
    else:
        
        
        # äº¤äº’å¼è¾“å…¥é…ç½®
        
        base_url = typer.prompt("ğŸŒ APIåŸºç¡€URL", default="https://api.openai.com/v1")
        
        # APIå¯†é’¥
        api_key = typer.prompt("ğŸ”‘ APIå¯†é’¥")
        
        if not api_key.strip():
            print("[bold red]âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º[/bold red]")
            raise typer.Exit(code=1)
        
        # LLMæ¨¡å‹
        model_options = [
            "gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo",
            "claude-3-sonnet", "claude-3-haiku",
            "google/gemini-2.5-flash-lite-preview-06-17"
        ]
        
        
        
        llm_model = typer.prompt("è¯·é€‰æ‹©LLMæ¨¡å‹ (è¾“å…¥åºå·æˆ–ç›´æ¥è¾“å…¥æ¨¡å‹å)", default="gpt-4o-mini")
        
        # å¦‚æœè¾“å…¥çš„æ˜¯æ•°å­—ï¼Œè½¬æ¢ä¸ºå¯¹åº”çš„æ¨¡å‹
        if llm_model.isdigit():
            idx = int(llm_model) - 1
            if 0 <= idx < len(model_options):
                llm_model = model_options[idx]
            else:
                print("âš ï¸  æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: gpt-4o-mini")
                llm_model = "gpt-4o-mini"
        
        # å¯é€‰é…ç½®
        log_level = typer.prompt("ğŸ“Š æ—¥å¿—çº§åˆ« (DEBUG/INFO/WARNING/ERROR)", default="INFO").upper()
        
        debug_response = typer.prompt("ğŸ› å¯ç”¨è°ƒè¯•æ¨¡å¼? (y/N)", default="n", show_default=False).lower()
        debug_mode = debug_response in ['y', 'yes', 'æ˜¯', 'ç¡®å®š']
        
        # ç”Ÿæˆé…ç½®æ–‡ä»¶å†…å®¹
        config_content = f"""# Subtitle Translator é…ç½®æ–‡ä»¶
# ç”± subtitle-translate init å‘½ä»¤è‡ªåŠ¨ç”Ÿæˆ

# OpenAI API é…ç½® (å¿…éœ€)
# API åŸºç¡€URL
OPENAI_BASE_URL={base_url}

# API å¯†é’¥
OPENAI_API_KEY={api_key}

# é»˜è®¤ LLM æ¨¡å‹
LLM_MODEL={llm_model}

# å¯é€‰é…ç½®
# æ—¥å¿—çº§åˆ«
LOG_LEVEL={log_level}

# è°ƒè¯•æ¨¡å¼
DEBUG={str(debug_mode).lower()}

# ä½¿ç”¨è¯´æ˜
# 1. æ­¤é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°å…¨å±€é…ç½®ç›®å½• (~/.config/subtitle_translator/.env)
# 2. ä½ ç°åœ¨å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ subtitle-translate å‘½ä»¤
# 3. å¦‚éœ€ä¿®æ”¹é…ç½®ï¼Œå¯ä»¥ç¼–è¾‘æ­¤æ–‡ä»¶æˆ–é‡æ–°è¿è¡Œ subtitle-translate init
"""
        
        # ä¿å­˜åˆ°å…¨å±€é…ç½®
        try:
            with open(global_env_path, 'w', encoding='utf-8') as f:
                f.write(config_content)
            print(f"\nâœ… é…ç½®å·²ä¿å­˜åˆ°: [bold green]{global_env_path}[/bold green]")
            
            # æ˜¾ç¤ºé…ç½®æ‘˜è¦
            
            print(f"   ğŸŒ API URL: {base_url}")
            print(f"   ğŸ”‘ API Key: {api_key[:10]}{'*' * (len(api_key) - 10)}")
            print(f"   ğŸ¤– LLMæ¨¡å‹: {llm_model}")
            print(f"   ğŸ“Š æ—¥å¿—çº§åˆ«: {log_level}")
            print(f"   ğŸ› è°ƒè¯•æ¨¡å¼: {debug_mode}")
            
            print("\nğŸ‰ é…ç½®å®Œæˆï¼ç°åœ¨ä½ å¯ä»¥åœ¨ä»»æ„ç›®å½•ä¸‹è¿è¡Œ subtitle-translate å‘½ä»¤ï¼")
            
        except Exception as e:
            print(f"[bold red]âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}[/bold red]")
            raise typer.Exit(code=1)
    
    # éªŒè¯é…ç½®
    
    try:
        # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
        global _env_loaded
        _env_loaded = False
        setup_environment()
        
        # æµ‹è¯•APIè¿æ¥
        from .translation_core.utils.test_openai import test_openai
        
        base_url = os.getenv('OPENAI_BASE_URL')
        api_key = os.getenv('OPENAI_API_KEY')
        model = os.getenv('LLM_MODEL')
        
        
        success, message = test_openai(base_url, api_key, model)
        
        if success:
            print("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸï¼")
            print(f"å“åº”: {message[:100]}...")
        else:
            print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {message}")
            
    except Exception as e:
        print(f"âš ï¸  é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ä½†é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜ï¼Œä½ å¯ä»¥ç¨åæ‰‹åŠ¨éªŒè¯")

if __name__ == "__main__":
    app()
