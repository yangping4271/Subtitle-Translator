"""
ä¸»å‘½ä»¤è¡Œæ¥å£æ¨¡å— - ç®€æ´æ¸…æ™°çš„CLIå…¥å£
"""
import glob
import re
import typer
from pathlib import Path
from typing import Optional
from typing_extensions import Annotated

from rich import print

from .env_setup import setup_environment
from .processor import process_single_file
from .config_manager import init_config
from .logger import setup_logger
from .transcription_core.utils import _find_cached_model, _check_network_connectivity, from_pretrained
from .transcription_core import utils as transcription_utils

# é»˜è®¤è½¬å½•æ¨¡å‹
DEFAULT_TRANSCRIPTION_MODEL = "mlx-community/parakeet-tdt-0.6b-v2"

# åˆå§‹åŒ–logger
logger = setup_logger(__name__)


app = typer.Typer(
    help="ä¸€ä¸ªé›†æˆäº†è¯­éŸ³è½¬å½•ã€å­—å¹•ç¿»è¯‘å’Œæ ¼å¼è½¬æ¢çš„å‘½ä»¤è¡Œå·¥å…·",
    epilog="ğŸ’¡ é¦–æ¬¡ä½¿ç”¨è¯·è¿è¡Œ: translate init æ¥é…ç½®APIå¯†é’¥"
)


@app.callback(invoke_without_command=True)
def main(
    ctx: typer.Context,
    input_file: Optional[Path] = typer.Option(None, "--input-file", "-i", help="è¦å¤„ç†çš„å•ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œå¦‚ä¸æŒ‡å®šåˆ™æ‰¹é‡å¤„ç†å½“å‰ç›®å½•ã€‚", exists=True, file_okay=True, dir_okay=False, readable=True),
    max_count: int = typer.Option(-1, "--count", "-n", help="æœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡ï¼Œ-1è¡¨ç¤ºå¤„ç†æ‰€æœ‰æ–‡ä»¶ã€‚"),
    target_lang: str = typer.Option("zh", "--target_lang", "-t", help="ç›®æ ‡ç¿»è¯‘è¯­è¨€ã€‚æ”¯æŒçš„è¯­è¨€ï¼šzh(ç®€ä½“ä¸­æ–‡), zh-tw(ç¹ä½“ä¸­æ–‡), ja(æ—¥æ–‡), ko(éŸ©æ–‡), en(è‹±æ–‡), fr(æ³•æ–‡), de(å¾·æ–‡), es(è¥¿ç­ç‰™æ–‡), pt(è‘¡è„ç‰™æ–‡), ru(ä¿„æ–‡), it(æ„å¤§åˆ©æ–‡), ar(é˜¿æ‹‰ä¼¯æ–‡), th(æ³°æ–‡), vi(è¶Šå—æ–‡)ç­‰ã€‚"),
    output_dir: Optional[Path] = typer.Option(None, "--output_dir", "-o", help="è¾“å‡ºæ–‡ä»¶çš„ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚"),
    model: str = typer.Option("mlx-community/parakeet-tdt-0.6b-v2", "--model", help="ç”¨äºè½¬å½•çš„ Parakeet MLX æ¨¡å‹ã€‚"),
    llm_model: Optional[str] = typer.Option(None, "--llm-model", "-m", help="ç”¨äºç¿»è¯‘çš„LLMæ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ã€‚"),
    reflect: bool = typer.Option(False, "--reflect", "-r", help="å¯ç”¨åæ€ç¿»è¯‘æ¨¡å¼ï¼Œæé«˜ç¿»è¯‘è´¨é‡ä½†ä¼šå¢åŠ å¤„ç†æ—¶é—´ã€‚"),
    debug: bool = typer.Option(False, "--debug", "-d", help="å¯ç”¨è°ƒè¯•æ—¥å¿—çº§åˆ«ï¼Œæ˜¾ç¤ºæ›´è¯¦ç»†çš„å¤„ç†ä¿¡æ¯ã€‚"),
):
    """å­—å¹•ç¿»è¯‘å·¥å…·ä¸»å‘½ä»¤"""
    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return
        
    setup_environment()
    
    # æ—©æœŸéªŒè¯ç›®æ ‡è¯­è¨€ä»£ç ï¼Œæä¾›å‹å¥½é”™è¯¯ä¿¡æ¯
    try:
        _validate_target_language(target_lang)
    except ValueError as e:
        logger.error(f"âŒ å‘½ä»¤è¡Œå‚æ•°é”™è¯¯ - ç›®æ ‡è¯­è¨€: {str(e)}")
        print(f"[bold red]âŒ ç›®æ ‡è¯­è¨€å‚æ•°é”™è¯¯![/bold red]")
        print(str(e))
        print(f"\nğŸ’¡ [bold blue]ä½¿ç”¨ç¤ºä¾‹:[/bold blue]")
        print(f"   translate -t ja  # ç¿»è¯‘æˆæ—¥æ–‡")
        print(f"   translate -t ko  # ç¿»è¯‘æˆéŸ©æ–‡")
        print(f"   translate -t fr  # ç¿»è¯‘æˆæ³•æ–‡")
        raise typer.Exit(code=1)

    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = Path.cwd()
    
    output_dir = output_dir.resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    # è·å–è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    if input_file:
        files_to_process = [input_file]
        logger.info(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: {input_file.name}")
        print(f"å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶: [bold cyan]{input_file.name}[/bold cyan]")
    else:
        files_to_process = _get_batch_files(max_count, llm_model)

    # æ‰¹é‡å¤„ç†æ–‡ä»¶
    _process_files_batch(files_to_process, target_lang, output_dir, model, llm_model, reflect, debug)


def _validate_target_language(target_lang: str):
    """éªŒè¯ç›®æ ‡è¯­è¨€ä»£ç """
    from .translation_core.config import get_target_language
    target_language_name = get_target_language(target_lang)
    print(f"ğŸ¯ [bold green]ç›®æ ‡è¯­è¨€:[/bold green] [cyan]{target_language_name}[/cyan] ([dim]{target_lang}[/dim])")


def _get_batch_files(max_count: int, llm_model: Optional[str]) -> list:
    """è·å–æ‰¹é‡å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨"""
    MEDIA_EXTENSIONS = ["*.srt", "*.mp3", "*.mp4"]

    # æŸ¥æ‰¾æ‰€æœ‰åª’ä½“æ–‡ä»¶
    media_files = []
    for pattern in MEDIA_EXTENSIONS:
        media_files.extend(glob.glob(pattern))
    
    if not media_files:
        print("[bold red]å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶ (*.srt, *.mp3, *.mp4)ã€‚[/bold red]")
        raise typer.Exit(code=1)
    
    # æå–åŸºç¡€æ–‡ä»¶åå¹¶å»é‡æ’åº
    base_names = set()
    for file in media_files:
        # ç§»é™¤æ‰©å±•å
        base_name = re.sub(r'\.(srt|mp3|mp4)$', '', file)
        # ç§»é™¤å„ç§è¯­è¨€åç¼€
        language_suffixes = [r'\.zh$', r'\.zh-cn$', r'\.zh-tw$', r'\.ja$', r'\.en$', r'\.ko$', r'\.fr$', r'\.de$', r'\.es$', r'\.pt$', r'\.ru$', r'\.it$', r'\.ar$', r'\.th$', r'\.vi$']
        for suffix_pattern in language_suffixes:
            base_name = re.sub(suffix_pattern, '', base_name)
        base_names.add(base_name)
    
    base_names = sorted(base_names)
    
    # ä¸ºæ¯ä¸ªåŸºç¡€åç§°æ‰¾åˆ°å¯¹åº”çš„è¾“å…¥æ–‡ä»¶
    files_to_process = []
    for base_name in base_names:
        # è·³è¿‡å·²å­˜åœ¨.assæ–‡ä»¶çš„
        ass_file = Path(f"{base_name}.ass")
        if ass_file.exists():
            print(f"INFO: {base_name}.ass å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†ã€‚")
            continue
        
        # ç¡®å®šè¾“å…¥æ–‡ä»¶ä¼˜å…ˆçº§ï¼šsrt > mp3 > mp4
        input_file_found = None
        for ext in ['.srt', '.mp3', '.mp4']:
            candidate = Path(f"{base_name}{ext}")
            if candidate.exists():
                input_file_found = candidate
                break
        
        if input_file_found:
            files_to_process.append(input_file_found)
            print(f"ğŸ“„ å‘ç°æ–‡ä»¶ [cyan]{input_file_found}[/cyan]")
        else:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ° [yellow]{base_name}[/yellow] çš„è¾“å…¥æ–‡ä»¶")
    
    if not files_to_process:
        print("[bold yellow]æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–°æ–‡ä»¶ã€‚[/bold yellow]")
        raise typer.Exit(code=0)
    
    # åº”ç”¨æ•°é‡é™åˆ¶
    if max_count > 0:
        files_to_process = files_to_process[:max_count]
    
    print(f"[bold green]å¼€å§‹æ‰¹é‡ç¿»è¯‘å¤„ç†ï¼Œå…±{len(files_to_process)}ä¸ªæ–‡ä»¶...[/bold green]")
    if llm_model:
        print(f"ä½¿ç”¨LLMæ¨¡å‹: [bold cyan]{llm_model}[/bold cyan]")
    
    return files_to_process


def _process_files_batch(files_to_process: list, target_lang: str, output_dir: Path, 
                        model: str, llm_model: Optional[str], reflect: bool, debug: bool):
    """æ‰¹é‡å¤„ç†æ–‡ä»¶"""
    count = 0
    generated_ass_files = []
    
    for i, current_input_file in enumerate(files_to_process):
        print()
        logger.info(f"ğŸ¯ å¤„ç†æ–‡ä»¶ ({i+1}/{len(files_to_process)}): {current_input_file.name}")
        print(f"ğŸ¯ å¤„ç†æ–‡ä»¶ ({i+1}/{len(files_to_process)}): [bold cyan]{current_input_file.name}[/bold cyan]")
        
        try:
            process_single_file(
                current_input_file, target_lang, output_dir, model, 
                llm_model, reflect, debug
            )
            count += 1
            logger.info(f"âœ… {current_input_file.stem} å¤„ç†å®Œæˆï¼")
            print(f"[bold green]âœ… {current_input_file.stem} å¤„ç†å®Œæˆï¼[/bold green]")
            
            # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ASSæ–‡ä»¶
            ass_file = output_dir / f"{current_input_file.stem}.ass"
            if ass_file.exists():
                generated_ass_files.append(ass_file)
                logger.info(f"ğŸ“º åŒè¯­ASSæ–‡ä»¶å·²ç”Ÿæˆ: {ass_file.name}")
                print(f"ğŸ“º åŒè¯­ASSæ–‡ä»¶å·²ç”Ÿæˆ: [cyan]{ass_file.name}[/cyan]")
        
        except Exception as e:
            from .translation_core.spliter import SmartSplitError, TranslationError, SummaryError
            if isinstance(e, (SmartSplitError, TranslationError, SummaryError)):
                # è¿™äº›å¼‚å¸¸å·²ç»åœ¨processor.pyä¸­æ˜¾ç¤ºè¿‡äº†ï¼Œè¿™é‡Œä¸é‡å¤æ˜¾ç¤º
                # ä½†éœ€è¦è®°å½•åˆ°æ—¥å¿—ä¸­ç”¨äºç»Ÿè®¡
                logger.info(f"âŒ {current_input_file.stem} å¤„ç†å¤±è´¥: {e}")
            else:
                logger.error(f"âŒ {current_input_file.stem} å¤„ç†å¤±è´¥: {e}")
                print(f"[bold red]âŒ {current_input_file.stem} å¤„ç†å¤±è´¥ï¼{e}[/bold red]")
        
        print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    _show_batch_results(count, generated_ass_files, output_dir)


def _show_batch_results(count: int, generated_ass_files: list, output_dir: Path):
    """æ˜¾ç¤ºæ‰¹é‡å¤„ç†ç»“æœ"""
    print()
    logger.info("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    logger.info(f"æ€»è®¡å¤„ç†æ–‡ä»¶æ•°: {count}")
    print(f"ğŸ‰ [bold green]æ‰¹é‡å¤„ç†å®Œæˆï¼[/bold green] (å¤„ç† [cyan]{count}[/cyan] ä¸ªæ–‡ä»¶)")
    
    # åªæ˜¾ç¤ºæœ¬æ¬¡ç”Ÿæˆçš„ASSæ–‡ä»¶ç»Ÿè®¡
    if count > 0:
        if generated_ass_files:
            logger.info("æœ¬æ¬¡ç”Ÿæˆçš„ASSæ–‡ä»¶ï¼š")
            for f in generated_ass_files:
                logger.info(f"  {f.name}")
            print(f"ğŸ“º [bold green]å·²ç”Ÿæˆ {len(generated_ass_files)} ä¸ªåŒè¯­ASSæ–‡ä»¶[/bold green]")
        
        # è¿‡æ»¤æ‰è¯­è¨€ç‰¹å®šçš„SRTæ–‡ä»¶
        language_patterns = ['.zh.', '.zh-cn.', '.zh-tw.', '.ja.', '.en.', '.ko.', '.fr.', '.de.', '.es.', '.pt.', '.ru.', '.it.', '.ar.', '.th.', '.vi.']
        srt_files = [f for f in output_dir.glob("*.srt") if not any(pattern in f.name for pattern in language_patterns)]
        if srt_files:
            logger.info("åŸå§‹å­—å¹•æ–‡ä»¶ï¼š")
            for f in srt_files:
                logger.info(f"  {f.name}")
    
    logger.info("å¤„ç†å®Œæ¯•ï¼")


@app.command("model")
def model_cmd(
    ctx: typer.Context,
    action: str = typer.Argument(..., help="è¦æ‰§è¡Œçš„æ“ä½œ: list(åˆ—å‡ºå·²ç¼“å­˜æ¨¡å‹), info(æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯), download(é¢„ä¸‹è½½æ¨¡å‹), clean(æ¸…ç†ç¼“å­˜)"),
    model_id: Optional[str] = typer.Argument(None, help=f"æ¨¡å‹ID (downloadå’Œinfoæ“ä½œé»˜è®¤: {DEFAULT_TRANSCRIPTION_MODEL})")
):
    """æ¨¡å‹ç®¡ç†å‘½ä»¤"""
    from rich.console import Console
    from rich.table import Table
    from pathlib import Path
    import os
    import shutil
    
    console = Console()
    
    if action == "list":
        """åˆ—å‡ºå·²ç¼“å­˜çš„æ¨¡å‹"""
        try:
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
            cache_dir = Path(cache_dir) / "hub"
            
            if not cache_dir.exists():
                console.print("[yellow]ğŸ“‚ è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•æ¨¡å‹[/yellow]")
                return
            
            # æŸ¥æ‰¾æ¨¡å‹ç¼“å­˜ç›®å½•
            model_dirs = [d for d in cache_dir.iterdir() if d.is_dir() and d.name.startswith("models--")]
            
            if not model_dirs:
                console.print("[yellow]ğŸ“‚ è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•æ¨¡å‹[/yellow]")
                return
            
            # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            table = Table(title="ğŸ¤– å·²ç¼“å­˜çš„æ¨¡å‹åˆ—è¡¨")
            table.add_column("æ¨¡å‹ID", style="cyan")
            table.add_column("ç¼“å­˜å¤§å°", style="green")
            table.add_column("æœ€åä¿®æ”¹æ—¶é—´", style="dim")
            
            for model_dir in sorted(model_dirs):
                # è§£ææ¨¡å‹ID
                model_id = model_dir.name.replace("models--", "").replace("--", "/")
                
                # è®¡ç®—ç›®å½•å¤§å°
                total_size = sum(f.stat().st_size for f in model_dir.rglob('*') if f.is_file())
                size_mb = total_size / (1024 * 1024)
                
                # è·å–æœ€åä¿®æ”¹æ—¶é—´
                import datetime
                mtime = datetime.datetime.fromtimestamp(model_dir.stat().st_mtime)
                
                table.add_row(
                    model_id,
                    f"{size_mb:.1f} MB",
                    mtime.strftime("%Y-%m-%d %H:%M")
                )
            
            console.print(table)
            console.print(f"\nğŸ“ ç¼“å­˜ä½ç½®: [dim]{cache_dir}[/dim]")
            
        except Exception as e:
            console.print(f"[red]âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}[/red]")
    
    elif action == "info":
        """æ˜¾ç¤ºæŒ‡å®šæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = DEFAULT_TRANSCRIPTION_MODEL
            console.print(f"[dim]ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_id}[/dim]")
        
        try:
            # å°è¯•æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜
            try:
                config_path, weight_path = _find_cached_model(model_id)
                console.print(f"âœ… [green]æ¨¡å‹å·²ç¼“å­˜[/green]: [bold]{model_id}[/bold]")
                console.print(f"ğŸ“„ é…ç½®æ–‡ä»¶: [dim]{config_path}[/dim]")
                console.print(f"âš–ï¸  æƒé‡æ–‡ä»¶: [dim]{weight_path}[/dim]")
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                config_size = Path(config_path).stat().st_size / 1024
                weight_size = Path(weight_path).stat().st_size / (1024 * 1024)
                console.print(f"ğŸ“Š å¤§å°: é…ç½® {config_size:.1f} KB, æƒé‡ {weight_size:.1f} MB")
                
            except FileNotFoundError:
                console.print(f"[yellow]âš ï¸  æ¨¡å‹æœªç¼“å­˜[/yellow]: [bold]{model_id}[/bold]")
                console.print("ğŸ’¡ ä½ å¯ä»¥ä½¿ç”¨ 'translate model download' å‘½ä»¤é¢„ä¸‹è½½æ¨¡å‹")
                
                # æ£€æŸ¥ç½‘ç»œè¿æ¥
                if _check_network_connectivity():
                    console.print("ğŸŒ ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œæ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½")
                else:
                    console.print("[red]ğŸŒ ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹[/red]")
                    
        except Exception as e:
            console.print(f"[red]âŒ è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}[/red]")
    
    elif action == "download":
        """é¢„ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = DEFAULT_TRANSCRIPTION_MODEL
            console.print(f"[dim]ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_id}[/dim]")
        
        try:
            console.print(f"ğŸš€ å¼€å§‹é¢„ä¸‹è½½æ¨¡å‹: [bold]{model_id}[/bold]")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ç¼“å­˜
            try:
                _find_cached_model(model_id)
                console.print(f"âœ… [green]æ¨¡å‹å·²å­˜åœ¨äºæœ¬åœ°ç¼“å­˜[/green]")
                return
            except FileNotFoundError:
                pass
            
            # ä¸‹è½½æ¨¡å‹
            model = from_pretrained(model_id, show_progress=True)
            console.print(f"\nğŸ‰ [bold green]æ¨¡å‹é¢„ä¸‹è½½å®Œæˆ![/bold green]")
            console.print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜ï¼Œåç»­ä½¿ç”¨æ—¶å°†ç›´æ¥åŠ è½½")
            
        except Exception as e:
            console.print(f"[red]âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {str(e)}[/red]")
    
    elif action == "clean":
        """æ¸…ç†æ¨¡å‹ç¼“å­˜"""
        try:
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
            cache_dir = Path(cache_dir) / "hub"
            
            if not cache_dir.exists():
                console.print("[yellow]ğŸ“‚ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†[/yellow]")
                return
            
            # è®¡ç®—ç¼“å­˜å¤§å°
            total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())
            size_mb = total_size / (1024 * 1024)
            
            # è¯¢é—®ç¡®è®¤
            if size_mb > 0:
                console.print(f"âš ï¸  [yellow]å³å°†æ¸…ç† {size_mb:.1f} MB çš„æ¨¡å‹ç¼“å­˜[/yellow]")
                console.print(f"ğŸ“ ç¼“å­˜ä½ç½®: [dim]{cache_dir}[/dim]")
                
                confirm = typer.confirm("ç¡®å®šè¦æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜å—ï¼Ÿ")
                if not confirm:
                    console.print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return
                
                # æ¸…ç†ç¼“å­˜
                shutil.rmtree(cache_dir)
                console.print("âœ… [green]æ¨¡å‹ç¼“å­˜æ¸…ç†å®Œæˆ[/green]")
            else:
                console.print("[yellow]ğŸ“‚ ç¼“å­˜ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†[/yellow]")
                
        except Exception as e:
            console.print(f"[red]âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}[/red]")
    
    else:
        console.print(f"[red]âŒ æœªçŸ¥æ“ä½œ: {action}[/red]")
        console.print("ğŸ’¡ æ”¯æŒçš„æ“ä½œ: list, info, download, clean")
        console.print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        console.print("   translate model list                                    # åˆ—å‡ºå·²ç¼“å­˜æ¨¡å‹")
        console.print("   translate model info                                    # æ˜¾ç¤ºé»˜è®¤æ¨¡å‹ä¿¡æ¯")
        console.print("   translate model info mlx-community/parakeet-tdt-0.6b-v2  # æ˜¾ç¤ºæŒ‡å®šæ¨¡å‹ä¿¡æ¯")
        console.print("   translate model download                                      # é¢„ä¸‹è½½é»˜è®¤æ¨¡å‹")
        console.print("   translate model download mlx-community/parakeet-tdt-0.6b-v2  # é¢„ä¸‹è½½æŒ‡å®šæ¨¡å‹")
        console.print("   translate model clean                                   # æ¸…ç†ç¼“å­˜")


@app.command("init")
def init():
    """åˆå§‹åŒ–å…¨å±€é…ç½® - æ£€æŸ¥å½“å‰ç›®å½•.envæ–‡ä»¶æˆ–äº¤äº’å¼è¾“å…¥é…ç½®"""
    import traceback
    print("ğŸš€ å¼€å§‹åˆå§‹åŒ–é…ç½®...")
    try:
        # è®¾ç½®ç¯å¢ƒæ—¶å…è®¸ç¼ºå°‘é…ç½®
        setup_environment(allow_missing_config=True)
        init_config()
        print("âœ… é…ç½®åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}")
        print(f"[bold red]âŒ é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}[/bold red]")
        print(f"[bold red]è¯¦ç»†é”™è¯¯ä¿¡æ¯:[/bold red]")
        traceback.print_exc()
        raise typer.Exit(code=1)


if __name__ == "__main__":
    app() 