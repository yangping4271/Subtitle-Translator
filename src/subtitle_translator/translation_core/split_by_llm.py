import re
from typing import List, Optional

from .prompts import SPLIT_SYSTEM_PROMPT
from .config import SubtitleConfig, get_default_config
from .llm_client import LLMClient
from .utils.errors import extract_error_message, get_error_suggestions
from .utils.api import validate_api_response
from ..logger import setup_logger

logger = setup_logger("split_by_llm")

def count_words(text: str) -> int:
    """
    ç»Ÿè®¡æ–‡æœ¬ä¸­è‹±æ–‡å•è¯æ•°
    Args:
        text: è¾“å…¥æ–‡æœ¬ï¼Œè‹±æ–‡
    Returns:
        int: è‹±æ–‡å•è¯æ•°
    """
    english_text = re.sub(r'[\u4e00-\u9fff]', ' ', text)
    english_words = english_text.strip().split()
    return len(english_words)

def split_by_end_marks(sentence: str) -> List[str]:
    """
    æŒ‰æ˜ç¡®çš„å¥å­ç»“æŸæ ‡è®°æ‹†åˆ†å¥å­ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    Args:
        sentence: éœ€è¦æ‹†åˆ†çš„å¥å­
        
    Returns:
        List[str]: æ‹†åˆ†åçš„å¥å­åˆ—è¡¨
    """
    # åªå¤„ç†æ˜ç¡®çš„å¥å­ç»“æŸæ ‡è®°ï¼Œé¿å…è¿‡åº¦åˆ†å‰²
    end_marks = [". ", "! ", "? "]
    positions = []
    
    # æŸ¥æ‰¾å¥å­ç»“æŸæ ‡è®°çš„ä½ç½®
    for mark in end_marks:
        start = 0
        while True:
            pos = sentence.find(mark, start)
            if pos == -1:
                break
            # ç¡®ä¿ä¸æ˜¯å°æ•°ç‚¹
            if mark == ". " and pos > 0 and sentence[pos-1].isdigit():
                start = pos + 1
                continue
            positions.append(pos + 1)  # æ ‡ç‚¹åçš„ä½ç½®
            start = pos + 1
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æŸæ ‡è®°ï¼Œè¿”å›åŸå¥å­
    if not positions:
        return [sentence]
    
    # æ‰§è¡Œåˆ†å‰²
    positions.sort()
    segments = []
    start = 0
    
    for pos in positions:
        segment = sentence[start:pos].strip()
        # ç¡®ä¿æ¯æ®µè‡³å°‘æœ‰3ä¸ªå•è¯æ‰åˆ†å‰²
        if segment and count_words(segment) >= 3:
            segments.append(segment)
            start = pos
    
    # å¤„ç†æœ€åä¸€æ®µ
    last_segment = sentence[start:].strip()
    if last_segment:
        if segments and count_words(last_segment) < 2:
            # æœ€åä¸€æ®µå¤ªçŸ­ï¼Œåˆå¹¶åˆ°å‰ä¸€æ®µ
            segments[-1] += " " + last_segment
        else:
            segments.append(last_segment)
    
    # è®°å½•åˆ†å‰²ç»“æœ
    if len(segments) > 1:
        logger.info(f"âœ‚ï¸ æ ‡ç‚¹åˆ†å‰²: {len(segments)}æ®µ")
    
    return segments if len(segments) > 1 else [sentence]

def split_by_llm(text: str,
                model: Optional[str] = None,
                max_word_count_english: int = 14,
                max_retries: int = 3,
                batch_index: Optional[int] = None) -> List[str]:
    """
    ä½¿ç”¨LLMæ‹†åˆ†å¥å­
    
    Args:
        text: è¦æ‹†åˆ†çš„æ–‡æœ¬
        model: ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„æ–­å¥æ¨¡å‹
        max_word_count_english: è‹±æ–‡æœ€å¤§å•è¯æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        batch_index: æ‰¹æ¬¡ç´¢å¼•ï¼Œç”¨äºæ—¥å¿—æ˜¾ç¤º
        
    Returns:
        List[str]: æ‹†åˆ†åçš„å¥å­åˆ—è¡¨
    """
    logger.info(f"ğŸ“ å¤„ç†æ–‡æœ¬: å…±{count_words(text)}ä¸ªå•è¯")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    config = SubtitleConfig()
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„æ–­å¥æ¨¡å‹
    if model is None:
        model = config.split_model

    llm = LLMClient.get_instance(config)
    client = llm.client
    
    # ä½¿ç”¨ç³»ç»Ÿæç¤ºè¯
    system_prompt = SPLIT_SYSTEM_PROMPT.format(max_word_count_english=max_word_count_english)
    
    # åœ¨ç”¨æˆ·æç¤ºä¸­æ·»åŠ å¯¹ç©ºæ ¼çš„å¼ºè°ƒ
    user_prompt = f"Please use multiple <br> tags to separate the following sentence. Make sure to preserve all spaces and punctuation exactly as they appear in the original text:\n{text}"

    try:
        # è°ƒç”¨API
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.2,
            timeout=80
        )

        result = validate_api_response(response)
        if not result:
            raise Exception("APIè¿”å›ä¸ºç©º")
        logger.info(f"APIè¿”å›ç»“æœ: \n\n{result}\n")

        # 0. é¦–å…ˆç§»é™¤<think>å’Œ</think>æ ‡ç­¾
        result = re.sub(r'<think>.*?</think>', '', result, flags=re.DOTALL)

        # æ¸…ç†å’Œåˆ†å‰²æ–‡æœ¬ - ç®€åŒ–å¤„ç†ï¼Œä¿ç•™åŸå§‹æ ¼å¼
        result = re.sub(r'\n+', '', result)
        
        # ç›´æ¥æŒ‰<br>åˆ†å‰²ï¼Œä¿ç•™åŸå§‹æ ¼å¼å’Œç©ºæ ¼
        sentences = result.split("<br>")
        
        # æ¸…ç†ç©ºç™½è¡Œï¼Œä½†ä¿ç•™å†…éƒ¨ç©ºæ ¼
        sentences = [seg.strip() for seg in sentences if seg.strip()]

        # å››å±‚é˜²æŠ¤æœºåˆ¶éªŒè¯å¥å­é•¿åº¦
        # åŠ¨æ€è®¡ç®—é˜ˆå€¼ï¼ˆåŸºäºé…ç½®çš„å€æ•°å‚æ•°ï¼‰
        config = get_default_config()
        tolerance_threshold = int(max_word_count_english * config.tolerance_multiplier)      # è½»åº¦å®¹å¿é˜ˆå€¼
        warning_threshold = int(max_word_count_english * config.warning_multiplier)         # è­¦å‘Šé˜ˆå€¼
        max_threshold = int(max_word_count_english * config.max_multiplier)                 # æœ€å¤§é˜ˆå€¼

        new_sentences = []
        stats = {
            'normal': 0,        # â‰¤ target
            'tolerated': 0,     # target < x â‰¤ tolerance
            'optimized': 0,     # tolerance < x â‰¤ warningï¼ˆç»è¿‡ä¼˜åŒ–ï¼‰
            'forced': 0,        # warning < x â‰¤ maxï¼ˆå¼ºåˆ¶æ‹†åˆ†ï¼‰
            'rejected': 0       # > maxï¼ˆä¸¥é‡è¶…æ ‡ï¼Œå¼ºåˆ¶å¤šæ¬¡æ‹†åˆ†ï¼‰
        }

        for sentence in sentences:
            # é¦–å…ˆæŒ‰ç»“æŸæ ‡è®°æ‹†åˆ†å¥å­
            segments = split_by_end_marks(sentence)

            # å¯¹æ¯ä¸ªåˆ†æ®µè¿›è¡Œå››å±‚éªŒè¯
            for segment in segments:
                word_count = count_words(segment)

                # å±‚çº§1ï¼šæ­£å¸¸èŒƒå›´ (â‰¤ target)
                if word_count <= max_word_count_english:
                    new_sentences.append(segment)
                    stats['normal'] += 1

                # å±‚çº§2ï¼šè½»åº¦å®¹å¿å±‚ (target < x â‰¤ tolerance)
                elif word_count <= tolerance_threshold:
                    new_sentences.append(segment)
                    stats['tolerated'] += 1
                    logger.info(f"âœ“ è½»åº¦è¶…æ ‡({word_count}/{max_word_count_english}å­—): {segment[:40]}...")

                # å±‚çº§3ï¼šå¼ºåˆ¶ä¼˜åŒ–å±‚ (tolerance < x â‰¤ warning)
                elif word_count <= warning_threshold:
                    logger.info(f"ğŸ”§ å°è¯•ä¼˜åŒ–({word_count}/{max_word_count_english}å­—): {segment[:40]}...")
                    split_results = aggressive_split(segment, max_word_count_english)

                    if len(split_results) > 1:
                        stats['optimized'] += 1
                        logger.info(f"âœ… ä¼˜åŒ–æˆåŠŸ: åˆ†ä¸º{len(split_results)}æ®µ")
                        new_sentences.extend(split_results)
                    else:
                        # ä¼˜åŒ–å¤±è´¥ï¼Œä½†ä»åœ¨å¯æ¥å—èŒƒå›´å†…
                        stats['tolerated'] += 1
                        logger.warning(f"âš ï¸ ä¼˜åŒ–å¤±è´¥ï¼Œæ¥å—åŸå¥({word_count}å­—)")
                        new_sentences.append(segment)

                # å±‚çº§4ï¼šæ™ºèƒ½æ‹†åˆ†å±‚ (warning < x â‰¤ max) - å…ˆå°è¯•æ™ºèƒ½åˆ†å‰²ï¼Œå¤±è´¥å†å¼ºåˆ¶ç­‰åˆ†
                # å±‚çº§5ï¼šä¸¥é‡è¶…æ ‡å±‚ (> max) - åŒæ ·å¤„ç†é€»è¾‘
                else:
                    is_severe = word_count > max_threshold
                    level_name = "ä¸¥é‡è¶…æ ‡" if is_severe else "è¶…å‡ºè­¦å‘Šé˜ˆå€¼"
                    log_func = logger.error if is_severe else logger.warning
                    stat_key = 'rejected' if is_severe else 'forced'

                    log_func(f"{level_name}({word_count}/{max_word_count_english}å­—): {segment[:40]}...")
                    split_results = aggressive_split(segment, max_word_count_english)

                    if len(split_results) > 1:
                        stats['optimized'] += 1
                        logger.info(f"æ™ºèƒ½åˆ†å‰²æˆåŠŸ: åˆ†ä¸º{len(split_results)}æ®µ")
                        new_sentences.extend(split_results)
                    else:
                        logger.warning(f"æ™ºèƒ½åˆ†å‰²å¤±è´¥ï¼Œä½¿ç”¨é™çº§åˆ†å‰²")
                        new_sentences.extend(fallback_split(segment, max_word_count_english, warning_threshold))
                        stats[stat_key] += 1

        sentences = new_sentences

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯ï¼ˆä½¿ç”¨åŠ¨æ€é˜ˆå€¼æ˜¾ç¤ºï¼‰
        logger.info(f"ğŸ“Š æ–­å¥è´¨é‡ç»Ÿè®¡:")
        logger.info(f"   âœ… æ­£å¸¸: {stats['normal']}å¥ (â‰¤{max_word_count_english}å­—)")
        if stats['tolerated'] > 0:
            logger.info(f"   âœ“ è½»åº¦è¶…æ ‡: {stats['tolerated']}å¥ ({max_word_count_english}-{tolerance_threshold}å­—)")
        if stats['optimized'] > 0:
            logger.info(f"   ğŸ”§ ä¼˜åŒ–æ‹†åˆ†: {stats['optimized']}å¥ ({tolerance_threshold}-{warning_threshold}å­—)")
        if stats['forced'] > 0:
            logger.warning(f"   ğŸ”¨ å¼ºåˆ¶æ‹†åˆ†: {stats['forced']}å¥ ({warning_threshold}-{max_threshold}å­—)")
        if stats['rejected'] > 0:
            logger.error(f"   âŒ ä¸¥é‡è¶…æ ‡: {stats['rejected']}å¥ (>{max_threshold}å­—)")

        # éªŒè¯ç»“æœ
        word_count = count_words(text)
        expected_segments = word_count / max_word_count_english
        actual_segments = len(sentences)

        if actual_segments < expected_segments * 0.9:
            logger.warning(f"âš ï¸ æ–­å¥æ•°é‡ä¸è¶³ï¼šé¢„æœŸ {expected_segments:.1f}ï¼Œå®é™… {actual_segments}")

        batch_prefix = f"[æ‰¹æ¬¡{batch_index}]" if batch_index else ""
        logger.info(f"âœ… {batch_prefix} æ–­å¥å®Œæˆ: {len(sentences)} ä¸ªå¥å­")
        return sentences
        
    except Exception as e:
        if max_retries > 0:
            logger.warning(f"APIè°ƒç”¨å¤±è´¥ï¼Œç¬¬{4-max_retries}æ¬¡é‡è¯•: {extract_error_message(str(e))}")
            return split_by_llm(text, model, max_word_count_english, max_retries-1, batch_index)
        else:
            error_msg = extract_error_message(str(e))
            logger.error(f"æ™ºèƒ½æ–­å¥å¤±è´¥: {error_msg}")

            # æ ¹æ®é”™è¯¯ç±»å‹ç»™å‡ºé’ˆå¯¹æ€§å»ºè®®
            suggestions = get_error_suggestions(str(e), model)

            # åˆ›å»ºä¸€ä¸ªæºå¸¦å»ºè®®çš„è‡ªå®šä¹‰å¼‚å¸¸ç±»å‹
            from ..exceptions import SmartSplitError
            raise SmartSplitError(error_msg, suggestions)


def aggressive_split(text: str, max_words: int) -> List[str]:
    """
    æ™ºèƒ½åˆ†å‰²ï¼šåŸºäºè¯­ä¹‰è¾¹ç•Œçš„æ‹†åˆ†

    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆåŸºäºæ ‡ç‚¹ç¬¦å·ï¼ˆå¥å·ã€åˆ†å·ã€é€—å·ç­‰ï¼‰
    2. å…¶æ¬¡åŸºäºè¿æ¥è¯ï¼ˆå¹¶åˆ—è¿è¯ã€ä»å±è¿è¯ã€å…³ç³»ä»£è¯ï¼‰
    3. å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„è¯­ä¹‰è¾¹ç•Œï¼Œè¿”å›åŸå¥ï¼ˆè®©è°ƒç”¨æ–¹å†³å®šæ˜¯å¦å¼ºåˆ¶æ‹†åˆ†ï¼‰

    Args:
        text: éœ€è¦åˆ†å‰²çš„æ–‡æœ¬
        max_words: æœ€å¤§å•è¯æ•°é™åˆ¶

    Returns:
        åˆ†å‰²åçš„å¥å­åˆ—è¡¨
        - æ‰¾åˆ°è¯­ä¹‰è¾¹ç•Œï¼šè¿”å›å¤šä¸ªç‰‡æ®µï¼ˆlen â‰¥ 2ï¼‰
        - æ‰¾ä¸åˆ°è¾¹ç•Œï¼šè¿”å›åŸå¥ [text]ï¼ˆlen = 1ï¼‰
    """
    words = text.split()
    word_count = len(words)

    # å¦‚æœå·²ç»æ»¡è¶³è¦æ±‚ï¼Œç›´æ¥è¿”å›
    if word_count <= max_words:
        return [text]

    logger.info(f"ğŸ”§ å°è¯•æ™ºèƒ½åˆ†å‰²: {word_count}å­— -> ç›®æ ‡â‰¤{max_words}å­—")

    # ============ ç­–ç•¥1: è§„åˆ™åŒ¹é…åˆ†å‰²ï¼ˆ6å±‚ä¼˜å…ˆçº§ï¼‰ ============
    # ä¼˜å…ˆçº§è®¾è®¡åŸåˆ™ï¼šä¿æŠ¤è¯­ä¹‰å®Œæ•´æ€§ï¼Œé¿å…ç ´åä¸å¯åˆ†å‰²çš„è¯­ä¹‰å•å…ƒ
    # å·²ç§»é™¤åŸä¼˜å…ˆçº§7ï¼ˆä»‹è¯çŸ­è¯­ï¼‰ï¼Œå› å…¶å®¹æ˜“ç ´åè¯­ä¹‰ï¼Œå®é™…è§¦å‘ç‡<1%
    split_candidates = []

    # ä¼˜å…ˆçº§1: å¥å­ç»“æŸæ ‡è®°
    for i, word in enumerate(words):
        if i > 2 and i < word_count - 2:  # é¿å…å¤ªçŸ­çš„ç‰‡æ®µ
            if word.rstrip().endswith(('.', '!', '?')):
                split_candidates.append((i + 1, 10, f"å¥å·'{word[-1]}'"))

    # ä¼˜å…ˆçº§2: åˆ†å·/å†’å·
    for i, word in enumerate(words):
        if i > 2 and i < word_count - 2:
            if word.rstrip().endswith((';', ':')):
                split_candidates.append((i + 1, 9, f"åˆ†éš”'{word[-1]}'"))

    # ä¼˜å…ˆçº§3: é€—å·
    for i, word in enumerate(words):
        if i > 2 and i < word_count - 2:
            if word.rstrip().endswith(','):
                split_candidates.append((i + 1, 8, f"é€—å·"))

    # ä¼˜å…ˆçº§4: å¹¶åˆ—è¿è¯
    coordinating_conj = ["and", "but", "or", "so", "yet", "nor"]
    for i in range(3, word_count - 2):
        word = words[i].lower().strip(",.!?")
        if word in coordinating_conj:
            split_candidates.append((i, 7, f"å¹¶åˆ—è¿è¯'{word}'"))

    # ä¼˜å…ˆçº§5: ä»å±è¿è¯ï¼ˆåœ¨å¥ä¸­çš„ä½ç½®ï¼‰
    subordinating_conj = ["because", "although", "though", "unless", "since",
                          "while", "whereas", "if", "when", "before", "after"]
    for i in range(3, word_count - 2):
        word = words[i].lower().strip(",.!?")
        if word in subordinating_conj:
            split_candidates.append((i, 6, f"ä»å±è¿è¯'{word}'"))

    # ä¼˜å…ˆçº§6: å…³ç³»ä»£è¯ï¼ˆä»å¥å¼€å§‹ï¼‰
    relative_pronouns = ["that", "which", "who", "whom", "whose", "where", "when", "whether"]
    for i in range(3, word_count - 2):
        word = words[i].lower().strip(",.!?")
        if word in relative_pronouns:
            split_candidates.append((i, 5, f"å…³ç³»è¯'{word}'"))

    # å¦‚æœæ‰¾åˆ°å€™é€‰ç‚¹ï¼Œé€‰æ‹©æœ€ä¼˜çš„
    if split_candidates:
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ŒåŒä¼˜å…ˆçº§é€‰æ‹©æœ€æ¥è¿‘ä¸­ç‚¹çš„
        mid_point = word_count // 2
        split_candidates.sort(key=lambda x: (-x[1], abs(x[0] - mid_point)))

        best_pos, priority, reason = split_candidates[0]

        # æ‰§è¡Œåˆ†å‰²
        first_part = " ".join(words[:best_pos]).strip()
        second_part = " ".join(words[best_pos:]).strip()

        logger.info(f"âœ… [ç­–ç•¥1] è§„åˆ™åŒ¹é…åˆ†å‰²åœ¨{reason}å¤„ (ä¼˜å…ˆçº§{priority}):")
        logger.info(f"   ç‰‡æ®µ1({count_words(first_part)}å­—): {first_part[:50]}...")
        logger.info(f"   ç‰‡æ®µ2({count_words(second_part)}å­—): {second_part[:50]}...")

        # é€’å½’å¤„ç†ä»ç„¶è¶…é•¿çš„ç‰‡æ®µï¼ˆä½¿ç”¨warning_thresholdä½œä¸ºåˆ¤æ–­æ¡ä»¶ï¼‰
        result = []
        # è®¡ç®—warning_thresholdï¼ˆå…è®¸é€’å½’åçš„ç‰‡æ®µç¨å¾®è¶…æ ‡ï¼‰
        warning_threshold = int(max_words * 1.5)
        for part in [first_part, second_part]:
            if count_words(part) > warning_threshold:
                result.extend(aggressive_split(part, max_words))
            else:
                result.append(part)
        return result

    # ============ æ‰¾ä¸åˆ°è¯­ä¹‰è¾¹ç•Œï¼Œè¿”å›åŸå¥ ============
    logger.warning("âš ï¸ æœªæ‰¾åˆ°è¯­ä¹‰è¾¹ç•Œï¼Œè¿”å›åŸå¥")
    return [text]  # è¿”å›å•å…ƒç´ åˆ—è¡¨ï¼Œè®©è°ƒç”¨æ–¹å†³å®šä¸‹ä¸€æ­¥


def fallback_split(text: str, max_words: int, warning_threshold: int = None) -> List[str]:
    """
    é™çº§åˆ†å‰²ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰ï¼šåœ¨ç†æƒ³åˆ‡åˆ†ç‚¹é™„è¿‘å¯»æ‰¾è¯­ä¹‰è¾¹ç•Œ

    ç­–ç•¥ï¼š
    1. è®¡ç®—ç†æƒ³ç­‰åˆ†ç‚¹ï¼ˆç¡®ä¿æ¯æ®µ â‰¤ max_wordsï¼‰
    2. åœ¨ç†æƒ³ç‚¹å‰å5è¯èŒƒå›´å†…æœç´¢æœ€ä½³åˆ‡åˆ†ä½ç½®
    3. ä¼˜å…ˆé€‰æ‹©æ ‡ç‚¹ï¼ˆå¥å·ã€é€—å·ç­‰ï¼‰
    4. å…¶æ¬¡é€‰æ‹©è¿æ¥è¯ï¼ˆandã€butã€whenç­‰ï¼‰
    5. ä¿åº•é€‰æ‹©è¯è¾¹ç•Œ

    Args:
        text: éœ€è¦åˆ†å‰²çš„æ–‡æœ¬
        max_words: æœ€å¤§å•è¯æ•°é™åˆ¶ï¼ˆç›®æ ‡å€¼ï¼Œå¦‚19ï¼‰
        warning_threshold: è­¦å‘Šé˜ˆå€¼ï¼ˆå¦‚28ï¼‰ï¼Œç”¨äºé€’å½’åˆ¤æ–­ã€‚å¦‚æœä¸ºNoneï¼Œé»˜è®¤ä½¿ç”¨max_words*1.5

    Returns:
        åˆ†å‰²åçš„å¥å­åˆ—è¡¨ï¼Œä¿è¯æ¯æ®µ â‰¤ max_words
    """
    # å¦‚æœæœªæä¾›warning_thresholdï¼Œè®¡ç®—é»˜è®¤å€¼
    if warning_threshold is None:
        warning_threshold = int(max_words * 1.5)

    words = text.split()
    word_count = len(words)

    # è®¡ç®—éœ€è¦åˆ†æˆå‡ æ®µ
    import math
    num_segments = math.ceil(word_count / max_words)

    if num_segments == 1:
        return [text]

    logger.info(f"ğŸ”¨ é™çº§åˆ†å‰²: {word_count}å­— -> {num_segments}æ®µ (æ¯æ®µâ‰¤{max_words}å­—)")

    # è®¡ç®—ç†æƒ³åˆ†å‰²ç‚¹
    segment_size = word_count / num_segments
    ideal_points = [int(segment_size * i) for i in range(1, num_segments)]

    # åœ¨æ¯ä¸ªç†æƒ³ç‚¹é™„è¿‘å¯»æ‰¾æœ€ä½³åˆ†å‰²ä½ç½®
    actual_splits = []
    search_range = 5  # åœ¨ç†æƒ³ç‚¹å‰å5ä¸ªå•è¯èŒƒå›´å†…æœç´¢

    for ideal_pos in ideal_points:
        best_pos = ideal_pos
        best_score = 0

        start = max(1, ideal_pos - search_range)
        end = min(word_count - 1, ideal_pos + search_range)

        for i in range(start, end + 1):
            score = 0
            word = words[i - 1].rstrip()

            # è¯„åˆ†ï¼šæ ‡ç‚¹ä¼˜äºè¿æ¥è¯ä¼˜äºæ™®é€šä½ç½®
            if word.endswith(('.', '!', '?')):
                score = 10
            elif word.endswith((',', ';', ':')):
                score = 8
            elif i < word_count and words[i].lower() in ["and", "but", "or", "so", "because", "when", "while"]:
                score = 6
            else:
                score = 1

            # åŒç­‰åˆ†æ•°ä¸‹ï¼Œä¼˜å…ˆé€‰æ‹©æ›´æ¥è¿‘ç†æƒ³ç‚¹çš„
            if score > best_score or (score == best_score and abs(i - ideal_pos) < abs(best_pos - ideal_pos)):
                best_score = score
                best_pos = i

        actual_splits.append(best_pos)

    # æ‰§è¡Œåˆ†å‰²
    result = []
    start_idx = 0

    for split_pos in actual_splits:
        segment = " ".join(words[start_idx:split_pos]).strip()
        if segment:
            result.append(segment)
        start_idx = split_pos

    # æ·»åŠ æœ€åä¸€æ®µ
    last_segment = " ".join(words[start_idx:]).strip()
    if last_segment:
        result.append(last_segment)

    # è¾“å‡ºåˆ†å‰²ç»“æœ
    logger.info(f"âœ… é™çº§åˆ†å‰²å®Œæˆ: {len(result)}æ®µ")
    for i, segment in enumerate(result, 1):
        seg_words = count_words(segment)
        logger.info(f"   ç‰‡æ®µ{i}({seg_words}å­—): {segment[:50]}...")
        if seg_words > max_words:
            logger.warning(f"   âš ï¸ ç‰‡æ®µ{i}ä»è¶…æ ‡ï¼Œéœ€å†æ¬¡åˆ†å‰²")

    # éªŒè¯ï¼šå¦‚æœä»æœ‰è¶…æ ‡ç‰‡æ®µï¼Œé€’å½’å¤„ç†ï¼ˆä½¿ç”¨warning_thresholdä½œä¸ºåˆ¤æ–­æ¡ä»¶ï¼‰
    final_result = []
    for segment in result:
        if count_words(segment) > warning_threshold:
            # ç®€å•äºŒåˆ†
            seg_words = segment.split()
            mid = len(seg_words) // 2
            final_result.append(" ".join(seg_words[:mid]))
            final_result.append(" ".join(seg_words[mid:]))
        else:
            final_result.append(segment)

    return final_result
