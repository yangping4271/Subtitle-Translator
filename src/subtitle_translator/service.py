"""
å­—å¹•ç¿»è¯‘æœåŠ¡æ¨¡å— - æ ¸å¿ƒç¿»è¯‘æœåŠ¡ç±»
"""
import time
import string
from typing import Optional, Dict, Any, List, Tuple
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

from rich import print

from .translation_core.optimizer import SubtitleOptimizer
from .translation_core.summarizer import SubtitleSummarizer
from .translation_core.spliter import merge_segments
from .translation_core.config import SubtitleConfig
from .translation_core.data import SubtitleData
from .translation_core.utils.test_openai import test_openai
from .logger import setup_logger, log_section_start, log_section_end, log_stats
from .env_setup import OpenAIAPIError


class SubtitleTranslatorService:
    """å­—å¹•ç¿»è¯‘æœåŠ¡ç±»"""
    
    def __init__(self):
        self.config = SubtitleConfig()
        self.summarizer = SubtitleSummarizer(self.config)
        # å»¶è¿Ÿåˆå§‹åŒ–loggerï¼Œåœ¨setup_environmentä¸­åˆå§‹åŒ–
        self.logger = None

    def _get_logger(self):
        """è·å–loggerå®ä¾‹"""
        if self.logger is None:
            from .env_setup import logger
            self.logger = logger
        return self.logger

    def _init_translation_env(self, llm_model: str, show_config: bool = True) -> None:
        """åˆå§‹åŒ–ç¿»è¯‘ç¯å¢ƒé…ç½®"""
        logger = self._get_logger()
        start_time = time.time()
        log_section_start(logger, "ç¿»è¯‘ç¯å¢ƒåˆå§‹åŒ–", "âš™ï¸")
        
        if llm_model:
            self.config.split_model = llm_model
            self.config.summary_model = llm_model
            self.config.translation_model = llm_model

        logger.info(f"ğŸŒ APIç«¯ç‚¹: {self.config.openai_base_url}")
        
        model_config = {
            "æ–­å¥æ¨¡å‹": self.config.split_model,
            "æ€»ç»“æ¨¡å‹": self.config.summary_model,
            "ç¿»è¯‘æ¨¡å‹": self.config.translation_model
        }
        log_stats(logger, model_config, "æ¨¡å‹é…ç½®")
        
        # åªåœ¨éœ€è¦æ—¶æ˜¾ç¤º API é…ç½®
        if show_config:
            print(f"ğŸŒ [bold blue]API é…ç½®:[/bold blue]")
            print(f"   ç«¯ç‚¹: [cyan]{self.config.openai_base_url}[/cyan]")
            # å¯¹ API å¯†é’¥è¿›è¡Œè„±æ•å¤„ç†
            api_key = self.config.openai_api_key
            if api_key:
                if len(api_key) > 12:
                    # å¯¹äºé•¿å¯†é’¥ï¼Œæ˜¾ç¤ºå‰6ä¸ªå’Œå6ä¸ªå­—ç¬¦ï¼Œä¸­é—´ç”¨ * çœç•¥
                    masked_key = f"{api_key[:6]}{'*' * 8}{api_key[-6:]}"
                else:
                    # å¯¹äºçŸ­å¯†é’¥ï¼Œå…¨éƒ¨ç”¨ * æ›¿ä»£
                    masked_key = '*' * len(api_key)
                print(f"   å¯†é’¥: [cyan]{masked_key}[/cyan]")
            else:
                print(f"   å¯†é’¥: [red]æœªè®¾ç½®[/red]")
            
            # æ˜¾ç¤ºæ¨¡å‹é…ç½®
            print(f"ğŸ¤– [bold blue]æ¨¡å‹é…ç½®:[/bold blue]")
            print(f"   æ–­å¥: [cyan]{self.config.split_model}[/cyan]")
            print(f"   æ€»ç»“: [cyan]{self.config.summary_model}[/cyan]")
            print(f"   ç¿»è¯‘: [cyan]{self.config.translation_model}[/cyan]")
        
        elapsed_time = time.time() - start_time
        log_section_end(logger, "ç¿»è¯‘ç¯å¢ƒåˆå§‹åŒ–", elapsed_time, "âœ…")

    def translate_srt(self, input_srt_path: Path, target_lang: str, output_dir: Path,
                      llm_model: Optional[str] = None, skip_env_init: bool = False) -> Path:
        """ç¿»è¯‘å­—å¹•æ–‡ä»¶"""
        logger = self._get_logger()
        try:
            task_start_time = time.time()
            log_section_start(logger, "å­—å¹•ç¿»è¯‘ä»»åŠ¡", "ğŸ¬")
            
            # ç”¨äºæ”¶é›†å„é˜¶æ®µè€—æ—¶çš„å­—å…¸
            stage_times = {}
            
            # è®¾ç½®ç›®æ ‡è¯­è¨€ï¼ˆå¸¦å‹å¥½é”™è¯¯å¤„ç†ï¼‰
            logger.info(f"ğŸŒ è®¾ç½®ç›®æ ‡è¯­è¨€: {target_lang}")
            try:
                self.config.set_target_language(target_lang)
                logger.info(f"âœ… ç›®æ ‡è¯­è¨€å·²è®¾ç½®ä¸º: {self.config.target_language}")
            except ValueError as e:
                # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—
                logger.error(f"âŒ è¯­è¨€è®¾ç½®å¤±è´¥: {str(e)}")
                # ä¸ºç”¨æˆ·æ˜¾ç¤ºå‹å¥½çš„é”™è¯¯ä¿¡æ¯
                print(f"[bold red]âŒ è¯­è¨€è®¾ç½®å¤±è´¥![/bold red]")
                print(str(e))
                raise ValueError(str(e))
            
            # åªåœ¨éœ€è¦æ—¶åˆå§‹åŒ–ç¿»è¯‘ç¯å¢ƒ
            if not skip_env_init:
                self._init_translation_env(llm_model)
            
            # åŠ è½½å­—å¹•æ–‡ä»¶
            from .translation_core.data import load_subtitle
            logger.info("ğŸ“‚ æ­£åœ¨åŠ è½½å­—å¹•æ–‡ä»¶...")
            asr_data = load_subtitle(str(input_srt_path))
            logger.info(f"ğŸ“Š å­—å¹•ç»Ÿè®¡: å…± {len(asr_data.segments)} æ¡å­—å¹•")
            logger.info(f"å­—å¹•å†…å®¹é¢„è§ˆ: {asr_data.to_txt()[:100]}...")  
            
            # æ£€æŸ¥å­—å¹•æ˜¯å¦ä¸ºç©º
            if len(asr_data.segments) == 0:
                logger.info("âš ï¸  SRTæ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡ç¿»è¯‘å¤„ç†")
                print(f"[yellow]âš ï¸  SRTæ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡ç¿»è¯‘å¤„ç†[/yellow]")
                # ä½¿ç”¨ä¸“é—¨çš„ç©ºæ–‡ä»¶å¼‚å¸¸ï¼Œé¿å…æ˜¾ç¤ºå †æ ˆè·Ÿè¸ª
                from .translation_core.spliter import EmptySubtitleError
                raise EmptySubtitleError("SRTæ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç¿»è¯‘")
            
            print(f"ğŸ“Š [bold blue]åŠ è½½å®Œæˆ[/bold blue]")
            
            # å¹¶è¡Œé¢„å¤„ç†é˜¶æ®µï¼šæ–­å¥å’Œæ€»ç»“åŒæ—¶è¿›è¡Œï¼ˆv0.5.x æ€§èƒ½ä¼˜åŒ–ï¼‰
            # å€Ÿé‰´VideoCaptionerçš„è§£å†³æ–¹æ¡ˆï¼šç»Ÿä¸€è½¬æ¢ä¸ºå•è¯çº§åˆ«åè¿›è¡Œæ–­å¥
            # ä¼˜åŠ¿ï¼š1) å¤ç”¨ç°æœ‰æ‰¹é‡æ¡†æ¶ 2) æ— é¢å¤–APIæˆæœ¬ 3) æ—¶é—´æˆ³ç²¾ç¡®åˆ†é… 4) å¹¶è¡Œå¤„ç†èŠ‚çœæ—¶é—´
            preprocessing_start_time = time.time()
            log_section_start(logger, "å¹¶è¡Œé¢„å¤„ç†é˜¶æ®µ", "âš¡")

            print(f"âš¡ [bold cyan]å¯åŠ¨å¹¶è¡Œé¢„å¤„ç†ï¼šæ–­å¥ + å†…å®¹åˆ†æ...[/bold cyan]")

            # å‡†å¤‡åŸå§‹å­—å¹•å†…å®¹ç”¨äºæ€»ç»“ï¼ˆæ–­å¥å‰ï¼‰
            original_subtitle_content = asr_data.to_txt()

            # å¯åŠ¨æ–­å¥ä»»åŠ¡
            def execute_splitting(asr_data_copy: SubtitleData) -> Tuple[SubtitleData, float]:
                """æ‰§è¡Œæ–­å¥å¤„ç†çš„ä»»åŠ¡å‡½æ•°"""
                section_start_time = time.time()
                log_section_start(logger, "å­—å¹•æ–­å¥å¤„ç†", "âœ‚ï¸")

                # æ£€æŸ¥å­—å¹•ç±»å‹å¹¶ç»Ÿä¸€è½¬æ¢ä¸ºå•è¯çº§åˆ«
                if asr_data_copy.is_word_timestamp():
                    print(f"âœ‚ï¸ [bold yellow]æ£€æµ‹åˆ°å•è¯çº§åˆ«å­—å¹•ï¼Œè¿›è¡Œæ™ºèƒ½æ–­å¥...[/bold yellow]")
                    logger.info("æ£€æµ‹åˆ°å•è¯çº§åˆ«æ—¶é—´æˆ³ï¼Œæ‰§è¡Œåˆå¹¶æ–­å¥")
                else:
                    print(f"âœ‚ï¸ [bold yellow]æ£€æµ‹åˆ°ç‰‡æ®µçº§åˆ«å­—å¹•ï¼Œè½¬æ¢ä¸ºå•è¯çº§åˆ«åè¿›è¡Œæ–­å¥...[/bold yellow]")
                    logger.info("æ£€æµ‹åˆ°ç‰‡æ®µçº§åˆ«æ—¶é—´æˆ³ï¼Œå…ˆè½¬æ¢ä¸ºå•è¯çº§åˆ«")
                    # ç»Ÿä¸€è½¬æ¢ä¸ºå•è¯çº§åˆ«å­—å¹•ï¼ˆæ ¸å¿ƒåˆ›æ–°åŠŸèƒ½ï¼‰
                    # ä½¿ç”¨éŸ³ç´ çº§æ—¶é—´æˆ³åˆ†é…ï¼Œæ”¯æŒå¤šè¯­è¨€å¤„ç†
                    asr_data_copy = asr_data_copy.split_to_word_segments()
                    logger.info(f"è½¬æ¢å®Œæˆï¼Œç”Ÿæˆ {len(asr_data_copy.segments)} ä¸ªå•è¯çº§åˆ«ç‰‡æ®µ")

                # æ‰§è¡Œç»Ÿä¸€çš„æ–­å¥å¤„ç†æµç¨‹
                # ç°åœ¨æ‰€æœ‰å­—å¹•éƒ½æ˜¯å•è¯çº§åˆ«ï¼Œå¯ä»¥ä½¿ç”¨ç›¸åŒçš„æ‰¹é‡å¤„ç†ç­–ç•¥
                model = self.config.split_model
                logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
                logger.info(f"ğŸ“ å¥å­é•¿åº¦é™åˆ¶: {self.config.max_word_count_english} å­—")

                asr_data_copy = merge_segments(asr_data_copy, model=model,
                                             num_threads=self.config.thread_num,
                                             save_split=None)

                split_time = time.time() - section_start_time
                log_section_end(logger, "å­—å¹•æ–­å¥å¤„ç†", split_time, "âœ…")
                print(f"âœ… [bold green]æ–­å¥å®Œæˆ[/bold green] (ä¼˜åŒ–ä¸º [cyan]{len(asr_data_copy.segments)}[/cyan] å¥)")

                return asr_data_copy, split_time

            # å¯åŠ¨æ€»ç»“ä»»åŠ¡
            def execute_summarization(subtitle_content: str, input_file: str) -> Tuple[dict, float]:
                """æ‰§è¡Œæ€»ç»“å¤„ç†çš„ä»»åŠ¡å‡½æ•°"""
                summary_start_time = time.time()
                summarize_result = self._get_subtitle_summary(subtitle_content, input_file, is_parallel=True)
                summary_time = time.time() - summary_start_time
                return summarize_result, summary_time

            # å¹¶è¡Œæ‰§è¡Œæ–­å¥å’Œæ€»ç»“ä»»åŠ¡
            with ThreadPoolExecutor(max_workers=2) as executor:
                # æäº¤ä»»åŠ¡
                split_future = executor.submit(execute_splitting, asr_data)
                summary_future = executor.submit(execute_summarization, original_subtitle_content, str(input_srt_path.resolve()))

                # ç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶å¤„ç†ç»“æœ
                try:
                    # è·å–æ–­å¥ç»“æœ
                    asr_data, split_time = split_future.result()
                    stage_times["âœ‚ï¸  æ™ºèƒ½æ–­å¥"] = split_time

                    # è·å–æ€»ç»“ç»“æœ
                    summarize_result, summary_time = summary_future.result()
                    stage_times["ğŸ” å†…å®¹åˆ†æ"] = summary_time

                except Exception as e:
                    # å¤„ç†å¹¶è¡Œä»»åŠ¡ä¸­çš„å¼‚å¸¸
                    logger.error(f"âŒ å¹¶è¡Œé¢„å¤„ç†ä»»åŠ¡å¤±è´¥: {str(e)}")

                    # å®‰å…¨åœ°æ£€æŸ¥ä»»åŠ¡å¼‚å¸¸
                    split_exception = None
                    summary_exception = None

                    try:
                        split_exception = split_future.exception()
                    except Exception:
                        pass

                    try:
                        summary_exception = summary_future.exception()
                    except Exception:
                        pass

                    if split_exception:
                        error_msg = f"æ–­å¥ä»»åŠ¡å¤±è´¥: {split_exception}"
                        logger.error(f"âŒ {error_msg}")
                        from .translation_core.spliter import SmartSplitError
                        raise SmartSplitError(error_msg) from split_exception

                    if summary_exception:
                        error_msg = f"å†…å®¹åˆ†æä»»åŠ¡å¤±è´¥: {summary_exception}"
                        logger.error(f"âŒ {error_msg}")
                        from .translation_core.spliter import SummaryError
                        raise SummaryError(error_msg) from summary_exception

                    # æœªçŸ¥å¼‚å¸¸
                    raise e

            preprocessing_time = time.time() - preprocessing_start_time
            log_section_end(logger, "å¹¶è¡Œé¢„å¤„ç†é˜¶æ®µ", preprocessing_time, "ğŸ‰")
            print(f"ğŸ‰ [bold green]å¹¶è¡Œé¢„å¤„ç†å®Œæˆ[/bold green] (æ€»è€—æ—¶: [cyan]{preprocessing_time:.1f}s[/cyan])")

            # æ·»åŠ å¹¶è¡Œå¤„ç†ç»Ÿè®¡
            stage_times["âš¡ å¹¶è¡Œé¢„å¤„ç†"] = preprocessing_time
            
            # ç¿»è¯‘å­—å¹•
            translate_start_time = time.time()
            translate_result = self._translate_subtitles(asr_data, summarize_result)
            translate_time = time.time() - translate_start_time
            stage_times["ğŸŒ å¸¸è§„ç¿»è¯‘"] = translate_time
            
            # ä¿å­˜å­—å¹•
            logger.info("ğŸ’¾ æ­£åœ¨ä¿å­˜ç¿»è¯‘ç»“æœ...")
            base_name = input_srt_path.stem
            target_lang_output_path = output_dir / f"{base_name}.{target_lang}.srt"
            english_output_path = output_dir / f"{base_name}.en.srt"

            asr_data.save_translations_to_files(
                translate_result,
                str(english_output_path),
                str(target_lang_output_path)
            )
            
            total_elapsed = time.time() - task_start_time
            
            # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
            print()
            self._format_time_stats(stage_times, total_elapsed)
            
            # ä»»åŠ¡å®Œæˆç»Ÿè®¡
            final_stats = {
                "è¾“å…¥æ–‡ä»¶": input_srt_path.name,
                "å­—å¹•æ•°é‡": len(asr_data.segments),
                "ç›®æ ‡è¯­è¨€": target_lang,
                "æ€»è€—æ—¶": f"{total_elapsed:.1f}ç§’"
            }
            log_stats(logger, final_stats, "ä»»åŠ¡å®Œæˆç»Ÿè®¡")
            log_section_end(logger, "å­—å¹•ç¿»è¯‘ä»»åŠ¡", total_elapsed, "ğŸ‰")
            
            return target_lang_output_path
                
        except OpenAIAPIError as e:
            logger.error(f"ğŸš¨ APIé”™è¯¯: {str(e)}")
            raise
        
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ™ºèƒ½æ–­å¥ã€ç¿»è¯‘ã€æ€»ç»“æˆ–ç©ºæ–‡ä»¶å¼‚å¸¸ï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥ä¼ æ’­
            from .translation_core.spliter import SmartSplitError, TranslationError, SummaryError, EmptySubtitleError
            if isinstance(e, (SmartSplitError, TranslationError, SummaryError, EmptySubtitleError)):
                raise e
            
            logger.error(f"ğŸ’¥ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            raise

    def _get_subtitle_summary(self, subtitle_content: str, input_file: str, is_parallel: bool = False) -> dict:
        """è·å–å­—å¹•å†…å®¹æ‘˜è¦

        Args:
            subtitle_content: å­—å¹•å†…å®¹æ–‡æœ¬
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            is_parallel: æ˜¯å¦ä¸ºå¹¶è¡Œè°ƒç”¨æ¨¡å¼
        """
        logger = self._get_logger()

        # åœ¨å¹¶è¡Œæ¨¡å¼ä¸‹ï¼Œä¸é‡å¤è¾“å‡ºæ—¥å¿—å¤´éƒ¨ä¿¡æ¯
        if not is_parallel:
            print(f"ğŸ” [bold cyan]å†…å®¹åˆ†æä¸­...[/bold cyan]")

        logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.config.summary_model}")
        summarize_result = self.summarizer.summarize(subtitle_content, input_file)
        logger.info(f"æ€»ç»“å­—å¹•å†…å®¹:\n{summarize_result.get('summary')}\n")

        # åœ¨å¹¶è¡Œæ¨¡å¼ä¸‹ï¼Œä¸é‡å¤è¾“å‡ºå®Œæˆä¿¡æ¯
        if not is_parallel:
            print(f"âœ… [bold green]å†…å®¹åˆ†æå®Œæˆ[/bold green]")

        return summarize_result

    def _translate_subtitles(self, asr_data: SubtitleData, summarize_result: dict) -> list:
        """ç¿»è¯‘å­—å¹•å†…å®¹"""
        logger = self._get_logger()
        section_start_time = time.time()
        log_section_start(logger, "å­—å¹•ç¿»è¯‘", "ğŸŒ")

        print(f"ğŸŒ [bold magenta]ç¿»è¯‘ä¸­...[/bold magenta]")

        logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.config.translation_model}")
        logger.info(f"âš¡ çº¿ç¨‹æ•°: {self.config.thread_num}")

        try:
            translator = SubtitleOptimizer(config=self.config)
            translate_result = translator.translate(asr_data, summarize_result)

            # è·å–ä¼˜åŒ–ç»Ÿè®¡
            stats = self._get_optimization_stats(translator.batch_logs)

            section_elapsed = time.time() - section_start_time
            log_section_end(logger, "å­—å¹•ç¿»è¯‘", section_elapsed, "ğŸ‰")
            print(f"âœ… [bold green]ç¿»è¯‘å®Œæˆ[/bold green]")
            
            # æ˜¾ç¤ºä¼˜åŒ–ç»Ÿè®¡
            if stats['total_changes'] > 0:
                print(f"ğŸ“Š [bold blue]ä¼˜åŒ–ç»Ÿè®¡:[/bold blue]")
                if stats['format_changes'] > 0:
                    print(f"   æ ¼å¼ä¼˜åŒ–: [cyan]{stats['format_changes']}[/cyan] é¡¹")
                if stats['content_changes'] > 0:
                    print(f"   å†…å®¹ä¿®æ”¹: [cyan]{stats['content_changes']}[/cyan] é¡¹")
                if stats['wrong_changes'] > 0:
                    print(f"   [yellow]å¯ç–‘æ›¿æ¢: {stats['wrong_changes']} é¡¹[/yellow]")
                print(f"   æ€»è®¡: [cyan]{stats['total_changes']}[/cyan] é¡¹ä¼˜åŒ–")
            else:
                print("ğŸ“Š [dim]æ— éœ€ä¼˜åŒ–è°ƒæ•´[/dim]")
            
            return translate_result
        except Exception as e:
            # ä¸åœ¨è¿™é‡Œè®°å½•é”™è¯¯ä¿¡æ¯ï¼Œé¿å…é‡å¤æ˜¾ç¤º  
            # é”™è¯¯ä¿¡æ¯å·²ç»åœ¨processor.pyä¸­å¤„ç†è¿‡äº†
            raise

    def _get_optimization_stats(self, batch_logs: list) -> dict:
        """ä»batch_logsä¸­è·å–ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        
        def is_format_change_only(original, optimized):
            """åˆ¤æ–­æ˜¯å¦åªæœ‰æ ¼å¼å˜åŒ–ï¼ˆå¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·ï¼‰"""
            # å¿½ç•¥å¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·åæ¯”è¾ƒ
            original_normalized = original.lower().translate(str.maketrans('', '', string.punctuation))
            optimized_normalized = optimized.lower().translate(str.maketrans('', '', string.punctuation))
            return original_normalized == optimized_normalized

        def is_wrong_replacement(original, optimized):
            """æ£€æµ‹æ˜¯å¦å­˜åœ¨é”™è¯¯çš„æ›¿æ¢ï¼ˆæ›¿æ¢äº†ä¸ç›¸å…³çš„è¯ï¼‰"""
            import re
            # æå–æ‰€æœ‰å•è¯
            original_words = set(re.findall(r'\b\w+\b', original.lower()))
            optimized_words = set(re.findall(r'\b\w+\b', optimized.lower()))
            # æ‰¾å‡ºè¢«æ›¿æ¢çš„è¯
            removed_words = original_words - optimized_words
            added_words = optimized_words - original_words
            # å¦‚æœæ›¿æ¢å‰åçš„è¯æ²¡æœ‰ç›¸ä¼¼æ€§ï¼Œå¯èƒ½æ˜¯é”™è¯¯æ›¿æ¢
            if removed_words and added_words:
                for removed in removed_words:
                    for added in added_words:
                        # å¦‚æœåŸè¯å’Œæ–°è¯å®Œå…¨ä¸åŒï¼ˆç¼–è¾‘è·ç¦»è¿‡å¤§ï¼‰ï¼Œåˆ¤å®šä¸ºé”™è¯¯æ›¿æ¢
                        if len(removed) > 3 and len(added) > 3 and not any(c in removed for c in added):
                            return True
            return False

        # ç»Ÿè®¡å˜æ›´ç±»å‹
        format_changes = 0
        content_changes = 0
        wrong_changes = 0

        # éå†æ‰€æœ‰æ—¥å¿—
        for log in batch_logs:
            if log["type"] == "content_optimization":
                original = log["original"]
                optimized = log["optimized"]

                # åˆ†ç±»ç»Ÿè®¡
                if is_format_change_only(original, optimized):
                    format_changes += 1
                elif is_wrong_replacement(original, optimized):
                    wrong_changes += 1
                else:
                    content_changes += 1

        total_changes = format_changes + content_changes + wrong_changes

        return {
            'format_changes': format_changes,
            'content_changes': content_changes,
            'wrong_changes': wrong_changes,
            'total_changes': total_changes
        }

    def _format_time_stats(self, stages: dict, total_time: float) -> None:
        """æ ¼å¼åŒ–æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡"""
        print(f"â±ï¸  [bold blue]è€—æ—¶ç»Ÿè®¡:[/bold blue]")

        # æ£€æŸ¥æ˜¯å¦æœ‰å¹¶è¡Œå¤„ç†é˜¶æ®µ
        has_parallel = "âš¡ å¹¶è¡Œé¢„å¤„ç†" in stages

        if has_parallel:
            print(f"   ğŸ“Š [bold yellow]å¹¶è¡Œä¼˜åŒ–æ•ˆæœ:[/bold yellow]")

            # è®¡ç®—å¹¶è¡Œå¤„ç†çš„ä¼˜åŒ–æ•ˆæœ
            parallel_time = stages.get("âš¡ å¹¶è¡Œé¢„å¤„ç†", 0)
            split_time = stages.get("âœ‚ï¸  æ™ºèƒ½æ–­å¥", 0)
            summary_time = stages.get("ğŸ” å†…å®¹åˆ†æ", 0)

            if split_time > 0 and summary_time > 0:
                serial_time = split_time + summary_time  # ä¸²è¡Œå¤„ç†éœ€è¦çš„æ—¶é—´
                time_saved = serial_time - parallel_time  # èŠ‚çœçš„æ—¶é—´
                efficiency_gain = (time_saved / serial_time) * 100 if serial_time > 0 else 0

                print(f"      âš¡ å¹¶è¡Œå¤„ç†: [cyan]{parallel_time:.1f}s[/cyan]")
                print(f"      ğŸ“ æ–­å¥æ—¶é—´: [dim]{split_time:.1f}s[/dim]")
                print(f"      ğŸ” åˆ†ææ—¶é—´: [dim]{summary_time:.1f}s[/dim]")
                print(f"      â±ï¸  ä¸²è¡Œè€—æ—¶: [dim]{serial_time:.1f}s[/dim]")
                print(f"      ğŸ’¡ èŠ‚çœæ—¶é—´: [green]{time_saved:.1f}s[/green] ([green]{efficiency_gain:.0f}%[/green])")
                print()

        # æŒ‰æ‰§è¡Œé¡ºåºæ˜¾ç¤ºå„é˜¶æ®µï¼ˆä¿æŒå­—å…¸æ’å…¥é¡ºåºï¼‰
        for stage_name, elapsed_time in stages.items():
            if elapsed_time > 0 and stage_name != "âš¡ å¹¶è¡Œé¢„å¤„ç†":  # å¹¶è¡Œå¤„ç†å·²å•ç‹¬æ˜¾ç¤º
                percentage = (elapsed_time / total_time) * 100
                print(f"   {stage_name}: [cyan]{elapsed_time:.1f}s[/cyan] ([dim]{percentage:.0f}%[/dim])")

        print(f"   [bold]æ€»è®¡: [cyan]{total_time:.1f}s[/cyan][/bold]") 