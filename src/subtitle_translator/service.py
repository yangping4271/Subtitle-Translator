"""
å­—å¹•ç¿»è¯‘æœåŠ¡æ¨¡å— - æ ¸å¿ƒç¿»è¯‘æœåŠ¡ç±»
"""
import time
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Optional, Tuple

from rich import print

from .exceptions import OpenAIAPIError, EmptySubtitleError, TranslationError, SummaryError, SmartSplitError
from .logger import log_section_end, log_section_start, log_stats
from .translation_core.config import SubtitleConfig
from .translation_core.data import SubtitleData
from .translation_core.optimizer import SubtitleOptimizer
from .translation_core.spliter import (
    batch_by_sentence_count,
    merge_segments_within_batch,
    preprocess_segments,
    presplit_by_punctuation,
)
from .translation_core.summarizer import SubtitleSummarizer


class SubtitleTranslatorService:
    """å­—å¹•ç¿»è¯‘æœåŠ¡ç±»"""
    
    def __init__(self):
        self.config = SubtitleConfig()
        self.summarizer = SubtitleSummarizer(self.config)
        # å»¶è¿Ÿåˆå§‹åŒ–loggerï¼Œåœ¨setup_environmentä¸­åˆå§‹åŒ–
        self.logger = None

    def _get_logger(self):
        """è·å–loggerå®ä¾‹"""
        if self.logger is None:
            from .env_setup import logger
            self.logger = logger
        return self.logger

    def _init_translation_env(
        self,
        llm_model: Optional[str] = None,
        split_model: Optional[str] = None,
        summary_model: Optional[str] = None,
        translation_model: Optional[str] = None,
        show_config: bool = True
    ) -> None:
        """åˆå§‹åŒ–ç¿»è¯‘ç¯å¢ƒé…ç½®

        Args:
            llm_model: è¦†ç›–æ‰€æœ‰æ¨¡å‹ï¼ˆä¼˜å…ˆçº§ä½äºç‹¬ç«‹å‚æ•°ï¼‰
            split_model: æ–­å¥æ¨¡å‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            summary_model: æ€»ç»“æ¨¡å‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            translation_model: ç¿»è¯‘æ¨¡å‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            show_config: æ˜¯å¦æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        """
        logger = self._get_logger()
        start_time = time.time()
        log_section_start(logger, "ç¿»è¯‘ç¯å¢ƒåˆå§‹åŒ–", "âš™ï¸")

        # ä¼˜å…ˆçº§ï¼šç‹¬ç«‹å‚æ•° > llm_model > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
        if llm_model:
            self.config.split_model = llm_model
            self.config.summary_model = llm_model
            self.config.translation_model = llm_model

        # ç‹¬ç«‹å‚æ•°è¦†ç›–ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        if split_model:
            self.config.split_model = split_model
        if summary_model:
            self.config.summary_model = summary_model
        if translation_model:
            self.config.translation_model = translation_model

        logger.info(f"ğŸŒ APIç«¯ç‚¹: {self.config.openai_base_url}")

        model_config = {
            "æ–­å¥æ¨¡å‹": self.config.split_model,
            "æ€»ç»“æ¨¡å‹": self.config.summary_model,
            "ç¿»è¯‘æ¨¡å‹": self.config.translation_model
        }
        log_stats(logger, model_config, "æ¨¡å‹é…ç½®")

        if show_config:
            self._display_api_config()
            self._display_model_config()

        elapsed_time = time.time() - start_time
        log_section_end(logger, "ç¿»è¯‘ç¯å¢ƒåˆå§‹åŒ–", elapsed_time, "âœ…")

    def _save_subtitle_files(
        self,
        asr_data: SubtitleData,
        translate_result: list,
        input_srt_path: Path,
        output_dir: Path,
        target_lang: str
    ) -> Path:
        """ä¿å­˜ç¿»è¯‘ç»“æœåˆ°æ–‡ä»¶"""
        logger = self._get_logger()
        logger.info("ğŸ’¾ æ­£åœ¨ä¿å­˜ç¿»è¯‘ç»“æœ...")

        base_name = input_srt_path.stem
        target_lang_output_path = output_dir / f"{base_name}.{target_lang}.srt"
        english_output_path = output_dir / f"{base_name}.en.srt"

        logger.info(f"ç¿»è¯‘æ–‡ä»¶å°†ä¿å­˜åˆ°ç›®å½•: {output_dir}")
        logger.info(f"ç›®æ ‡è¯­è¨€æ–‡ä»¶: {target_lang_output_path}")
        logger.info(f"è‹±æ–‡æ–‡ä»¶: {english_output_path}")

        output_dir.mkdir(parents=True, exist_ok=True)

        asr_data.save_translations_to_files(
            translate_result,
            str(english_output_path),
            str(target_lang_output_path)
        )

        if not target_lang_output_path.exists():
            raise RuntimeError(f"ç›®æ ‡è¯­è¨€ç¿»è¯‘æ–‡ä»¶ä¿å­˜å¤±è´¥: {target_lang_output_path}")
        if not english_output_path.exists():
            raise RuntimeError(f"è‹±æ–‡ç¿»è¯‘æ–‡ä»¶ä¿å­˜å¤±è´¥: {english_output_path}")

        logger.info(f"ç¿»è¯‘æ–‡ä»¶å·²ä¿å­˜:")
        logger.info(f"  - ç›®æ ‡è¯­è¨€: {target_lang_output_path}")
        logger.info(f"  - è‹±æ–‡: {english_output_path}")

        return target_lang_output_path

    def _load_subtitle_file(self, input_srt_path: Path) -> SubtitleData:
        """åŠ è½½å¹¶éªŒè¯å­—å¹•æ–‡ä»¶"""
        from .translation_core.data import load_subtitle

        logger = self._get_logger()
        logger.info("ğŸ“‚ æ­£åœ¨åŠ è½½å­—å¹•æ–‡ä»¶...")

        asr_data = load_subtitle(str(input_srt_path))
        logger.info(f"ğŸ“Š å­—å¹•ç»Ÿè®¡: å…± {len(asr_data.segments)} æ¡å­—å¹•")
        logger.info(f"å­—å¹•å†…å®¹é¢„è§ˆ: {asr_data.to_txt()[:100]}...")

        if len(asr_data.segments) == 0:
            logger.info("âš ï¸  SRTæ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡ç¿»è¯‘å¤„ç†")
            print(f"[yellow]âš ï¸  SRTæ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡ç¿»è¯‘å¤„ç†[/yellow]")
            raise EmptySubtitleError("SRTæ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç¿»è¯‘")

        print(f"ğŸ“Š [bold blue]åŠ è½½å®Œæˆ[/bold blue]")
        return asr_data

    def _set_target_language(self, target_lang: str) -> None:
        """è®¾ç½®ç›®æ ‡è¯­è¨€ï¼ˆå¸¦å‹å¥½é”™è¯¯å¤„ç†ï¼‰"""
        logger = self._get_logger()
        logger.info(f"ğŸŒ è®¾ç½®ç›®æ ‡è¯­è¨€: {target_lang}")

        try:
            self.config.set_target_language(target_lang)
            logger.info(f"âœ… ç›®æ ‡è¯­è¨€å·²è®¾ç½®ä¸º: {self.config.target_language}")
        except ValueError as e:
            logger.error(f"âŒ è¯­è¨€è®¾ç½®å¤±è´¥: {str(e)}")
            print(f"[bold red]âŒ è¯­è¨€è®¾ç½®å¤±è´¥![/bold red]")
            print(str(e))
            raise

    def _display_api_config(self) -> None:
        """æ˜¾ç¤º API é…ç½®ä¿¡æ¯"""
        print(f"ğŸŒ [bold blue]API é…ç½®:[/bold blue]")
        print(f"   ç«¯ç‚¹: [cyan]{self.config.openai_base_url}[/cyan]")

        api_key = self.config.openai_api_key
        if api_key:
            masked_key = self._mask_api_key(api_key)
            print(f"   å¯†é’¥: [cyan]{masked_key}[/cyan]")
        else:
            print(f"   å¯†é’¥: [red]æœªè®¾ç½®[/red]")

    def _mask_api_key(self, api_key: str) -> str:
        """å¯¹ API å¯†é’¥è¿›è¡Œè„±æ•å¤„ç†"""
        if len(api_key) > 12:
            return f"{api_key[:6]}{'*' * 8}{api_key[-6:]}"
        return '*' * len(api_key)

    def _display_model_config(self) -> None:
        """æ˜¾ç¤ºæ¨¡å‹é…ç½®ä¿¡æ¯"""
        print(f"ğŸ¤– [bold blue]æ¨¡å‹é…ç½®:[/bold blue]")
        print(f"   æ–­å¥: [cyan]{self.config.split_model}[/cyan]")
        print(f"   æ€»ç»“: [cyan]{self.config.summary_model}[/cyan]")
        print(f"   ç¿»è¯‘: [cyan]{self.config.translation_model}[/cyan]")

    def translate_srt(self, input_srt_path: Path, target_lang: str, output_dir: Path,
                      llm_model: Optional[str] = None, skip_env_init: bool = False) -> Path:
        """ç¿»è¯‘å­—å¹•æ–‡ä»¶

        Args:
            input_srt_path: è¾“å…¥å­—å¹•æ–‡ä»¶è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€
            output_dir: è¾“å‡ºç›®å½•
            llm_model: LLM æ¨¡å‹åç§°
            skip_env_init: æ˜¯å¦è·³è¿‡ç¯å¢ƒåˆå§‹åŒ–
        """
        logger = self._get_logger()
        try:
            task_start_time = time.time()
            log_section_start(logger, "å­—å¹•ç¿»è¯‘ä»»åŠ¡", "ğŸ¬")
            
            # ç”¨äºæ”¶é›†å„é˜¶æ®µè€—æ—¶çš„å­—å…¸
            stage_times = {}
            
            # è®¾ç½®ç›®æ ‡è¯­è¨€
            self._set_target_language(target_lang)
            
            # åªåœ¨éœ€è¦æ—¶åˆå§‹åŒ–ç¿»è¯‘ç¯å¢ƒ
            if not skip_env_init:
                self._init_translation_env(llm_model)
            
            # åŠ è½½å­—å¹•æ–‡ä»¶
            asr_data = self._load_subtitle_file(input_srt_path)
            
            # å¹¶è¡Œé¢„å¤„ç†é˜¶æ®µï¼šæ–­å¥å’Œæ€»ç»“åŒæ—¶è¿›è¡Œï¼ˆv0.5.x æ€§èƒ½ä¼˜åŒ–ï¼‰
            # å€Ÿé‰´VideoCaptionerçš„è§£å†³æ–¹æ¡ˆï¼šç»Ÿä¸€è½¬æ¢ä¸ºå•è¯çº§åˆ«åè¿›è¡Œæ–­å¥
            # ä¼˜åŠ¿ï¼š1) å¤ç”¨ç°æœ‰æ‰¹é‡æ¡†æ¶ 2) æ— é¢å¤–APIæˆæœ¬ 3) æ—¶é—´æˆ³ç²¾ç¡®åˆ†é… 4) å¹¶è¡Œå¤„ç†èŠ‚çœæ—¶é—´
            preprocessing_start_time = time.time()
            log_section_start(logger, "å¹¶è¡Œé¢„å¤„ç†é˜¶æ®µ", "âš¡")

            print(f"âš¡ [bold cyan]å¯åŠ¨å¹¶è¡Œé¢„å¤„ç†ï¼šæ–­å¥ + å†…å®¹åˆ†æ...[/bold cyan]")

            # å‡†å¤‡åŸå§‹å­—å¹•å†…å®¹ç”¨äºæ€»ç»“ï¼ˆæ–­å¥å‰ï¼‰
            original_subtitle_content = asr_data.to_txt()

            # å¯åŠ¨æ€»ç»“ä»»åŠ¡ï¼ˆä¸æµæ°´çº¿å¹¶è¡Œï¼‰
            def execute_summarization(subtitle_content: str, input_file: str) -> Tuple[dict, float]:
                """æ‰§è¡Œæ€»ç»“å¤„ç†çš„ä»»åŠ¡å‡½æ•°"""
                summary_start_time = time.time()
                summarize_result = self._get_subtitle_summary(subtitle_content, input_file, is_parallel=True)
                summary_time = time.time() - summary_start_time
                return summarize_result, summary_time

            # å…ˆè·å–æ€»ç»“ï¼ˆéœ€è¦ä½œä¸ºç¿»è¯‘ä¸Šä¸‹æ–‡ï¼‰
            summarize_result, summary_time = execute_summarization(original_subtitle_content, str(input_srt_path.resolve()))
            stage_times["ğŸ” å†…å®¹åˆ†æ"] = summary_time

            # ä½¿ç”¨æµæ°´çº¿å¼å¤„ç†ï¼šæ–­å¥ + ç¿»è¯‘ä¸€ä½“åŒ–
            pipeline_start_time = time.time()
            print(f"âš¡ [bold cyan]å¯åŠ¨æµæ°´çº¿å¤„ç†ï¼šæ–­å¥ + ç¿»è¯‘å¹¶è¡Œ...[/bold cyan]")

            asr_data, translate_result = self._translate_with_pipeline(asr_data, summarize_result)

            pipeline_time = time.time() - pipeline_start_time
            stage_times["ğŸš€ æµæ°´çº¿å¤„ç†"] = pipeline_time

            preprocessing_time = time.time() - preprocessing_start_time
            log_section_end(logger, "å¹¶è¡Œé¢„å¤„ç†é˜¶æ®µ", preprocessing_time, "ğŸ‰")
            print(f"ğŸ‰ [bold green]æµæ°´çº¿å¤„ç†å®Œæˆ[/bold green] (æ€»è€—æ—¶: [cyan]{preprocessing_time:.1f}s[/cyan])")

            # æ·»åŠ å¹¶è¡Œå¤„ç†ç»Ÿè®¡
            stage_times["âš¡ å¹¶è¡Œé¢„å¤„ç†"] = preprocessing_time
            
            # ä¿å­˜å­—å¹•
            target_lang_output_path = self._save_subtitle_files(
                asr_data, translate_result, input_srt_path, output_dir, target_lang
            )
            
            total_elapsed = time.time() - task_start_time
            
            # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
            print()
            self._format_time_stats(stage_times, total_elapsed)
            
            # ä»»åŠ¡å®Œæˆç»Ÿè®¡
            final_stats = {
                "è¾“å…¥æ–‡ä»¶": input_srt_path.name,
                "å­—å¹•æ•°é‡": len(asr_data.segments),
                "ç›®æ ‡è¯­è¨€": target_lang,
                "æ€»è€—æ—¶": f"{total_elapsed:.1f}ç§’"
            }
            log_stats(logger, final_stats, "ä»»åŠ¡å®Œæˆç»Ÿè®¡")
            log_section_end(logger, "å­—å¹•ç¿»è¯‘ä»»åŠ¡", total_elapsed, "ğŸ‰")
            
            return target_lang_output_path
                
        except OpenAIAPIError as e:
            logger.error(f"ğŸš¨ APIé”™è¯¯: {str(e)}")
            raise
        
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ™ºèƒ½æ–­å¥ã€ç¿»è¯‘ã€æ€»ç»“æˆ–ç©ºæ–‡ä»¶å¼‚å¸¸ï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥ä¼ æ’­
            if isinstance(e, (SmartSplitError, TranslationError, SummaryError, EmptySubtitleError)):
                raise e
            
            logger.error(f"ğŸ’¥ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            raise

    def _get_subtitle_summary(self, subtitle_content: str, input_file: str, is_parallel: bool = False) -> dict:
        """è·å–å­—å¹•å†…å®¹æ‘˜è¦

        Args:
            subtitle_content: å­—å¹•å†…å®¹æ–‡æœ¬
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            is_parallel: æ˜¯å¦ä¸ºå¹¶è¡Œè°ƒç”¨æ¨¡å¼
        """
        logger = self._get_logger()

        # åœ¨å¹¶è¡Œæ¨¡å¼ä¸‹ï¼Œä¸é‡å¤è¾“å‡ºæ—¥å¿—å¤´éƒ¨ä¿¡æ¯
        if not is_parallel:
            print(f"ğŸ” [bold cyan]å†…å®¹åˆ†æä¸­...[/bold cyan]")

        logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.config.summary_model}")
        summarize_result = self.summarizer.summarize(subtitle_content, input_file)
        logger.info(f"æ€»ç»“å­—å¹•å†…å®¹:\n{summarize_result.get('summary')}\n")

        # åœ¨å¹¶è¡Œæ¨¡å¼ä¸‹ï¼Œä¸é‡å¤è¾“å‡ºå®Œæˆä¿¡æ¯
        if not is_parallel:
            print(f"âœ… [bold green]å†…å®¹åˆ†æå®Œæˆ[/bold green]")

        return summarize_result

    def _translate_with_pipeline(self, asr_data: SubtitleData, summarize_result: dict) -> Tuple[SubtitleData, list]:
        """
        æµæ°´çº¿å¼ç¿»è¯‘ï¼šæ¯ä¸ªæ‰¹æ¬¡æ–­å¥åç«‹å³ç¿»è¯‘

        Returns:
            (final_asr_data, translate_result)
        """
        logger = self._get_logger()

        # 1. é¢„å¤„ç†ï¼šç§»é™¤çº¯æ ‡ç‚¹ç¬¦å·
        asr_data.segments = preprocess_segments(asr_data.segments)

        # 2. è½¬æ¢ä¸ºå•è¯çº§å­—å¹•ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if not asr_data.is_word_timestamp():
            asr_data = asr_data.split_to_word_segments()

        word_segments = asr_data.segments

        # 3. é¢„åˆ†å¥
        pre_split_sentences = presplit_by_punctuation(word_segments)

        # 4. åˆ†æ‰¹
        batches = batch_by_sentence_count(
            pre_split_sentences,
            min_size=self.config.min_batch_sentences,
            max_size=self.config.max_batch_sentences
        )
        total_batches = len(batches)
        logger.info(f"ğŸ“¦ åˆ†ä¸º {total_batches} æ‰¹å¤„ç† {len(word_segments)} ä¸ªå•è¯")

        # 5. å¹¶å‘å¤„ç†
        concurrency = self.config.thread_num
        all_translated_results = []
        all_segments = []
        batch_logs_all = []

        def process_batch_task(args):
            """æ¯ä¸ªæ‰¹æ¬¡çš„å®Œæ•´ä»»åŠ¡ï¼šæ–­å¥ + ç¿»è¯‘"""
            batch_index, batch = args
            batch_num = batch_index + 1

            batch_segments = merge_segments_within_batch(
                batch,
                word_segments,
                model=self.config.split_model,
                batch_index=batch_num
            )

            batch_asr_data = SubtitleData(batch_segments)
            translator = SubtitleOptimizer(config=self.config)
            batch_translate_result = translator.translate_batch_directly(batch_asr_data, summarize_result)

            return (batch_segments, batch_translate_result, translator.batch_logs)

        batch_tasks = list(enumerate(batches))

        for i in range(0, len(batch_tasks), concurrency):
            chunk = batch_tasks[i:i + concurrency]
            with ThreadPoolExecutor(max_workers=min(len(chunk), concurrency)) as executor:
                processed_chunks = list(executor.map(process_batch_task, chunk))
                for segments, translate_result, batch_logs in processed_chunks:
                    all_segments.extend(segments)
                    all_translated_results.extend(translate_result)
                    batch_logs_all.extend(batch_logs)

                progress = min(i + concurrency, len(batch_tasks))
                logger.info(f"ğŸ“ˆ æµæ°´çº¿è¿›åº¦: {progress}/{len(batch_tasks)}")

        # 6. æŒ‰æ—¶é—´æ’åº
        all_segments.sort(key=lambda seg: seg.start_time)
        final_asr_data = SubtitleData(all_segments)

        # 7. é‡æ–°ç¼–å·ç¿»è¯‘ç»“æœ
        renumbered_results = []
        for idx, result in enumerate(all_translated_results, 1):
            result_copy = result.copy()
            result_copy['id'] = idx
            renumbered_results.append(result_copy)

        # 8. æ˜¾ç¤ºä¼˜åŒ–ç»Ÿè®¡
        stats = self._get_optimization_stats(batch_logs_all)
        if stats['total_changes'] > 0:
            # å…ˆæ˜¾ç¤ºè¯¦ç»†çš„ä¼˜åŒ–æ—¥å¿—
            self._print_optimization_details(batch_logs_all)

            # å†æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡
            print(f"ğŸ“Š [bold blue]ä¼˜åŒ–ç»Ÿè®¡:[/bold blue]")
            if stats['format_changes'] > 0:
                print(f"   æ ¼å¼ä¼˜åŒ–: [cyan]{stats['format_changes']}[/cyan] é¡¹")
            if stats['content_changes'] > 0:
                print(f"   å†…å®¹ä¿®æ”¹: [cyan]{stats['content_changes']}[/cyan] é¡¹")
            if stats['wrong_changes'] > 0:
                print(f"   [yellow]å¯ç–‘æ›¿æ¢: {stats['wrong_changes']} é¡¹[/yellow]")
            print(f"   æ€»è®¡: [cyan]{stats['total_changes']}[/cyan] é¡¹ä¼˜åŒ–")

        logger.info(f"âœ… æµæ°´çº¿å¤„ç†å®Œæˆï¼å…± {len(all_segments)} å¥")

        return final_asr_data, renumbered_results

    def _print_optimization_details(self, batch_logs: list) -> None:
        """æ‰“å°è¯¦ç»†çš„ä¼˜åŒ–æ—¥å¿—"""
        from .translation_core.optimizer import format_diff

        logger = self._get_logger()
        logger.info("ğŸ“Š å­—å¹•ä¼˜åŒ–ç»“æœæ±‡æ€»")

        # éå†æ‰€æœ‰æ—¥å¿—ï¼Œæ‰“å°æœ‰å®é™…æ”¹åŠ¨çš„
        for log in batch_logs:
            if log["type"] == "content_optimization":
                id_num = log["id"]
                original = log["original"]
                optimized = log["optimized"]

                # åªåœ¨å®é™…æœ‰å˜åŒ–æ—¶æ‰“å°
                if original != optimized:
                    logger.info(f"ğŸ”§ å­—å¹•ID {id_num} - å†…å®¹ä¼˜åŒ–:")
                    logger.info(f"   {format_diff(original, optimized)}")

    def _get_optimization_stats(self, batch_logs: list) -> dict:
        """ä»batch_logsä¸­è·å–ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        from .translation_core.optimizer import _is_format_change_only, _is_wrong_replacement

        format_changes = 0
        content_changes = 0
        wrong_changes = 0

        for log in batch_logs:
            if log["type"] == "content_optimization":
                original = log["original"]
                optimized = log["optimized"]

                if _is_format_change_only(original, optimized):
                    format_changes += 1
                elif _is_wrong_replacement(original, optimized):
                    wrong_changes += 1
                else:
                    content_changes += 1

        return {
            'format_changes': format_changes,
            'content_changes': content_changes,
            'wrong_changes': wrong_changes,
            'total_changes': format_changes + content_changes + wrong_changes
        }

    def _format_time_stats(self, stages: dict, total_time: float) -> None:
        """æ ¼å¼åŒ–æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡"""
        print(f"â±ï¸  [bold blue]è€—æ—¶ç»Ÿè®¡:[/bold blue]")

        # æ£€æŸ¥æ˜¯å¦æœ‰å¹¶è¡Œå¤„ç†é˜¶æ®µ
        has_parallel = "âš¡ å¹¶è¡Œé¢„å¤„ç†" in stages

        # æŒ‰æ‰§è¡Œé¡ºåºæ˜¾ç¤ºå„é˜¶æ®µï¼ˆä¿æŒå­—å…¸æ’å…¥é¡ºåºï¼‰
        for stage_name, elapsed_time in stages.items():
            if elapsed_time > 0 and stage_name != "âš¡ å¹¶è¡Œé¢„å¤„ç†":  # å¹¶è¡Œå¤„ç†ä¸å•ç‹¬æ˜¾ç¤º
                percentage = (elapsed_time / total_time) * 100
                print(f"   {stage_name}: [cyan]{elapsed_time:.1f}s[/cyan] ([dim]{percentage:.0f}%[/dim])")

        print(f"   [bold]æ€»è®¡: [cyan]{total_time:.1f}s[/cyan][/bold]") 