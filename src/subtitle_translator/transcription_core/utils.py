import json
import logging
from pathlib import Path
import time
import os
import requests
import urllib.parse
import subprocess
import shutil
import pickle
import hashlib
from typing import Optional, List, Dict, Any

import mlx.core as mx
from dacite import from_dict
from huggingface_hub import hf_hub_download
from huggingface_hub.utils import (
    HfHubHTTPError,
    LocalEntryNotFoundError,
    RepositoryNotFoundError,
)
from huggingface_hub import snapshot_download
from mlx.utils import tree_flatten, tree_unflatten
import retry
from rich.console import Console
from rich.progress import (
    Progress,
    SpinnerColumn,
    BarColumn,
    TextColumn,
    DownloadColumn,
    TransferSpeedColumn,
    TimeRemainingColumn,
    FileSizeColumn,
)
from rich.text import Text

from .parakeet import (
    BaseParakeet,
    ParakeetCTC,
    ParakeetCTCArgs,
    ParakeetRNNT,
    ParakeetRNNTArgs,
    ParakeetTDT,
    ParakeetTDTArgs,
    ParakeetTDTCTC,
    ParakeetTDTCTCArgs,
)
from .model_cache import load_cached_model, model_context

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)
console = Console()

# Hugging Face é•œåƒç«™åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
HF_MIRROR_SITES = [
    "https://huggingface.co",  # å®˜æ–¹åœ°å€
    "https://hf-mirror.com",   # æ¨èé•œåƒç«™
]


# å­˜å‚¨å±‚ä¼˜åŒ– - é¢„ç¼–è¯‘æ¨¡å‹ç¼“å­˜
class ModelStorageOptimizer:
    """æ¨¡å‹å­˜å‚¨å±‚ä¼˜åŒ–å™¨ - é€šè¿‡ç¼“å­˜ä¼˜åŒ–åçš„æ¨¡å‹çŠ¶æ€åŠ é€ŸåŠ è½½"""
    
    def __init__(self):
        # è·å–ç¼“å­˜ç›®å½•
        self.cache_root = self._get_cache_dir()
        self.optimized_cache_dir = self.cache_root / "optimized_models"
        self.optimized_cache_dir.mkdir(parents=True, exist_ok=True)
        
    def _get_cache_dir(self) -> Path:
        """è·å–ç¼“å­˜ç›®å½•"""
        cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
        return Path(cache_dir)
    
    def _get_cache_key(self, model_id: str, dtype: mx.Dtype) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # ä½¿ç”¨æ¨¡å‹IDå’Œæ•°æ®ç±»å‹ç”Ÿæˆå”¯ä¸€é”®
        content = f"{model_id}_{dtype}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _get_optimized_paths(self, model_id: str, dtype: mx.Dtype) -> Dict[str, Path]:
        """è·å–ä¼˜åŒ–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        cache_key = self._get_cache_key(model_id, dtype)
        cache_dir = self.optimized_cache_dir / cache_key
        
        return {
            "cache_dir": cache_dir,
            "config_file": cache_dir / "config.json",
            "weights_file": cache_dir / "optimized_weights.safetensors", 
            "metadata_file": cache_dir / "metadata.json",
            "model_state_file": cache_dir / "model_state.pkl"
        }
    
    def has_optimized_cache(self, model_id: str, dtype: mx.Dtype) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¼˜åŒ–ç¼“å­˜"""
        paths = self._get_optimized_paths(model_id, dtype)
        return (
            paths["config_file"].exists() 
            and paths["weights_file"].exists()
            and paths["metadata_file"].exists()
        )
    
    def save_optimized_model(self, model_id: str, dtype: mx.Dtype, 
                           model: BaseParakeet, config: Dict[str, Any],
                           original_weight_path: str) -> None:
        """ä¿å­˜ä¼˜åŒ–åçš„æ¨¡å‹åˆ°å­˜å‚¨"""
        try:
            paths = self._get_optimized_paths(model_id, dtype)
            paths["cache_dir"].mkdir(parents=True, exist_ok=True)
            
            # 1. ä¿å­˜é…ç½®æ–‡ä»¶
            with open(paths["config_file"], 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # 2. ä¿å­˜ä¼˜åŒ–åçš„æƒé‡ï¼ˆå·²è½¬æ¢æ•°æ®ç±»å‹ï¼‰
            import shutil
            shutil.copy2(original_weight_path, paths["weights_file"])
            
            # 3. ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "model_id": model_id,
                "dtype": str(dtype),
                "cache_time": time.time(),
                "original_weight_path": original_weight_path,
                "version": "1.0"
            }
            with open(paths["metadata_file"], 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2)
            
            logger.debug(f"å·²ä¿å­˜ä¼˜åŒ–ç¼“å­˜: {model_id} ({dtype})")
            
        except Exception as e:
            logger.warning(f"ä¿å­˜ä¼˜åŒ–ç¼“å­˜å¤±è´¥: {e}")
    
    def load_optimized_model(self, model_id: str, dtype: mx.Dtype) -> Optional[BaseParakeet]:
        """ä»å­˜å‚¨åŠ è½½ä¼˜åŒ–çš„æ¨¡å‹"""
        try:
            if not self.has_optimized_cache(model_id, dtype):
                return None
            
            paths = self._get_optimized_paths(model_id, dtype)
            
            # åŠ è½½é…ç½®
            with open(paths["config_file"], 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æ„å»ºæ¨¡å‹
            model = from_config(config)
            
            # åŠ è½½æƒé‡
            model.load_weights(str(paths["weights_file"]))
            
            # è½¬æ¢æ•°æ®ç±»å‹ï¼ˆå¯èƒ½å·²ç»æ˜¯æ­£ç¡®ç±»å‹ï¼Œä½†ä¿é™©èµ·è§ï¼‰
            curr_weights = dict(tree_flatten(model.parameters()))
            curr_weights = [(k, v.astype(dtype)) for k, v in curr_weights.items()]
            model.update(tree_unflatten(curr_weights))
            
            logger.debug(f"ä»ä¼˜åŒ–ç¼“å­˜åŠ è½½æ¨¡å‹æˆåŠŸ: {model_id} ({dtype})")
            return model
            
        except Exception as e:
            logger.warning(f"ä»ä¼˜åŒ–ç¼“å­˜åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            # æ¸…ç†å¯èƒ½æŸåçš„ç¼“å­˜
            self.clear_optimized_cache(model_id, dtype)
            return None
    
    def clear_optimized_cache(self, model_id: str, dtype: mx.Dtype) -> None:
        """æ¸…ç†ç‰¹å®šæ¨¡å‹çš„ä¼˜åŒ–ç¼“å­˜"""
        try:
            paths = self._get_optimized_paths(model_id, dtype)
            if paths["cache_dir"].exists():
                shutil.rmtree(paths["cache_dir"])
                logger.debug(f"å·²æ¸…ç†ä¼˜åŒ–ç¼“å­˜: {model_id} ({dtype})")
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¼˜åŒ–ç¼“å­˜å¤±è´¥: {e}")
    
    def clear_all_optimized_cache(self) -> None:
        """æ¸…ç†æ‰€æœ‰ä¼˜åŒ–ç¼“å­˜"""
        try:
            if self.optimized_cache_dir.exists():
                shutil.rmtree(self.optimized_cache_dir)
                self.optimized_cache_dir.mkdir(parents=True, exist_ok=True)
                logger.info("å·²æ¸…ç†æ‰€æœ‰ä¼˜åŒ–ç¼“å­˜")
        except Exception as e:
            logger.warning(f"æ¸…ç†æ‰€æœ‰ä¼˜åŒ–ç¼“å­˜å¤±è´¥: {e}")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not self.optimized_cache_dir.exists():
                return {"cached_models": 0, "total_size": 0}
            
            cached_models = 0
            total_size = 0
            
            for cache_dir in self.optimized_cache_dir.iterdir():
                if cache_dir.is_dir():
                    metadata_file = cache_dir / "metadata.json"
                    if metadata_file.exists():
                        cached_models += 1
                        # è®¡ç®—ç›®å½•å¤§å°
                        for file in cache_dir.rglob('*'):
                            if file.is_file():
                                total_size += file.stat().st_size
            
            return {
                "cached_models": cached_models,
                "total_size": total_size,
                "total_size_mb": total_size / (1024 * 1024),
                "cache_dir": str(self.optimized_cache_dir)
            }
        except Exception as e:
            logger.warning(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {"cached_models": 0, "total_size": 0}


# å…¨å±€å­˜å‚¨ä¼˜åŒ–å™¨å®ä¾‹
_storage_optimizer = ModelStorageOptimizer()

def _get_hf_endpoint() -> str:
    """è·å– Hugging Face ç«¯ç‚¹åœ°å€ï¼Œæ”¯æŒç¯å¢ƒå˜é‡é…ç½®"""
    # 1. ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ HF_ENDPOINT
    hf_endpoint = os.getenv("HF_ENDPOINT")
    if hf_endpoint and hf_endpoint.strip():
        return hf_endpoint.strip()
    
    # 2. ä½¿ç”¨é»˜è®¤å®˜æ–¹åœ°å€
    return "https://huggingface.co"

def _is_huggingface_cli_available() -> bool:
    """æ£€æŸ¥æ˜¯å¦å®‰è£…äº† huggingface-cli"""
    try:
        result = subprocess.run(
            ["huggingface-cli", "--version"], 
            capture_output=True, 
            text=True, 
            timeout=5
        )
        return result.returncode == 0
    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
        return False

def _check_endpoint_connectivity(endpoint: str) -> bool:
    """æ£€æŸ¥æŒ‡å®šç«¯ç‚¹çš„ç½‘ç»œè¿æ¥çŠ¶æ€"""
    try:
        # æ„å»ºæµ‹è¯•URL
        test_url = f"{endpoint.rstrip('/')}"
        response = requests.get(test_url, timeout=10)
        return response.status_code == 200
    except Exception as e:
        logger.debug(f"ç«¯ç‚¹ {endpoint} è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def _find_best_hf_endpoint() -> str:
    """è‡ªåŠ¨å¯»æ‰¾æœ€ä½³çš„ Hugging Face ç«¯ç‚¹"""
    # é¦–å…ˆæ£€æŸ¥ç”¨æˆ·é…ç½®çš„ç«¯ç‚¹
    configured_endpoint = _get_hf_endpoint()
    if configured_endpoint != "https://huggingface.co":
        if _check_endpoint_connectivity(configured_endpoint):
            logger.info(f"ä½¿ç”¨é…ç½®çš„ HF ç«¯ç‚¹: {configured_endpoint}")
            return configured_endpoint
        else:
            logger.warning(f"é…ç½®çš„ HF ç«¯ç‚¹ä¸å¯ç”¨: {configured_endpoint}ï¼Œå°†å°è¯•å…¶ä»–é•œåƒç«™")
    
    # æµ‹è¯•æ‰€æœ‰é•œåƒç«™ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„
    for endpoint in HF_MIRROR_SITES:
        if _check_endpoint_connectivity(endpoint):
            logger.info(f"æ‰¾åˆ°å¯ç”¨çš„ HF ç«¯ç‚¹: {endpoint}")
            return endpoint
    
    # å¦‚æœéƒ½ä¸å¯ç”¨ï¼Œè¿”å›å®˜æ–¹åœ°å€ä½œä¸ºæœ€åå°è¯•
    logger.warning("æ‰€æœ‰ HF é•œåƒç«™éƒ½ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å®˜æ–¹åœ°å€")
    return "https://huggingface.co"

def from_config(config: dict) -> BaseParakeet:
    """Loads model from config (randomized weight)"""
    if (
        config.get("target")
        == "nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel"
        and config.get("model_defaults", {}).get("tdt_durations") is not None
    ):
        cfg = from_dict(ParakeetTDTArgs, config)
        model = ParakeetTDT(cfg)
    elif (
        config.get("target")
        == "nemo.collections.asr.models.hybrid_rnnt_ctc_bpe_models.EncDecHybridRNNTCTCBPEModel"
        and config.get("model_defaults", {}).get("tdt_durations") is not None
    ):
        cfg = from_dict(ParakeetTDTCTCArgs, config)
        model = ParakeetTDTCTC(cfg)
    elif (
        config.get("target")
        == "nemo.collections.asr.models.rnnt_bpe_models.EncDecRNNTBPEModel"
        and config.get("model_defaults", {}).get("tdt_durations") is None
    ):
        cfg = from_dict(ParakeetRNNTArgs, config)
        model = ParakeetRNNT(cfg)
    elif (
        config.get("target")
        == "nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE"
    ):
        cfg = from_dict(ParakeetCTCArgs, config)
        model = ParakeetCTC(cfg)
    else:
        raise ValueError("Model is not supported yet!")

    model.eval()  # prevents layernorm not computing correctly on inference!

    return model


def _check_network_connectivity() -> bool:
    """æ£€æŸ¥ç½‘ç»œè¿æ¥çŠ¶æ€ï¼Œä¼˜å…ˆæ£€æŸ¥é…ç½®çš„é•œåƒç«™"""
    configured_endpoint = _get_hf_endpoint()
    
    # å…ˆæ£€æŸ¥é…ç½®çš„ç«¯ç‚¹
    if _check_endpoint_connectivity(configured_endpoint):
        return True
    
    # å¦‚æœé…ç½®çš„ç«¯ç‚¹ä¸å¯ç”¨ï¼Œæ£€æŸ¥å…¶ä»–é•œåƒç«™
    for endpoint in HF_MIRROR_SITES:
        if endpoint != configured_endpoint and _check_endpoint_connectivity(endpoint):
            return True
    
    return False


def _get_file_size(hf_id_or_path: str, filename: str) -> Optional[int]:
    """è·å–è¿œç¨‹æ–‡ä»¶å¤§å°"""
    try:
        import huggingface_hub
        api = huggingface_hub.HfApi()
        repo_info = api.repo_info(hf_id_or_path)
        for sibling in repo_info.siblings:
            if sibling.rfilename == filename:
                return sibling.size
    except Exception:
        pass
    return None


def _download_with_huggingface_cli(hf_id_or_path: str, filename: str, endpoint: str, show_progress: bool = True) -> Optional[str]:
    """
    ä½¿ç”¨ huggingface-cli ä¸‹è½½æ–‡ä»¶
    
    Args:
        hf_id_or_path: Hugging Face æ¨¡å‹ID
        filename: è¦ä¸‹è½½çš„æ–‡ä»¶å
        endpoint: HF ç«¯ç‚¹åœ°å€
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        
    Returns:
        ä¸‹è½½æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å› None
    """
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        if endpoint != "https://huggingface.co":
            env["HF_ENDPOINT"] = endpoint
        
        # æ„å»ºå‘½ä»¤
        cmd = [
            "huggingface-cli", 
            "download", 
            hf_id_or_path, 
            filename,
            "--quiet" if not show_progress else ""
        ]
        cmd = [arg for arg in cmd if arg]  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
        
        if show_progress:
            console.print(f"ğŸš€ [bold blue]ä½¿ç”¨ huggingface-cli ä¸‹è½½:[/bold blue] {filename}")
            # ç«¯ç‚¹ä¿¡æ¯å·²åœ¨ç­–ç•¥çº§åˆ«æ˜¾ç¤ºï¼Œæ­¤å¤„ä¸é‡å¤æ˜¾ç¤º
        
        # æ‰§è¡Œä¸‹è½½
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            env=env,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode == 0:
            # è§£æè¾“å‡ºè·å–æ–‡ä»¶è·¯å¾„
            output_lines = result.stdout.strip().split('\n')
            if output_lines and output_lines[-1]:
                file_path = output_lines[-1].strip()
                if Path(file_path).exists():
                    if show_progress:
                        console.print(f"âœ… [bold green]huggingface-cli ä¸‹è½½æˆåŠŸ:[/bold green] {filename}")
                    return file_path
        
        if show_progress:
            console.print(f"âŒ [yellow]huggingface-cli ä¸‹è½½å¤±è´¥:[/yellow] {result.stderr or 'Unknown error'}")
        
        return None
        
    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, Exception) as e:
        if show_progress:
            console.print(f"âŒ [yellow]huggingface-cli æ‰§è¡Œå¤±è´¥:[/yellow] {str(e)}")
        return None

def _download_with_hf_hub(hf_id_or_path: str, filename: str, endpoint: str, show_progress: bool = True) -> Optional[str]:
    """
    ä½¿ç”¨ hf_hub_download ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒé•œåƒç«™ï¼‰
    
    Args:
        hf_id_or_path: Hugging Face æ¨¡å‹ID
        filename: è¦ä¸‹è½½çš„æ–‡ä»¶å
        endpoint: HF ç«¯ç‚¹åœ°å€
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        
    Returns:
        ä¸‹è½½æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å› None
    """
    try:
        from huggingface_hub import HfApi
        
        if show_progress:
            console.print(f"ğŸ“¦ [bold blue]ä½¿ç”¨ hf_hub_download ä¸‹è½½:[/bold blue] {filename}")
            # ç«¯ç‚¹ä¿¡æ¯å·²åœ¨ç­–ç•¥çº§åˆ«æ˜¾ç¤ºï¼Œæ­¤å¤„ä¸é‡å¤æ˜¾ç¤º
        
        # åˆ›å»ºè‡ªå®šä¹‰çš„ HfApi å®ä¾‹
        if endpoint != "https://huggingface.co":
            api = HfApi(endpoint=endpoint)
            if show_progress:
                console.print(f"   ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰ç«¯ç‚¹: [cyan]{api.endpoint}[/cyan]")
        else:
            api = HfApi()
        
        # ä½¿ç”¨è‡ªå®šä¹‰ API å®ä¾‹ä¸‹è½½
        file_path = hf_hub_download(
            hf_id_or_path, 
            filename,
            endpoint=endpoint if endpoint != "https://huggingface.co" else None
        )
        
        if show_progress:
            console.print(f"âœ… [bold green]hf_hub_download ä¸‹è½½æˆåŠŸ:[/bold green] {filename}")
        
        return file_path
        
    except Exception as e:
        if show_progress:
            console.print(f"âŒ [yellow]hf_hub_download ä¸‹è½½å¤±è´¥:[/yellow] {str(e)}")
        return None

def _download_with_retry(hf_id_or_path: str, filename: str, show_progress: bool = True) -> str:
    """
    æ™ºèƒ½ä¸‹è½½å‡½æ•°ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³ä¸‹è½½æ–¹å¼å’Œé•œåƒç«™
    
    ä¸‹è½½ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. ä½¿ç”¨ huggingface-cli + é…ç½®çš„é•œåƒç«™
    2. ä½¿ç”¨ hf_hub_download + é…ç½®çš„é•œåƒç«™
    3. éå†æ‰€æœ‰é•œåƒç«™ï¼Œå°è¯• huggingface-cli
    4. éå†æ‰€æœ‰é•œåƒç«™ï¼Œå°è¯• hf_hub_download
    
    Args:
        hf_id_or_path: Hugging Face æ¨¡å‹IDæˆ–è·¯å¾„
        filename: è¦ä¸‹è½½çš„æ–‡ä»¶å
        show_progress: æ˜¯å¦æ˜¾ç¤ºä¸‹è½½è¿›åº¦
        
    Returns:
        ä¸‹è½½æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„
        
    Raises:
        RepositoryNotFoundError: ä»“åº“ä¸å­˜åœ¨
        LocalEntryNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        Exception: å…¶ä»–ä¸‹è½½é”™è¯¯
    """
    
    if show_progress:
        console.print(f"\nğŸ”„ [bold cyan]å¼€å§‹æ™ºèƒ½ä¸‹è½½:[/bold cyan] [bold]{filename}[/bold]")
        console.print("ğŸ“‹ [dim]ä¸‹è½½ç­–ç•¥: huggingface-cli â†’ hf_hub_download â†’ é•œåƒç«™è½®è¯¢[/dim]\n")
    
    # æ£€æŸ¥åŸºæœ¬ç½‘ç»œè¿æ¥
    if not _check_network_connectivity():
        raise ConnectionError("æ— æ³•è¿æ¥åˆ°ä»»ä½• Hugging Face ç«¯ç‚¹ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
    
    # è·å–é…ç½®çš„ç«¯ç‚¹
    configured_endpoint = _get_hf_endpoint()
    cli_available = _is_huggingface_cli_available()
    
    download_attempts = []
    
    # ç­–ç•¥1: ä½¿ç”¨ huggingface-cli + é…ç½®çš„é•œåƒç«™
    if cli_available:
        if show_progress:
            console.print(f"ğŸš€ [bold blue]ç­–ç•¥1: huggingface-cli + é…ç½®ç«¯ç‚¹[/bold blue] ({configured_endpoint})")
        
        try:
            result = _download_with_huggingface_cli(hf_id_or_path, filename, configured_endpoint, show_progress)
            if result:
                if show_progress:
                    console.print("âœ… [bold green]ç­–ç•¥1 æˆåŠŸ![/bold green]")
                return result
        except Exception as e:
            download_attempts.append(f"ç­–ç•¥1 (huggingface-cli + {configured_endpoint}): {str(e)}")
    
    # ç­–ç•¥2: ä½¿ç”¨ hf_hub_download + é…ç½®çš„é•œåƒç«™
    if show_progress:
        console.print(f"ğŸ“¦ [bold blue]ç­–ç•¥2: hf_hub_download + é…ç½®ç«¯ç‚¹[/bold blue] ({configured_endpoint})")
    
    try:
        result = _download_with_hf_hub(hf_id_or_path, filename, configured_endpoint, show_progress)
        if result:
            if show_progress:
                console.print("âœ… [bold green]ç­–ç•¥2 æˆåŠŸ![/bold green]")
            return result
    except Exception as e:
        download_attempts.append(f"ç­–ç•¥2 (hf_hub_download + {configured_endpoint}): {str(e)}")
    
    # ç­–ç•¥3&4: éå†æ‰€æœ‰é•œåƒç«™
    if show_progress:
        console.print(f"ğŸ”„ [bold yellow]é…ç½®çš„ç«¯ç‚¹ {configured_endpoint} ä¸å¯ç”¨ï¼Œå¼€å§‹å°è¯•å…¶ä»–é•œåƒç«™...[/bold yellow]")
        console.print(f"ğŸ“‹ [dim]å°†å°è¯• {len([s for s in HF_MIRROR_SITES if s != configured_endpoint])} ä¸ªå¤‡ç”¨é•œåƒç«™[/dim]")
    
    mirror_attempts = 0
    for i, endpoint in enumerate(HF_MIRROR_SITES):
        if endpoint == configured_endpoint:
            continue  # è·³è¿‡å·²ç»å°è¯•è¿‡çš„ç«¯ç‚¹
        
        mirror_attempts += 1
        if show_progress:
            console.print(f"\nğŸŒ [bold blue]å°è¯•é•œåƒç«™ {mirror_attempts}:[/bold blue] [cyan]{endpoint}[/cyan]")
        
        # å…ˆæ£€æŸ¥é•œåƒç«™è¿é€šæ€§
        if not _check_endpoint_connectivity(endpoint):
            if show_progress:
                console.print(f"âŒ [yellow]é•œåƒç«™ä¸å¯è¾¾ï¼Œè·³è¿‡[/yellow]")
            download_attempts.append(f"é•œåƒç«™ {endpoint}: ç½‘ç»œä¸å¯è¾¾")
            continue
        
        # ç­–ç•¥3: huggingface-cli + å½“å‰é•œåƒç«™
        if cli_available:
            try:
                result = _download_with_huggingface_cli(hf_id_or_path, filename, endpoint, show_progress)
                if result:
                    if show_progress:
                        console.print(f"âœ… [bold green]ä½¿ç”¨ {endpoint} + huggingface-cli ä¸‹è½½æˆåŠŸ![/bold green]")
                    return result
            except Exception as e:
                download_attempts.append(f"huggingface-cli + {endpoint}: {str(e)}")
        
        # ç­–ç•¥4: hf_hub_download + å½“å‰é•œåƒç«™
        try:
            result = _download_with_hf_hub(hf_id_or_path, filename, endpoint, show_progress)
            if result:
                if show_progress:
                    console.print(f"âœ… [bold green]ä½¿ç”¨ {endpoint} + hf_hub_download ä¸‹è½½æˆåŠŸ![/bold green]")
                return result
        except Exception as e:
            download_attempts.append(f"hf_hub_download + {endpoint}: {str(e)}")
    
    # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥äº†
    if show_progress:
        console.print(f"\nâŒ [bold red]æ‰€æœ‰ {len(download_attempts)} ç§ä¸‹è½½ç­–ç•¥å‡å·²å°è¯•å®Œæ¯•[/bold red]")
    
    error_summary = "\n".join([f"   â€¢ {attempt}" for attempt in download_attempts])
    error_msg = f"""âŒ [bold red]æ‰€æœ‰ä¸‹è½½ç­–ç•¥å‡å¤±è´¥[/bold red]

ğŸ“‹ [bold]å°è¯•çš„ä¸‹è½½æ–¹å¼:[/bold]
{error_summary}

ğŸ’¡ [bold yellow]è§£å†³å»ºè®®:[/bold yellow]
   â€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š
   â€¢ ç¡®è®¤æ¨¡å‹IDæ˜¯å¦æ­£ç¡®: [cyan]{hf_id_or_path}[/cyan]
   â€¢ å°è¯•æ‰‹åŠ¨è®¿é—®: [link]https://huggingface.co/{hf_id_or_path}[/link]
   â€¢ è€ƒè™‘é…ç½®ä¸åŒçš„é•œåƒç«™: translate init"""
    
    if show_progress:
        console.print(error_msg)
    
    # å°è¯•åˆ¤æ–­å…·ä½“çš„é”™è¯¯ç±»å‹
    for attempt in download_attempts:
        if "404" in attempt or "Repository not found" in attempt:
            raise RepositoryNotFoundError(f"æ¨¡å‹ä»“åº“ä¸å­˜åœ¨: {hf_id_or_path}")
        elif "File not found" in attempt or f"{filename}" in attempt:
            raise LocalEntryNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {hf_id_or_path}/{filename}")
    
    raise Exception(f"æ— æ³•ä¸‹è½½æ–‡ä»¶ {filename} ä» {hf_id_or_path}")


def _find_cached_model(hf_id_or_path: str) -> tuple[str, str]:
    """
    æŸ¥æ‰¾å·²ç¼“å­˜çš„ Hugging Face æ¨¡å‹æ–‡ä»¶
    
    Args:
        hf_id_or_path: Hugging Face æ¨¡å‹ID
        
    Returns:
        tuple: (config_path, weight_path)
        
    Raises:
        FileNotFoundError: æ‰¾ä¸åˆ°ç¼“å­˜çš„æ¨¡å‹æ–‡ä»¶
    """
    # å°è¯•ä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤ä½ç½®æ‰¾åˆ° HF ç¼“å­˜ç›®å½•
    cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
    cache_dir = Path(cache_dir)
    
    # æ„å»ºæ¨¡å‹ç¼“å­˜è·¯å¾„
    model_cache_name = hf_id_or_path.replace("/", "--")
    model_cache_dir = cache_dir / "hub" / f"models--{model_cache_name}"
    
    logger.debug(f"æ­£åœ¨æŸ¥æ‰¾ç¼“å­˜æ¨¡å‹: {model_cache_dir}")
    
    if not model_cache_dir.exists():
        raise FileNotFoundError(f"æ¨¡å‹ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
    
    # æŸ¥æ‰¾ snapshots ç›®å½•ä¸‹çš„æœ€æ–°ç‰ˆæœ¬
    snapshots_dir = model_cache_dir / "snapshots"
    if not snapshots_dir.exists():
        raise FileNotFoundError(f"æ¨¡å‹å¿«ç…§ç›®å½•ä¸å­˜åœ¨")
    
    # è·å–æœ€æ–°çš„å¿«ç…§ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼‰
    snapshot_dirs = [d for d in snapshots_dir.iterdir() if d.is_dir()]
    if not snapshot_dirs:
        raise FileNotFoundError(f"æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹å¿«ç…§")
    
    latest_snapshot = max(snapshot_dirs, key=lambda d: d.stat().st_mtime)
    logger.debug(f"æ‰¾åˆ°æœ€æ–°å¿«ç…§: {latest_snapshot}")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶å’Œæƒé‡æ–‡ä»¶
    config_path = latest_snapshot / "config.json"
    weight_path = latest_snapshot / "model.safetensors"
    
    if not config_path.exists():
        raise FileNotFoundError(f"ç¼“å­˜çš„é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
    if not weight_path.exists():
        raise FileNotFoundError(f"ç¼“å­˜çš„æƒé‡æ–‡ä»¶ä¸å­˜åœ¨æˆ–æœªå®Œæ•´ä¸‹è½½")
    
    logger.debug(f"æ‰¾åˆ°ç¼“å­˜çš„é…ç½®æ–‡ä»¶: {config_path}")
    logger.debug(f"æ‰¾åˆ°ç¼“å­˜çš„æƒé‡æ–‡ä»¶: {weight_path}")
    
    return str(config_path), str(weight_path)


def _load_model_files(config_path: str, weight_path: str, silent: bool = False) -> tuple[dict, str]:
    """
    æ¨¡å‹æ–‡ä»¶åŠ è½½å‡½æ•°ï¼Œå…·æœ‰ç”¨æˆ·å‹å¥½çš„é”™è¯¯å¤„ç†
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        weight_path: æƒé‡æ–‡ä»¶è·¯å¾„
        silent: æ˜¯å¦ç¦ç”¨è¯¦ç»†çš„é”™è¯¯è¾“å‡º
        
    Returns:
        tuple: (config_dict, weight_path)
        
    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        json.JSONDecodeError: JSON è§£æé”™è¯¯
        Exception: å…¶ä»–åŠ è½½é”™è¯¯
    """
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not Path(config_path).exists():
        if not silent:
            logger.info("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†å°è¯•åœ¨çº¿ä¸‹è½½")
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {Path(config_path).name}")
    
    # æ£€æŸ¥æƒé‡æ–‡ä»¶
    if not Path(weight_path).exists():
        if not silent:
            logger.info("æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†å°è¯•åœ¨çº¿ä¸‹è½½")
        raise FileNotFoundError(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {Path(weight_path).name}")
    
    try:
        logger.debug(f"æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
            
        logger.debug("æ¨¡å‹æ–‡ä»¶åŠ è½½æˆåŠŸ")
        return config, weight_path
        
    except json.JSONDecodeError as e:
        if not silent:
            logger.warning("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå¯èƒ½å·²æŸå")
        raise json.JSONDecodeError("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯", config_path, 0) from e
    except Exception as e:
        if not silent:
            logger.warning("æ¨¡å‹æ–‡ä»¶è®¿é—®å¤±è´¥")
        raise e


def from_pretrained(
    hf_id_or_path: str, *, dtype: mx.Dtype = mx.bfloat16, show_progress: bool = True, 
    use_cache: bool = True
) -> BaseParakeet:
    """
    ä» Hugging Face æˆ–æœ¬åœ°ç›®å½•åŠ è½½æ¨¡å‹ï¼Œæ”¯æŒå†…å­˜å’Œå­˜å‚¨å±‚ç¼“å­˜ä¼˜åŒ–
    
    åŠ è½½ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. å†…å­˜ç¼“å­˜ï¼ˆæœ€å¿«ï¼Œæ¯«ç§’çº§ï¼‰
    2. å­˜å‚¨å±‚ä¼˜åŒ–ç¼“å­˜ï¼ˆå¿«ï¼Œç§’çº§ï¼‰
    3. æœ¬åœ°ç¼“å­˜çš„åŸå§‹æ¨¡å‹æ–‡ä»¶ï¼ˆä¸­ç­‰ï¼‰
    4. æŒ‡å®šçš„æœ¬åœ°è·¯å¾„åŠ è½½ï¼ˆä¸­ç­‰ï¼‰
    5. ä» Hugging Face Hub ä¸‹è½½ï¼ˆæœ€æ…¢ï¼‰
    
    Args:
        hf_id_or_path: Hugging Face æ¨¡å‹IDæˆ–æœ¬åœ°è·¯å¾„
        dtype: æ¨¡å‹æ•°æ®ç±»å‹
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†çš„åŠ è½½è¿›åº¦
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–
        
    Returns:
        åŠ è½½çš„ Parakeet æ¨¡å‹
        
    Raises:
        ValueError: ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹
        FileNotFoundError: é…ç½®æ–‡ä»¶æˆ–æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨
        Exception: å…¶ä»–åŠ è½½é”™è¯¯
    """
    
    def _original_loader() -> BaseParakeet:
        """åŸå§‹çš„æ¨¡å‹åŠ è½½é€»è¾‘ï¼Œä½œä¸ºfallback"""
        return _load_model_original(hf_id_or_path, dtype, show_progress)
    
    # ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–çš„åŠ è½½
    if use_cache:
        return load_cached_model(hf_id_or_path, dtype, _original_loader)
    else:
        # ä¸ä½¿ç”¨ç¼“å­˜ï¼Œç›´æ¥åŠ è½½
        return _original_loader()


def _load_model_original(
    hf_id_or_path: str, dtype: mx.Dtype = mx.bfloat16, show_progress: bool = True
) -> BaseParakeet:
    """
    åŸå§‹æ¨¡å‹åŠ è½½é€»è¾‘ï¼ˆé‡æ„åçš„å†…éƒ¨å‡½æ•°ï¼‰
    
    åŠ è½½ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. å­˜å‚¨å±‚ä¼˜åŒ–ç¼“å­˜ï¼ˆé¢„ç¼–è¯‘æ¨¡å‹ï¼‰
    2. æœ¬åœ°ç¼“å­˜çš„åŸå§‹æ¨¡å‹æ–‡ä»¶
    3. æŒ‡å®šçš„æœ¬åœ°è·¯å¾„åŠ è½½
    4. ä» Hugging Face Hub ä¸‹è½½
    """
    if show_progress:
        console.print(f"\nğŸ¤– [bold cyan]å¼€å§‹åŠ è½½æ¨¡å‹:[/bold cyan] [bold]{hf_id_or_path}[/bold]")
        console.print("ğŸ“‹ [dim]åŠ è½½ç­–ç•¥: å­˜å‚¨ä¼˜åŒ–ç¼“å­˜ â†’ æœ¬åœ°ç¼“å­˜ â†’ æœ¬åœ°è·¯å¾„ â†’ åœ¨çº¿ä¸‹è½½[/dim]\n")
    
    config = None
    weight = None
    loading_method = None
    
    # ç­–ç•¥1: å°è¯•ä»å­˜å‚¨å±‚ä¼˜åŒ–ç¼“å­˜åŠ è½½ï¼ˆæœ€å¿«çš„æ–‡ä»¶åŠ è½½ï¼‰
    try:
        if show_progress:
            with console.status("[bold blue]ğŸš€ ç­–ç•¥1: æŸ¥æ‰¾å­˜å‚¨å±‚ä¼˜åŒ–ç¼“å­˜...[/bold blue]"):
                time.sleep(0.2)  # ç»™ç”¨æˆ·ä¸€ç‚¹æ—¶é—´çœ‹åˆ°çŠ¶æ€
                optimized_model = _storage_optimizer.load_optimized_model(hf_id_or_path, dtype)
        else:
            optimized_model = _storage_optimizer.load_optimized_model(hf_id_or_path, dtype)
        
        if optimized_model is not None:
            loading_method = "å­˜å‚¨ä¼˜åŒ–ç¼“å­˜"
            if show_progress:
                console.print("âœ… [bold green]ä»å­˜å‚¨ä¼˜åŒ–ç¼“å­˜åŠ è½½æˆåŠŸ![/bold green] (æé€ŸåŠ è½½)")
                console.print(f"\nğŸ‰ [bold green]æ¨¡å‹åŠ è½½å®Œæˆ![/bold green] (åŠ è½½æ–¹å¼: [bold cyan]{loading_method}[/bold cyan])")
                console.print("â”" * 60)
            return optimized_model
        else:
            if show_progress:
                console.print("ğŸ” [dim]å­˜å‚¨ä¼˜åŒ–ç¼“å­˜ä¸å¯ç”¨ï¼Œå°†å°è¯•å…¶ä»–æ–¹å¼[/dim]")
    except Exception as e:
        if show_progress:
            console.print(f"ğŸ” [dim]å­˜å‚¨ä¼˜åŒ–ç¼“å­˜æŸ¥æ‰¾å¤±è´¥: {str(e)}[/dim]")
        logger.debug(f"å­˜å‚¨ä¼˜åŒ–ç¼“å­˜æŸ¥æ‰¾å¤±è´¥: {str(e)}")
    
    config = None
    weight = None
    
    # ç­–ç•¥2: æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜çš„åŸå§‹æ¨¡å‹æ–‡ä»¶ï¼ˆæ— ç½‘ç»œè¯·æ±‚ï¼‰
    try:
        if show_progress:
            with console.status("[bold blue]ğŸ” ç­–ç•¥2: æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹æ–‡ä»¶...[/bold blue]"):
                time.sleep(0.3)  # ç»™ç”¨æˆ·ä¸€ç‚¹æ—¶é—´çœ‹åˆ°çŠ¶æ€
                config_path, weight_path = _find_cached_model(hf_id_or_path)
                config, weight = _load_model_files(config_path, weight_path, silent=not show_progress)
        else:
            config_path, weight_path = _find_cached_model(hf_id_or_path)
            config, weight = _load_model_files(config_path, weight_path, silent=True)
        
        loading_method = "æœ¬åœ°ç¼“å­˜"
        if show_progress:
            console.print("âœ… [bold green]æˆåŠŸä»æœ¬åœ°ç¼“å­˜åŠ è½½æ¨¡å‹æ–‡ä»¶[/bold green] (æ— éœ€ä¸‹è½½)")
        
    except Exception as e:
        if show_progress:
            console.print(f"ğŸ” [dim]æœ¬åœ°ç¼“å­˜ä¸å¯ç”¨ï¼Œå°†å°è¯•å…¶ä»–æ–¹å¼[/dim]")
        logger.debug(f"æœ¬åœ°ç¼“å­˜æŸ¥æ‰¾å¤±è´¥: {str(e)}")
    
    # ç­–ç•¥3: å°è¯•ä»æŒ‡å®šçš„æœ¬åœ°è·¯å¾„åŠ è½½
    if config is None:
        try:
            if show_progress:
                with console.status("[bold blue]ğŸ” ç­–ç•¥3: å°è¯•ä»æŒ‡å®šçš„æœ¬åœ°è·¯å¾„åŠ è½½...[/bold blue]"):
                    local_path = Path(hf_id_or_path)
                    config_path = str(local_path / "config.json")
                    weight_path = str(local_path / "model.safetensors")
                    config, weight = _load_model_files(config_path, weight_path, silent=not show_progress)
            else:
                local_path = Path(hf_id_or_path)
                config_path = str(local_path / "config.json")
                weight_path = str(local_path / "model.safetensors")
                config, weight = _load_model_files(config_path, weight_path, silent=True)
            
            loading_method = "æœ¬åœ°è·¯å¾„"
            if show_progress:
                console.print("âœ… [bold green]æˆåŠŸä»æŒ‡å®šæœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹æ–‡ä»¶[/bold green]")
            
        except Exception as e:
            if show_progress:
                console.print(f"ğŸ” [dim]æŒ‡å®šæœ¬åœ°è·¯å¾„ä¸å¯ç”¨ï¼Œå°†å°è¯•åœ¨çº¿ä¸‹è½½[/dim]")
            logger.debug(f"æœ¬åœ°è·¯å¾„åŠ è½½å¤±è´¥: {str(e)}")
    
    # ç­–ç•¥4: æœ€åæ‰ä» Hugging Face Hub ä¸‹è½½ï¼ˆéœ€è¦ç½‘ç»œè¿æ¥ï¼‰
    if config is None:
        try:
            if show_progress:
                console.print("\nâš ï¸  [bold yellow]æœ¬åœ°æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œå¼€å§‹åœ¨çº¿ä¸‹è½½[/bold yellow]")
                console.print(f"ğŸ“¦ [bold]æ¨¡å‹ä¿¡æ¯:[/bold] [cyan]{hf_id_or_path}[/cyan]")
                console.print("ğŸ“ [bold]é¢„è®¡å¤§å°:[/bold] ~1.2GB")
                console.print("â±ï¸  [bold]é¢„è®¡æ—¶é—´:[/bold] 3-10åˆ†é’Ÿ (å–å†³äºç½‘ç»œé€Ÿåº¦)")
                console.print("ğŸ’¡ [dim]æç¤º: é¦–æ¬¡ä¸‹è½½è¾ƒå¤§ï¼Œåç»­ä½¿ç”¨å°†ç›´æ¥ä»ç¼“å­˜åŠ è½½[/dim]")
                console.print("ğŸ”„ [dim]ä¸‹è½½ä¸­æ–­å¯ä»¥é‡æ–°è¿è¡Œå‘½ä»¤ç»§ç»­ä¸‹è½½[/dim]")
                
                # æ£€æŸ¥ç½‘ç»œè¿æ¥
                with console.status("[bold blue]ğŸŒ æ£€æŸ¥ç½‘ç»œè¿æ¥...[/bold blue]"):
                    if not _check_network_connectivity():
                        raise ConnectionError("æ— æ³•è¿æ¥åˆ° Hugging Face Hub")
                
                console.print("âœ… [green]ç½‘ç»œè¿æ¥æ­£å¸¸[/green]")
                
            config_path = _download_with_retry(hf_id_or_path, "config.json", show_progress)
            weight_path = _download_with_retry(hf_id_or_path, "model.safetensors", show_progress)
            
            config, weight = _load_model_files(config_path, weight_path, silent=not show_progress)
            loading_method = "åœ¨çº¿ä¸‹è½½"
            if show_progress:
                console.print("\nâœ… [bold green]æ¨¡å‹ä¸‹è½½å¹¶åŠ è½½æˆåŠŸï¼[/bold green]")
                console.print("ğŸ‰ [dim]æ¨¡å‹å·²ç¼“å­˜åˆ°æœ¬åœ°ï¼Œåç»­ä½¿ç”¨å°†æ›´å¿«[/dim]")
            
        except (RepositoryNotFoundError, LocalEntryNotFoundError):
            error_msg = f"âŒ Hugging Face Hub ä¸­æœªæ‰¾åˆ°æŒ‡å®šæ¨¡å‹: [bold red]{hf_id_or_path}[/bold red]"
            if show_progress:
                console.print(error_msg)
            logger.error(error_msg)
            
        except ConnectionError as e:
            error_msg = f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥: {str(e)}"
            if show_progress:
                console.print(f"[bold red]{error_msg}[/bold red]")
                console.print("ğŸ’¡ [dim]å»ºè®®ï¼š[/dim]")
                console.print("   â€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥")
                console.print("   â€¢ è¿è¡Œ 'translate init' é…ç½®é•œåƒç«™")
                console.print("   â€¢ å°è¯•è®¾ç½®ç¯å¢ƒå˜é‡: HF_ENDPOINT=https://hf-mirror.com")
            logger.error(error_msg)
            
        except Exception as e:
            error_msg = f"âŒ ä» Hugging Face Hub ä¸‹è½½å¤±è´¥: {str(e)}"
            if show_progress:
                console.print(f"[bold red]{error_msg}[/bold red]")
            logger.error(error_msg)
    
    # å¦‚æœæ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥äº†
    if config is None:
        error_msg = f"""âŒ [bold red]æ— æ³•åŠ è½½æ¨¡å‹ {hf_id_or_path}[/bold red]

ğŸ“‹ [bold]å·²å°è¯•çš„åŠ è½½ç­–ç•¥:[/bold]
   1. âŒ å­˜å‚¨ä¼˜åŒ–ç¼“å­˜åŠ è½½å¤±è´¥
   2. âŒ æœ¬åœ°ç¼“å­˜åŠ è½½å¤±è´¥
   3. âŒ æŒ‡å®šæœ¬åœ°è·¯å¾„åŠ è½½å¤±è´¥  
   4. âŒ åœ¨çº¿ä¸‹è½½å¤±è´¥

ğŸ’¡ [bold yellow]è§£å†³å»ºè®®:[/bold yellow]
   â€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
   â€¢ ç¡®è®¤æ¨¡å‹IDæ˜¯å¦æ­£ç¡®: [cyan]{hf_id_or_path}[/cyan]
   â€¢ å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼Œç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨
   â€¢ è¿è¡Œ 'translate init' é…ç½®é•œåƒç«™
   â€¢ å°è¯•æ‰‹åŠ¨è®¿é—®: [link]https://huggingface.co/{hf_id_or_path}[/link]"""
        
        if show_progress:
            console.print(error_msg)
        
        logger.error(f"æ‰€æœ‰æ¨¡å‹åŠ è½½ç­–ç•¥å‡å¤±è´¥: {hf_id_or_path}")
        raise Exception(f"æ— æ³•åŠ è½½æ¨¡å‹ {hf_id_or_path}")

    # æ„å»ºå’ŒåŠ è½½æ¨¡å‹
    try:
        if show_progress:
            console.print(f"\nğŸ”§ [bold blue]æ­£åœ¨æ„å»ºæ¨¡å‹...[/bold blue]")
            with console.status("[bold blue]è§£æé…ç½®æ–‡ä»¶...[/bold blue]"):
                model = from_config(config)
        else:
            model = from_config(config)
        
        if show_progress:
            console.print("âœ… [green]æ¨¡å‹æ„å»ºæˆåŠŸ[/green]")
            
            with console.status("[bold blue]ğŸ”— æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡...[/bold blue]"):
                model.load_weights(weight)
            console.print("âœ… [green]æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ[/green]")
        else:
            model.load_weights(weight)

        # è½¬æ¢æ•°æ®ç±»å‹
        if show_progress:
            with console.status(f"[bold blue]ğŸ”„ æ­£åœ¨è½¬æ¢æ¨¡å‹æ•°æ®ç±»å‹ä¸º {dtype}...[/bold blue]"):
                curr_weights = dict(tree_flatten(model.parameters()))
                curr_weights = [(k, v.astype(dtype)) for k, v in curr_weights.items()]
                model.update(tree_unflatten(curr_weights))
            console.print(f"âœ… [green]æ•°æ®ç±»å‹è½¬æ¢å®Œæˆ[/green] ({dtype})")
        else:
            curr_weights = dict(tree_flatten(model.parameters()))
            curr_weights = [(k, v.astype(dtype)) for k, v in curr_weights.items()]
            model.update(tree_unflatten(curr_weights))
        
        # å¦‚æœæ˜¯ä»åŸå§‹æ–‡ä»¶åŠ è½½ä¸”ä¸æ˜¯å­˜å‚¨ä¼˜åŒ–ç¼“å­˜ï¼Œå°è¯•ä¿å­˜ä¼˜åŒ–ç¼“å­˜ï¼ˆå¼‚æ­¥ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰
        if loading_method in ["æœ¬åœ°ç¼“å­˜", "æœ¬åœ°è·¯å¾„", "åœ¨çº¿ä¸‹è½½"]:
            try:
                if show_progress:
                    with console.status("[bold blue]ğŸ’¾ ä¿å­˜å­˜å‚¨ä¼˜åŒ–ç¼“å­˜...[/bold blue]"):
                        _storage_optimizer.save_optimized_model(hf_id_or_path, dtype, model, config, weight)
                    console.print("âœ… [green]å­˜å‚¨ä¼˜åŒ–ç¼“å­˜å·²ä¿å­˜[/green] (ä¸‹æ¬¡åŠ è½½å°†æ›´å¿«)")
                else:
                    _storage_optimizer.save_optimized_model(hf_id_or_path, dtype, model, config, weight)
                    logger.debug("å­˜å‚¨ä¼˜åŒ–ç¼“å­˜å·²ä¿å­˜")
            except Exception as e:
                # ä¿å­˜ç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                logger.debug(f"ä¿å­˜å­˜å‚¨ä¼˜åŒ–ç¼“å­˜å¤±è´¥: {e}")
                if show_progress:
                    console.print("âš ï¸  [yellow]å­˜å‚¨ä¼˜åŒ–ç¼“å­˜ä¿å­˜å¤±è´¥ï¼Œä¸å½±å“æ¨¡å‹ä½¿ç”¨[/yellow]")
        
        if show_progress:
            console.print(f"\nğŸ‰ [bold green]æ¨¡å‹åŠ è½½å®Œæˆ![/bold green] (åŠ è½½æ–¹å¼: [bold cyan]{loading_method}[/bold cyan])")
            console.print("â”" * 60)
        
        return model
        
    except Exception as e:
        error_msg = f"âŒ æ¨¡å‹æ„å»ºæˆ–æƒé‡åŠ è½½å¤±è´¥: {str(e)}"
        if show_progress:
            console.print(f"[bold red]{error_msg}[/bold red]")
        logger.error(error_msg)
        raise Exception(error_msg) from e
