import datetime
import json
from pathlib import Path
from typing import Any, Dict, List, Optional

import typer
from mlx.core import bfloat16, float32
from rich import print
from rich.console import Console
from rich.progress import (
    BarColumn,
    Progress,
    SpinnerColumn,
    TextColumn,
    TimeElapsedColumn,
)
from rich.table import Table
from typing_extensions import Annotated

from . import AlignedResult, AlignedSentence, AlignedToken, from_pretrained
from .utils import _find_cached_model, _check_network_connectivity

# é»˜è®¤è½¬å½•æ¨¡å‹
DEFAULT_TRANSCRIPTION_MODEL = "mlx-community/parakeet-tdt-0.6b-v2"

# åˆå§‹åŒ–æ§åˆ¶å°
console = Console()

# helpers
def format_timestamp(
    seconds: float, always_include_hours: bool = True, decimal_marker: str = ","
) -> str:
    assert seconds >= 0
    milliseconds = round(seconds * 1000.0)

    hours = milliseconds // 3_600_000
    milliseconds %= 3_600_000

    minutes = milliseconds // 60_000
    milliseconds %= 60_000

    seconds = milliseconds // 1_000
    milliseconds %= 1_000

    hours_marker = f"{hours:02d}:" if always_include_hours or hours > 0 else ""
    return (
        f"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}"
    )


def to_txt(result: AlignedResult) -> str:
    """Format transcription result as plain text."""
    return result.text.strip()


def to_srt(result: AlignedResult, timestamps: bool = False) -> str:
    """
    Format transcription result as an SRT file.
    """
    srt_content = []
    entry_index = 1
    if timestamps:
        words = result.words
        for word in words:
            if not word.text.strip():
                continue
            start_time = format_timestamp(word.start, decimal_marker=",")
            end_time = format_timestamp(word.end, decimal_marker=",")
            text = word.text.strip()

            srt_content.append(f"{entry_index}")
            srt_content.append(f"{start_time} --> {end_time}")
            srt_content.append(text)
            srt_content.append("")
            entry_index += 1
    else:
        for sentence in result.sentences:
            start_time = format_timestamp(sentence.start, decimal_marker=",")
            end_time = format_timestamp(sentence.end, decimal_marker=",")
            text = sentence.text.strip()

            srt_content.append(f"{entry_index}")
            srt_content.append(f"{start_time} --> {end_time}")
            srt_content.append(text)
            srt_content.append("")
            entry_index += 1

    return "\n".join(srt_content)


def to_vtt(result: AlignedResult, timestamps: bool = False) -> str:
    """
    Format transcription result as a VTT file.
    """
    vtt_content = ["WEBVTT", ""]
    if timestamps:
        words = result.words
        for word in words:
            if not word.text.strip():
                continue
            start_time = format_timestamp(word.start, decimal_marker=".")
            end_time = format_timestamp(word.end, decimal_marker=".")
            text = word.text.strip()

            vtt_content.append(f"{start_time} --> {end_time}")
            vtt_content.append(text)
            vtt_content.append("")
    else:
        for sentence in result.sentences:
            start_time = format_timestamp(sentence.start, decimal_marker=".")
            end_time = format_timestamp(sentence.end, decimal_marker=".")
            text_line = sentence.text.strip()

            vtt_content.append(f"{start_time} --> {end_time}")
            vtt_content.append(text_line)
            vtt_content.append("")

    return "\n".join(vtt_content)


def _aligned_token_to_dict(token: AlignedToken) -> Dict[str, Any]:
    return {
        "text": token.text,
        "start": round(token.start, 3),
        "end": round(token.end, 3),
        "duration": round(token.duration, 3),
    }


def _aligned_sentence_to_dict(sentence: AlignedSentence) -> Dict[str, Any]:
    return {
        "text": sentence.text,
        "start": round(sentence.start, 3),
        "end": round(sentence.end, 3),
        "duration": round(sentence.duration, 3),
        "tokens": [_aligned_token_to_dict(token) for token in sentence.tokens],
    }


def to_json(result: AlignedResult) -> str:
    output_dict = {
        "text": result.text,
        "sentences": [
            _aligned_sentence_to_dict(sentence) for sentence in result.sentences
        ],
    }
    return json.dumps(output_dict, indent=2, ensure_ascii=False)


app = typer.Typer(
    help="ä½¿ç”¨ Parakeet MLX æ¨¡å‹è¿›è¡ŒéŸ³é¢‘è½¬å½•çš„å‘½ä»¤è¡Œå·¥å…·",
    epilog="ğŸ’¡ é¦–æ¬¡ä½¿ç”¨å‰å¯ä»¥è¿è¡Œ: transcribe model download <model_id> æ¥é¢„ä¸‹è½½æ¨¡å‹"
)


@app.callback(invoke_without_command=True)
def main(
    ctx: typer.Context,
    audios: Annotated[
        Optional[List[Path]],
        typer.Argument(
            help="è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶",
            exists=True,
            file_okay=True,
            dir_okay=False,
            readable=True,
        ),
    ] = None,
    model: Annotated[
        str, typer.Option(help="è¦ä½¿ç”¨çš„ Hugging Face æ¨¡å‹ä»“åº“")
    ] = "mlx-community/parakeet-tdt-0.6b-v2",
    output_dir: Annotated[
        Path, typer.Option(help="ä¿å­˜è½¬å½•ç»“æœçš„ç›®å½•")
    ] = Path("."),
    output_format: Annotated[
        str, typer.Option(help="è¾“å‡ºæ–‡ä»¶æ ¼å¼ (txt, srt, vtt, json, all)")
    ] = "srt",
    output_template: Annotated[
        str,
        typer.Option(
            help="è¾“å‡ºæ–‡ä»¶åæ¨¡æ¿ï¼Œä¾‹å¦‚ '{filename}_{date}_{index}'"
        ),
    ] = "{filename}",
    timestamps: Annotated[
        bool,
        typer.Option(help="åœ¨ srt/vtt æ ¼å¼ä¸­è¾“å‡ºè¯çº§æ—¶é—´æˆ³"),
    ] = False,
    chunk_duration: Annotated[
        float,
        typer.Option(
            help="é•¿éŸ³é¢‘çš„åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ0 ç¦ç”¨åˆ†å—ã€‚"
        ),
    ] = 60 * 2,
    overlap_duration: Annotated[
        float, typer.Option(help="ä½¿ç”¨åˆ†å—æ—¶çš„é‡å æ—¶é•¿ï¼ˆç§’ï¼‰")
    ] = 15,
    verbose: Annotated[
        bool,
        typer.Option("--verbose", "-v", help="æ‰“å°è¯¦ç»†çš„å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯"),
    ] = False,
    fp32: Annotated[
        bool, typer.Option("--fp32/--bf16", help="ä½¿ç”¨ FP32 ç²¾åº¦")
    ] = False,
):
    """
    ä½¿ç”¨ Parakeet MLX æ¨¡å‹è½¬å½•éŸ³é¢‘æ–‡ä»¶ã€‚
    """
    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return
    
    # å¦‚æœæ²¡æœ‰æä¾›éŸ³é¢‘æ–‡ä»¶ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if not audios:
        print("[bold red]é”™è¯¯: è¯·æä¾›è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶[/bold red]")
        print("\nğŸ’¡ [bold blue]ä½¿ç”¨ç¤ºä¾‹:[/bold blue]")
        print("   transcribe audio.mp3 audio2.wav                    # è½¬å½•å¤šä¸ªæ–‡ä»¶")
        print("   transcribe *.mp3 --output-format all              # è½¬å½•æ‰€æœ‰mp3æ–‡ä»¶ä¸ºæ‰€æœ‰æ ¼å¼")
        print("   transcribe audio.wav --model other-model          # ä½¿ç”¨æŒ‡å®šæ¨¡å‹")
        print("   transcribe model list                             # æŸ¥çœ‹å·²ç¼“å­˜çš„æ¨¡å‹")
        raise typer.Exit(code=1)
    
    _transcribe_files(
        audios=audios,
        model=model,
        output_dir=output_dir,
        output_format=output_format,
        output_template=output_template,
        timestamps=timestamps,
        chunk_duration=chunk_duration,
        overlap_duration=overlap_duration,
        verbose=verbose,
        fp32=fp32
    )


def _transcribe_files(
    audios: List[Path],
    model: str,
    output_dir: Path,
    output_format: str,
    output_template: str,
    timestamps: bool,
    chunk_duration: float,
    overlap_duration: float,
    verbose: bool,
    fp32: bool
):
    """æ‰§è¡ŒéŸ³é¢‘è½¬å½•çš„æ ¸å¿ƒé€»è¾‘"""
    if verbose:
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: [bold cyan]{model}[/bold cyan]...")

    try:
        # ä½¿ç”¨å¢å¼ºçš„æ¨¡å‹åŠ è½½ä½“éªŒ
        loaded_model = from_pretrained(
            model, 
            dtype=bfloat16 if not fp32 else float32,
            show_progress=verbose
        )
        if verbose:
            print("[green]æ¨¡å‹åŠ è½½æˆåŠŸã€‚[/green]")
    except Exception as e:
        print(f"[bold red]åŠ è½½æ¨¡å‹ {model} æ—¶å‡ºé”™:[/bold red] {e}")
        raise typer.Exit(code=1)

    try:
        output_dir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        print(f"[bold red]åˆ›å»ºè¾“å‡ºç›®å½• {output_dir} æ—¶å‡ºé”™:[/bold red] {e}")
        raise typer.Exit(code=1)

    if verbose:
        print(f"è¾“å‡ºç›®å½•: [bold cyan]{output_dir.resolve()}[/bold cyan]")
        print(f"è¾“å‡ºæ ¼å¼: [bold cyan]{output_format}[/bold cyan]")
        if output_format in ["srt", "vtt", "all"] and timestamps:
            print("æ—¶é—´æˆ³: [bold cyan]å·²å¯ç”¨[/bold cyan]")

    formatters = {
        "txt": to_txt,
        "srt": lambda r: to_srt(r, timestamps=timestamps),
        "vtt": lambda r: to_vtt(r, timestamps=timestamps),
        "json": to_json,
    }

    formats_to_generate = []
    if output_format == "all":
        formats_to_generate = list(formatters.keys())
    elif output_format in formatters:
        formats_to_generate = [output_format]
    else:
        print(
            f"[bold red]é”™è¯¯: æ— æ•ˆçš„è¾“å‡ºæ ¼å¼ '{output_format}'ã€‚è¯·ä» {list(formatters.keys()) + ['all']} ä¸­é€‰æ‹©ã€‚[/bold red]"
        )
        raise typer.Exit(code=1)

    total_files = len(audios)
    if verbose:
        print(f"æ­£åœ¨è½¬å½• {total_files} ä¸ªæ–‡ä»¶...")

    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        transient=True,
    ) as progress:
        task = progress.add_task("æ­£åœ¨è½¬å½•...", total=total_files)

        for i, audio_path in enumerate(audios):
            if verbose:
                print(
                    f"\næ­£åœ¨å¤„ç†æ–‡ä»¶ {i + 1}/{total_files}: [bold cyan]{audio_path.name}[/bold cyan]"
                )
            else:
                progress.update(
                    task, description=f"æ­£åœ¨å¤„ç† [cyan]{audio_path.name}[/cyan]..."
                )

            try:
                result: AlignedResult = loaded_model.transcribe(
                    audio_path,
                    dtype=bfloat16 if not fp32 else float32,
                    chunk_duration=chunk_duration if chunk_duration != 0 else None,
                    overlap_duration=overlap_duration,
                    chunk_callback=lambda current, full: progress.update(
                        task, total=total_files * full, completed=full * i + current
                    ),
                )

                if verbose:
                    for sentence in result.sentences:
                        start, end, text = sentence.start, sentence.end, sentence.text
                        line = f"[blue][{format_timestamp(start)} --> {format_timestamp(end)}][/blue] {text.strip()}"
                        print(line)

                base_filename = audio_path.stem
                template_vars = {
                    "filename": base_filename,
                    "date": datetime.datetime.now().strftime("%Y%m%d"),
                    "index": str(i + 1),
                }

                output_basename = output_template.format(**template_vars)

                for fmt in formats_to_generate:
                    formatter = formatters[fmt]
                    output_content = formatter(result)
                    output_filename = f"{output_basename}.{fmt}"
                    output_filepath = output_dir / output_filename

                    try:
                        with open(output_filepath, "w", encoding="utf-8") as f:
                            f.write(output_content)
                        if verbose:
                            print(
                                f"[green]å·²ä¿å­˜ {fmt.upper()}:[/green] {output_filepath.absolute()}"
                            )
                    except Exception as e:
                        print(
                            f"[bold red]å†™å…¥è¾“å‡ºæ–‡ä»¶ {output_filepath} æ—¶å‡ºé”™:[/bold red] {e}"
                        )

            except Exception as e:
                print(f"[bold red]è½¬å½•æ–‡ä»¶ {audio_path} æ—¶å‡ºé”™:[/bold red] {e}")

            progress.update(task, total=total_files, completed=i + 1)

    print(
        f"\n[bold green]è½¬å½•å®Œæˆã€‚[/bold green] è¾“å‡ºå·²ä¿å­˜åœ¨ '{output_dir.resolve()}'"
    )


app = typer.Typer(
    help="ä½¿ç”¨ Parakeet MLX æ¨¡å‹è¿›è¡ŒéŸ³é¢‘è½¬å½•çš„å‘½ä»¤è¡Œå·¥å…·",
    epilog="ğŸ’¡ é¦–æ¬¡ä½¿ç”¨å‰å¯ä»¥è¿è¡Œ: transcribe model download <model_id> æ¥é¢„ä¸‹è½½æ¨¡å‹"
)


@app.callback(invoke_without_command=True)
def main_callback(
    ctx: typer.Context,
    input_files: Annotated[
        Optional[str],
        typer.Option(
            "--input-files", "-i",
            help="è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆç”¨é€—å·åˆ†éš”å¤šä¸ªæ–‡ä»¶ï¼‰ï¼Œå¦‚ä¸æŒ‡å®šåˆ™ä½¿ç”¨ä½ç½®å‚æ•°"
        )
    ] = None,
    model: Annotated[
        str, typer.Option(help="è¦ä½¿ç”¨çš„ Hugging Face æ¨¡å‹ä»“åº“")
    ] = "mlx-community/parakeet-tdt-0.6b-v2",
    output_dir: Annotated[
        Path, typer.Option(help="ä¿å­˜è½¬å½•ç»“æœçš„ç›®å½•")
    ] = Path("."),
    output_format: Annotated[
        str, typer.Option(help="è¾“å‡ºæ–‡ä»¶æ ¼å¼ (txt, srt, vtt, json, all)")
    ] = "srt",
    output_template: Annotated[
        str,
        typer.Option(
            help="è¾“å‡ºæ–‡ä»¶åæ¨¡æ¿ï¼Œä¾‹å¦‚ '{filename}_{date}_{index}'"
        ),
    ] = "{filename}",
    timestamps: Annotated[
        bool,
        typer.Option(help="åœ¨ srt/vtt æ ¼å¼ä¸­è¾“å‡ºè¯çº§æ—¶é—´æˆ³"),
    ] = False,
    chunk_duration: Annotated[
        float,
        typer.Option(
            help="é•¿éŸ³é¢‘çš„åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ0 ç¦ç”¨åˆ†å—ã€‚"
        ),
    ] = 60 * 2,
    overlap_duration: Annotated[
        float, typer.Option(help="ä½¿ç”¨åˆ†å—æ—¶çš„é‡å æ—¶é•¿ï¼ˆç§’ï¼‰")
    ] = 15,
    verbose: Annotated[
        bool,
        typer.Option("--verbose", "-v", help="æ‰“å°è¯¦ç»†çš„å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯"),
    ] = False,
    fp32: Annotated[
        bool, typer.Option("--fp32/--bf16", help="ä½¿ç”¨ FP32 ç²¾åº¦")
    ] = False,
):
    """ä½¿ç”¨ Parakeet MLX æ¨¡å‹è½¬å½•éŸ³é¢‘æ–‡ä»¶ã€‚"""
    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return
    
    # è·å–è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    audio_files = []
    
    # å¤„ç† -i å‚æ•°æŒ‡å®šçš„æ–‡ä»¶
    if input_files:
        for file_path_str in input_files.split(","):
            file_path = Path(file_path_str.strip())
            if not file_path.exists():
                print(f"[bold red]é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}[/bold red]")
                raise typer.Exit(code=1)
            audio_files.append(file_path)
    else:
        # å¤„ç†ä½ç½®å‚æ•°ï¼ˆå‰©ä½™å‚æ•°ï¼‰
        remaining_args = ctx.args
        if remaining_args:
            for file_path_str in remaining_args:
                file_path = Path(file_path_str)
                if not file_path.exists():
                    print(f"[bold red]é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}[/bold red]")
                    raise typer.Exit(code=1)
                audio_files.append(file_path)
    
    # å¦‚æœæ²¡æœ‰æä¾›éŸ³é¢‘æ–‡ä»¶ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if not audio_files:
        print("[bold red]é”™è¯¯: è¯·æä¾›è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶[/bold red]")
        print("\nğŸ’¡ [bold blue]ä½¿ç”¨ç¤ºä¾‹:[/bold blue]")
        print("   transcribe audio.mp3 audio2.wav                    # ç›´æ¥è½¬å½•å¤šä¸ªæ–‡ä»¶")
        print("   transcribe -i audio.mp3,audio2.wav                 # ä½¿ç”¨ -i å‚æ•°")
        print("   transcribe *.mp3 --output-format all              # è½¬å½•æ‰€æœ‰mp3æ–‡ä»¶")
        print("   transcribe model list                             # æŸ¥çœ‹å·²ç¼“å­˜çš„æ¨¡å‹")
        raise typer.Exit(code=1)
    
    # è°ƒç”¨è½¬å½•åŠŸèƒ½
    _transcribe_files(
        audios=audio_files,
        model=model,
        output_dir=output_dir,
        output_format=output_format,
        output_template=output_template,
        timestamps=timestamps,
        chunk_duration=chunk_duration,
        overlap_duration=overlap_duration,
        verbose=verbose,
        fp32=fp32
    )


@app.command("model")
def model_cmd(
    ctx: typer.Context,
    action: str = typer.Argument(..., help="è¦æ‰§è¡Œçš„æ“ä½œ: list(åˆ—å‡ºå·²ç¼“å­˜æ¨¡å‹), info(æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯), download(é¢„ä¸‹è½½æ¨¡å‹), clean(æ¸…ç†ç¼“å­˜)"),
    model_id: Optional[str] = typer.Argument(None, help=f"æ¨¡å‹ID (downloadå’Œinfoæ“ä½œé»˜è®¤: {DEFAULT_TRANSCRIPTION_MODEL})")
):
    """è½¬å½•æ¨¡å‹ç®¡ç†å‘½ä»¤"""
    import os
    import shutil
    
    if action == "list":
        """åˆ—å‡ºå·²ç¼“å­˜çš„è½¬å½•æ¨¡å‹"""
        try:
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
            cache_dir = Path(cache_dir) / "hub"
            
            if not cache_dir.exists():
                console.print("[yellow]ğŸ“‚ è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•è½¬å½•æ¨¡å‹[/yellow]")
                return
            
            # æŸ¥æ‰¾æ¨¡å‹ç¼“å­˜ç›®å½•
            model_dirs = [d for d in cache_dir.iterdir() if d.is_dir() and d.name.startswith("models--")]
            
            if not model_dirs:
                console.print("[yellow]ğŸ“‚ è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•è½¬å½•æ¨¡å‹[/yellow]")
                return
            
            # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            table = Table(title="ğŸ¤ å·²ç¼“å­˜çš„è½¬å½•æ¨¡å‹åˆ—è¡¨")
            table.add_column("æ¨¡å‹ID", style="cyan")
            table.add_column("ç¼“å­˜å¤§å°", style="green")
            table.add_column("æœ€åä¿®æ”¹æ—¶é—´", style="dim")
            
            for model_dir in sorted(model_dirs):
                # è§£ææ¨¡å‹ID
                model_id = model_dir.name.replace("models--", "").replace("--", "/")
                
                # è®¡ç®—ç›®å½•å¤§å°
                total_size = sum(f.stat().st_size for f in model_dir.rglob('*') if f.is_file())
                size_mb = total_size / (1024 * 1024)
                
                # è·å–æœ€åä¿®æ”¹æ—¶é—´
                import datetime
                mtime = datetime.datetime.fromtimestamp(model_dir.stat().st_mtime)
                
                table.add_row(
                    model_id,
                    f"{size_mb:.1f} MB",
                    mtime.strftime("%Y-%m-%d %H:%M")
                )
            
            console.print(table)
            console.print(f"\nğŸ“ ç¼“å­˜ä½ç½®: [dim]{cache_dir}[/dim]")
            
        except Exception as e:
            console.print(f"[red]âŒ è·å–è½¬å½•æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}[/red]")
    
    elif action == "info":
        """æ˜¾ç¤ºæŒ‡å®šè½¬å½•æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = DEFAULT_TRANSCRIPTION_MODEL
            console.print(f"[dim]ä½¿ç”¨é»˜è®¤è½¬å½•æ¨¡å‹: {model_id}[/dim]")
        
        try:
            # å°è¯•æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜
            try:
                config_path, weight_path = _find_cached_model(model_id)
                console.print(f"âœ… [green]è½¬å½•æ¨¡å‹å·²ç¼“å­˜[/green]: [bold]{model_id}[/bold]")
                console.print(f"ğŸ“„ é…ç½®æ–‡ä»¶: [dim]{config_path}[/dim]")
                console.print(f"âš–ï¸  æƒé‡æ–‡ä»¶: [dim]{weight_path}[/dim]")
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                config_size = Path(config_path).stat().st_size / 1024
                weight_size = Path(weight_path).stat().st_size / (1024 * 1024)
                console.print(f"ğŸ“Š å¤§å°: é…ç½® {config_size:.1f} KB, æƒé‡ {weight_size:.1f} MB")
                
            except FileNotFoundError:
                console.print(f"[yellow]âš ï¸  è½¬å½•æ¨¡å‹æœªç¼“å­˜[/yellow]: [bold]{model_id}[/bold]")
                console.print("ğŸ’¡ ä½ å¯ä»¥ä½¿ç”¨ 'transcribe model download' å‘½ä»¤é¢„ä¸‹è½½æ¨¡å‹")
                
                # æ£€æŸ¥ç½‘ç»œè¿æ¥
                if _check_network_connectivity():
                    console.print("ğŸŒ ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œæ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½")
                else:
                    console.print("[red]ğŸŒ ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹[/red]")
                    
        except Exception as e:
            console.print(f"[red]âŒ è·å–è½¬å½•æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}[/red]")
    
    elif action == "download":
        """é¢„ä¸‹è½½æŒ‡å®šè½¬å½•æ¨¡å‹"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = DEFAULT_TRANSCRIPTION_MODEL
            console.print(f"[dim]ä½¿ç”¨é»˜è®¤è½¬å½•æ¨¡å‹: {model_id}[/dim]")
        
        try:
            console.print(f"ğŸš€ å¼€å§‹é¢„ä¸‹è½½è½¬å½•æ¨¡å‹: [bold]{model_id}[/bold]")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ç¼“å­˜
            try:
                _find_cached_model(model_id)
                console.print(f"âœ… [green]è½¬å½•æ¨¡å‹å·²å­˜åœ¨äºæœ¬åœ°ç¼“å­˜[/green]")
                return
            except FileNotFoundError:
                pass
            
            # ä¸‹è½½æ¨¡å‹
            model = from_pretrained(model_id, show_progress=True)
            console.print(f"\nğŸ‰ [bold green]è½¬å½•æ¨¡å‹é¢„ä¸‹è½½å®Œæˆ![/bold green]")
            console.print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜ï¼Œåç»­ä½¿ç”¨æ—¶å°†ç›´æ¥åŠ è½½")
            
        except Exception as e:
            console.print(f"[red]âŒ è½¬å½•æ¨¡å‹ä¸‹è½½å¤±è´¥: {str(e)}[/red]")
    
    elif action == "clean":
        """æ¸…ç†è½¬å½•æ¨¡å‹ç¼“å­˜"""
        try:
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
            cache_dir = Path(cache_dir) / "hub"
            
            if not cache_dir.exists():
                console.print("[yellow]ğŸ“‚ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†[/yellow]")
                return
            
            # è®¡ç®—ç¼“å­˜å¤§å°
            total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())
            size_mb = total_size / (1024 * 1024)
            
            # è¯¢é—®ç¡®è®¤
            if size_mb > 0:
                console.print(f"âš ï¸  [yellow]å³å°†æ¸…ç† {size_mb:.1f} MB çš„è½¬å½•æ¨¡å‹ç¼“å­˜[/yellow]")
                console.print(f"ğŸ“ ç¼“å­˜ä½ç½®: [dim]{cache_dir}[/dim]")
                
                confirm = typer.confirm("ç¡®å®šè¦æ¸…ç†æ‰€æœ‰è½¬å½•æ¨¡å‹ç¼“å­˜å—ï¼Ÿ")
                if not confirm:
                    console.print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return
                
                # æ¸…ç†ç¼“å­˜
                shutil.rmtree(cache_dir)
                console.print("âœ… [green]è½¬å½•æ¨¡å‹ç¼“å­˜æ¸…ç†å®Œæˆ[/green]")
            else:
                console.print("[yellow]ğŸ“‚ ç¼“å­˜ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†[/yellow]")
                
        except Exception as e:
            console.print(f"[red]âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}[/red]")
    
    else:
        console.print(f"[red]âŒ æœªçŸ¥æ“ä½œ: {action}[/red]")
        console.print("ğŸ’¡ æ”¯æŒçš„æ“ä½œ: list, info, download, clean")
        console.print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        console.print("   transcribe model list                                    # åˆ—å‡ºå·²ç¼“å­˜è½¬å½•æ¨¡å‹")
        console.print("   transcribe model info                                    # æ˜¾ç¤ºé»˜è®¤è½¬å½•æ¨¡å‹ä¿¡æ¯")
        console.print("   transcribe model info mlx-community/parakeet-tdt-0.6b-v2  # æ˜¾ç¤ºæŒ‡å®šè½¬å½•æ¨¡å‹ä¿¡æ¯")
        console.print("   transcribe model download                                      # é¢„ä¸‹è½½é»˜è®¤è½¬å½•æ¨¡å‹")
        console.print("   transcribe model download mlx-community/parakeet-tdt-0.6b-v2  # é¢„ä¸‹è½½æŒ‡å®šè½¬å½•æ¨¡å‹")
        console.print("   transcribe model clean                                   # æ¸…ç†ç¼“å­˜")


if __name__ == "__main__":
    app()