import datetime
import json
import os
import time
import glob
import re
from pathlib import Path
from typing import Any, Dict, List, Optional

import typer
from mlx.core import bfloat16, float32
from rich import print
from rich.console import Console

# æŠ‘åˆ¶ macOS MallocStackLogging è­¦å‘Šï¼ˆæ— å®³çš„ç³»ç»Ÿæ¶ˆæ¯ï¼‰
os.environ.setdefault('MallocStackLogging', '0')
from rich.progress import (
    BarColumn,
    Progress,
    SpinnerColumn,
    TextColumn,
    TimeElapsedColumn,
)
from rich.table import Table
from typing_extensions import Annotated

from ..logger import get_log_file_path, get_log_mode_info, setup_logger
from . import AlignedResult, AlignedSentence, AlignedToken, from_pretrained
from .utils import _find_cached_model, _check_network_connectivity, _storage_optimizer
from .model_cache import model_context, get_cache_info, clear_model_cache

# é»˜è®¤è½¬å½•æ¨¡å‹
DEFAULT_TRANSCRIPTION_MODEL = "mlx-community/parakeet-tdt-0.6b-v2"

# åˆå§‹åŒ–æ§åˆ¶å°
console = Console()

# helpers
def format_timestamp(
    seconds: float, always_include_hours: bool = True, decimal_marker: str = ","
) -> str:
    assert seconds >= 0
    milliseconds = round(seconds * 1000.0)

    hours = milliseconds // 3_600_000
    milliseconds %= 3_600_000

    minutes = milliseconds // 60_000
    milliseconds %= 60_000

    seconds = milliseconds // 1_000
    milliseconds %= 1_000

    hours_marker = f"{hours:02d}:" if always_include_hours or hours > 0 else ""
    return (
        f"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}"
    )


def to_txt(result: AlignedResult) -> str:
    """Format transcription result as plain text."""
    return result.text.strip()


def to_srt(result: AlignedResult, timestamps: bool = False) -> str:
    """
    Format transcription result as an SRT file.
    """
    srt_content = []
    entry_index = 1
    if timestamps:
        words = result.words
        for word in words:
            if not word.text.strip():
                continue
            start_time = format_timestamp(word.start, decimal_marker=",")
            end_time = format_timestamp(word.end, decimal_marker=",")
            text = word.text.strip()

            srt_content.append(f"{entry_index}")
            srt_content.append(f"{start_time} --> {end_time}")
            srt_content.append(text)
            srt_content.append("")
            entry_index += 1
    else:
        for sentence in result.sentences:
            start_time = format_timestamp(sentence.start, decimal_marker=",")
            end_time = format_timestamp(sentence.end, decimal_marker=",")
            text = sentence.text.strip()

            srt_content.append(f"{entry_index}")
            srt_content.append(f"{start_time} --> {end_time}")
            srt_content.append(text)
            srt_content.append("")
            entry_index += 1

    return "\n".join(srt_content)


def to_vtt(result: AlignedResult, timestamps: bool = False) -> str:
    """
    Format transcription result as a VTT file.
    """
    vtt_content = ["WEBVTT", ""]
    if timestamps:
        words = result.words
        for word in words:
            if not word.text.strip():
                continue
            start_time = format_timestamp(word.start, decimal_marker=".")
            end_time = format_timestamp(word.end, decimal_marker=".")
            text = word.text.strip()

            vtt_content.append(f"{start_time} --> {end_time}")
            vtt_content.append(text)
            vtt_content.append("")
    else:
        for sentence in result.sentences:
            start_time = format_timestamp(sentence.start, decimal_marker=".")
            end_time = format_timestamp(sentence.end, decimal_marker=".")
            text_line = sentence.text.strip()

            vtt_content.append(f"{start_time} --> {end_time}")
            vtt_content.append(text_line)
            vtt_content.append("")

    return "\n".join(vtt_content)


def _aligned_token_to_dict(token: AlignedToken) -> Dict[str, Any]:
    return {
        "text": token.text,
        "start": round(token.start, 3),
        "end": round(token.end, 3),
        "duration": round(token.duration, 3),
    }


def _aligned_sentence_to_dict(sentence: AlignedSentence) -> Dict[str, Any]:
    return {
        "text": sentence.text,
        "start": round(sentence.start, 3),
        "end": round(sentence.end, 3),
        "duration": round(sentence.duration, 3),
        "tokens": [_aligned_token_to_dict(token) for token in sentence.tokens],
    }


def to_json(result: AlignedResult) -> str:
    output_dict = {
        "text": result.text,
        "sentences": [
            _aligned_sentence_to_dict(sentence) for sentence in result.sentences
        ],
    }
    return json.dumps(output_dict, indent=2, ensure_ascii=False)


app = typer.Typer(
    help="ä½¿ç”¨ Parakeet MLX æ¨¡å‹è¿›è¡ŒéŸ³é¢‘è½¬å½•çš„å‘½ä»¤è¡Œå·¥å…·",
    epilog="ğŸ’¡ é¦–æ¬¡ä½¿ç”¨å‰å¯ä»¥è¿è¡Œ: transcribe model download <model_id> æ¥é¢„ä¸‹è½½æ¨¡å‹"
)


@app.callback(invoke_without_command=True)
def main(
    ctx: typer.Context,
    audios: Annotated[
        Optional[List[Path]],
        typer.Argument(
            help="è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶",
            exists=True,
            file_okay=True,
            dir_okay=False,
            readable=True,
        ),
    ] = None,
    model: Annotated[
        str, typer.Option(help="è¦ä½¿ç”¨çš„ Hugging Face æ¨¡å‹ä»“åº“")
    ] = "mlx-community/parakeet-tdt-0.6b-v2",
    output_dir: Annotated[
        Path, typer.Option(help="ä¿å­˜è½¬å½•ç»“æœçš„ç›®å½•")
    ] = Path("."),
    output_format: Annotated[
        str, typer.Option(help="è¾“å‡ºæ–‡ä»¶æ ¼å¼ (txt, srt, vtt, json, all)")
    ] = "srt",
    output_template: Annotated[
        str,
        typer.Option(
            help="è¾“å‡ºæ–‡ä»¶åæ¨¡æ¿ï¼Œä¾‹å¦‚ '{filename}_{date}_{index}'"
        ),
    ] = "{filename}",
    timestamps: Annotated[
        bool,
        typer.Option(help="åœ¨ srt/vtt æ ¼å¼ä¸­è¾“å‡ºè¯çº§æ—¶é—´æˆ³"),
    ] = True,
    chunk_duration: Annotated[
        float,
        typer.Option(
            help="é•¿éŸ³é¢‘çš„åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ0 ç¦ç”¨åˆ†å—ï¼Œ-1 æ™ºèƒ½åˆ†å—ï¼ˆæ¨èï¼‰ã€‚æ³¨æ„ï¼šå½“è®¾ä¸ºæ­£æ•°æ—¶ï¼Œå°†ä½¿ç”¨å›ºå®šåˆ†å—è€Œé VAD æ™ºèƒ½åˆ†å—ã€‚"
        ),
    ] = -1,  # æ™ºèƒ½åˆ†å—ï¼šæ ¹æ®ç³»ç»Ÿæ€§èƒ½è‡ªåŠ¨ä¼˜åŒ–
    overlap_duration: Annotated[
        float, typer.Option(help="ä½¿ç”¨åˆ†å—æ—¶çš„é‡å æ—¶é•¿ï¼ˆç§’ï¼‰")
    ] = 30,  # ä¼˜åŒ–ï¼šå¢åŠ åˆ°30ç§’é‡å ï¼Œæé«˜åˆå¹¶æˆåŠŸç‡
    use_vad: Annotated[
        bool,
        typer.Option(
            "--vad/--no-vad",
            help="ä½¿ç”¨ VAD æ™ºèƒ½åˆ†å—ï¼Œåœ¨é™éŸ³å¤„åˆ†å‰²éŸ³é¢‘ï¼ˆæ¨èï¼‰ã€‚ä»…åœ¨ chunk_duration ä¸ºè´Ÿæ•°æ—¶å¯ç”¨ã€‚"
        ),
    ] = True,
    verbose: Annotated[
        bool,
        typer.Option("--verbose", "-v", help="æ‰“å°è¯¦ç»†çš„å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯"),
    ] = False,
    fp32: Annotated[
        bool, typer.Option("--fp32/--bf16", help="ä½¿ç”¨ FP32 ç²¾åº¦")
    ] = False,
):
    """
    ä½¿ç”¨ Parakeet MLX æ¨¡å‹è½¬å½•éŸ³é¢‘æ–‡ä»¶ã€‚
    """
    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return
    
    # æ˜¾ç¤ºæ—¥å¿—æ–‡ä»¶è·¯å¾„ä¿¡æ¯
    log_mode, log_location = get_log_mode_info()
    log_path = get_log_file_path()
    print(f"ğŸ“ [dim]æ—¥å¿—æ¨¡å¼: {log_mode} ({log_location})[/dim]")
    print(f"ğŸ“ [dim]æ—¥å¿—æ–‡ä»¶: {log_path}[/dim]")
    print()  # ç©ºè¡Œåˆ†éš”
    
    # å¦‚æœæ²¡æœ‰æä¾›éŸ³é¢‘æ–‡ä»¶ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if not audios:
        print("[bold red]é”™è¯¯: è¯·æä¾›è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶[/bold red]")
        print("\nğŸ’¡ [bold blue]ä½¿ç”¨ç¤ºä¾‹:[/bold blue]")
        print("   transcribe audio.mp3 audio2.wav                    # è½¬å½•å¤šä¸ªæ–‡ä»¶")
        print("   transcribe *.mp3 --output-format all              # è½¬å½•æ‰€æœ‰mp3æ–‡ä»¶ä¸ºæ‰€æœ‰æ ¼å¼")
        print("   transcribe audio.wav --model other-model          # ä½¿ç”¨æŒ‡å®šæ¨¡å‹")
        print("   transcribe model list                             # æŸ¥çœ‹å·²ç¼“å­˜çš„æ¨¡å‹")
        raise typer.Exit(code=1)
    
    _transcribe_files(
        audios=audios,
        model=model,
        output_dir=output_dir,
        output_format=output_format,
        output_template=output_template,
        timestamps=timestamps,
        chunk_duration=chunk_duration,
        overlap_duration=overlap_duration,
        use_vad=use_vad,
        verbose=verbose,
        fp32=fp32
    )


def _transcribe_files(
    audios: List[Path],
    model: str,
    output_dir: Path,
    output_format: str,
    output_template: str,
    timestamps: bool,
    chunk_duration: float,
    overlap_duration: float,
    use_vad: bool,
    verbose: bool,
    fp32: bool
):
    """æ‰§è¡ŒéŸ³é¢‘è½¬å½•çš„æ ¸å¿ƒé€»è¾‘"""
    # è®¾ç½®æ—¥å¿—è®°å½•å™¨
    logger = setup_logger(__name__)

    # ä¸å†åœ¨è¿™é‡Œç«‹å³åŠ è½½æ¨¡å‹ï¼Œè€Œæ˜¯å»¶è¿Ÿåˆ°å®é™…è½¬å½•æ—¶åŠ è½½
    if verbose:
        print(f"å‡†å¤‡ä½¿ç”¨æ¨¡å‹: [bold cyan]{model}[/bold cyan]")
        print("ğŸš€ [dim]æ¨¡å‹å°†åœ¨å¼€å§‹è½¬å½•æ—¶åŠ è½½ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†ä¼˜åŒ–[/dim]")

    try:
        output_dir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        print(f"[bold red]åˆ›å»ºè¾“å‡ºç›®å½• {output_dir} æ—¶å‡ºé”™:[/bold red] {e}")
        raise typer.Exit(code=1)

    if verbose:
        print(f"è¾“å‡ºç›®å½•: [bold cyan]{output_dir.resolve()}[/bold cyan]")
        print(f"è¾“å‡ºæ ¼å¼: [bold cyan]{output_format}[/bold cyan]")
        if output_format in ["srt", "vtt", "all"] and timestamps:
            print("æ—¶é—´æˆ³: [bold cyan]å·²å¯ç”¨[/bold cyan]")

    formatters = {
        "txt": to_txt,
        "srt": lambda r: to_srt(r, timestamps=timestamps),
        "vtt": lambda r: to_vtt(r, timestamps=timestamps),
        "json": to_json,
    }

    formats_to_generate = []
    if output_format == "all":
        formats_to_generate = list(formatters.keys())
    elif output_format in formatters:
        formats_to_generate = [output_format]
    else:
        print(
            f"[bold red]é”™è¯¯: æ— æ•ˆçš„è¾“å‡ºæ ¼å¼ '{output_format}'ã€‚è¯·ä» {list(formatters.keys()) + ['all']} ä¸­é€‰æ‹©ã€‚[/bold red]"
        )
        raise typer.Exit(code=1)

    total_files = len(audios)
    if verbose:
        print(f"æ­£åœ¨è½¬å½• {total_files} ä¸ªæ–‡ä»¶...")

    # ä½¿ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼çš„æ¨¡å‹ç¼“å­˜ç®¡ç†
    batch_mode = total_files > 1
    
    with model_context(batch_mode=batch_mode):
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeElapsedColumn(),
            transient=True,
        ) as progress:
            task = progress.add_task("æ­£åœ¨è½¬å½•...", total=total_files)
            loaded_model = None  # å»¶è¿Ÿåˆå§‹åŒ–
            
            for i, audio_path in enumerate(audios):
                if verbose:
                    print(
                        f"\næ­£åœ¨å¤„ç†æ–‡ä»¶ {i + 1}/{total_files}: [bold cyan]{audio_path.name}[/bold cyan]"
                    )
                else:
                    progress.update(
                        task, description=f"æ­£åœ¨å¤„ç† [cyan]{audio_path.name}[/cyan]..."
                    )

                try:
                    # æ‡’åŠ è½½æ¨¡å‹ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡éœ€è¦æ—¶åŠ è½½ï¼Œåç»­å¤ç”¨ç¼“å­˜ï¼‰
                    if loaded_model is None:
                        if verbose:
                            print(f"ğŸ¤– [bold blue]æ­£åœ¨åŠ è½½æ¨¡å‹...[/bold blue] [cyan]{model}[/cyan]")

                        loaded_model, from_cache = from_pretrained(
                            model,
                            dtype=bfloat16 if not fp32 else float32,
                            show_progress=verbose,
                            use_cache=True,  # å¯ç”¨ç¼“å­˜
                            return_cache_info=True  # è¿”å›ç¼“å­˜ä¿¡æ¯
                        )

                        # åªæœ‰å½“æ¨¡å‹ä¸æ˜¯ä»ç¼“å­˜åŠ è½½æ—¶æ‰æ˜¾ç¤ºåŠ è½½å®Œæˆä¿¡æ¯
                        if verbose and not from_cache:
                            if batch_mode:
                                print("âœ… [green]æ¨¡å‹åŠ è½½å®Œæˆï¼Œæ‰¹é‡å¤„ç†æ¨¡å¼å·²å¯ç”¨[/green]")
                            else:
                                print("âœ… [green]æ¨¡å‹åŠ è½½å®Œæˆ[/green]")

                    # è®°å½•è½¬å½•å¼€å§‹æ—¶é—´
                    transcribe_start_time = time.time()

                    result: AlignedResult = loaded_model.transcribe(
                        audio_path,
                        dtype=bfloat16 if not fp32 else float32,
                        chunk_duration=chunk_duration if chunk_duration != 0 else None,
                        overlap_duration=overlap_duration,
                        use_vad=use_vad,
                        chunk_callback=lambda current, full: progress.update(
                            task, total=total_files * full, completed=full * i + current
                        ),
                    )

                    # è®¡ç®—è½¬å½•è€—æ—¶
                    transcribe_elapsed = time.time() - transcribe_start_time

                    if verbose:
                        for sentence in result.sentences:
                            start, end, text = sentence.start, sentence.end, sentence.text
                            line = f"[blue][{format_timestamp(start)} --> {format_timestamp(end)}][/blue] {text.strip()}"
                            print(line)

                    # ç»Ÿè®¡å­—å¹•æ•°é‡å¹¶æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
                    sentence_count = len(result.sentences)
                    logger.info(f"â±ï¸  è½¬å½•è€—æ—¶: {transcribe_elapsed:.1f}ç§’")
                    if not verbose:
                        print(f"âœ… [bold green]è½¬å½•å®Œæˆ[/bold green] (å…± [cyan]{sentence_count}[/cyan] æ¡å­—å¹•) - è€—æ—¶: [cyan]{transcribe_elapsed:.1f}ç§’[/cyan]")

                    base_filename = audio_path.stem
                    template_vars = {
                        "filename": base_filename,
                        "date": datetime.datetime.now().strftime("%Y%m%d"),
                        "index": str(i + 1),
                    }

                    output_basename = output_template.format(**template_vars)

                    for fmt in formats_to_generate:
                        formatter = formatters[fmt]
                        output_content = formatter(result)
                        
                        # å¯¹äºSRTæ ¼å¼ï¼Œæ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
                        if fmt == "srt":
                            srt_content_trimmed = output_content.strip()
                            if not srt_content_trimmed:
                                print(f"[yellow]âš ï¸  æœªæ£€æµ‹åˆ°è¯­éŸ³å†…å®¹ï¼Œè·³è¿‡ä¿å­˜ {fmt.upper()} æ–‡ä»¶[/yellow]")
                                continue
                            
                            # æ£€æŸ¥æ˜¯å¦åªåŒ…å«ç©ºçš„æ—¶é—´æˆ³æ¡ç›®ï¼ˆæ²¡æœ‰å®é™…æ–‡æœ¬å†…å®¹ï¼‰
                            import re
                            # ç§»é™¤åºå·å’Œæ—¶é—´æˆ³è¡Œï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰å®é™…å†…å®¹
                            lines = srt_content_trimmed.split('\n')
                            content_lines = []
                            for line in lines:
                                line = line.strip()
                                # è·³è¿‡åºå·è¡Œ
                                if line.isdigit():
                                    continue
                                # è·³è¿‡æ—¶é—´æˆ³è¡Œ
                                if re.match(r'\d{2}:\d{2}:\d{2}[,\.]\d{3}\s*-->\s*\d{2}:\d{2}:\d{2}[,\.]\d{3}', line):
                                    continue
                                # è·³è¿‡ç©ºè¡Œ
                                if not line:
                                    continue
                                content_lines.append(line)
                            
                            if not content_lines:
                                print(f"[yellow]âš ï¸  è½¬å½•ç»“æœä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜ {fmt.upper()} æ–‡ä»¶[/yellow]")
                                continue
                        
                        output_filename = f"{output_basename}.{fmt}"
                        output_filepath = output_dir / output_filename

                        try:
                            with open(output_filepath, "w", encoding="utf-8") as f:
                                f.write(output_content)
                            if verbose:
                                print(
                                    f"[green]å·²ä¿å­˜ {fmt.upper()}:[/green] {output_filepath.absolute()}"
                                )
                        except Exception as e:
                            print(
                                f"[bold red]å†™å…¥è¾“å‡ºæ–‡ä»¶ {output_filepath} æ—¶å‡ºé”™:[/bold red] {e}"
                            )

                except Exception as e:
                    # åŒºåˆ†æ¨¡å‹åŠ è½½é”™è¯¯å’Œè½¬å½•é”™è¯¯
                    if loaded_model is None:
                        print(f"[bold red]åŠ è½½æ¨¡å‹ {model} æ—¶å‡ºé”™:[/bold red] {e}")
                        # æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢æ•´ä¸ªæ‰¹æ¬¡
                        raise typer.Exit(code=1)
                    else:
                        print(f"[bold red]è½¬å½•æ–‡ä»¶ {audio_path} æ—¶å‡ºé”™:[/bold red] {e}")
                        # å•ä¸ªæ–‡ä»¶è½¬å½•å¤±è´¥ï¼Œç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶

                progress.update(task, total=total_files, completed=i + 1)

        # æ‰¹é‡å¤„ç†å®Œæˆåï¼Œæ¨¡å‹ç¼“å­˜å°†è‡ªåŠ¨é‡Šæ”¾
        if verbose and batch_mode:
            print("ğŸ¯ [dim]æ‰¹é‡å¤„ç†å®Œæˆï¼Œæ¨¡å‹ç¼“å­˜å·²è‡ªåŠ¨é‡Šæ”¾[/dim]")

    print(
        f"\n[bold green]è½¬å½•å®Œæˆã€‚[/bold green] è¾“å‡ºå·²ä¿å­˜åœ¨ '{output_dir.resolve()}'"
    )


app = typer.Typer(
    help="ä½¿ç”¨ Parakeet MLX æ¨¡å‹è¿›è¡ŒéŸ³é¢‘è½¬å½•çš„å‘½ä»¤è¡Œå·¥å…·",
    epilog="ğŸ’¡ é¦–æ¬¡ä½¿ç”¨å‰å¯ä»¥è¿è¡Œ: transcribe model download <model_id> æ¥é¢„ä¸‹è½½æ¨¡å‹"
)


@app.callback(invoke_without_command=True)
def main_callback(
    ctx: typer.Context,
    input_files: Annotated[
        Optional[str],
        typer.Option(
            "--input-files", "-i",
            help="è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆç”¨é€—å·åˆ†éš”å¤šä¸ªæ–‡ä»¶ï¼‰ï¼Œå¦‚ä¸æŒ‡å®šåˆ™ä½¿ç”¨ä½ç½®å‚æ•°"
        )
    ] = None,
    model: Annotated[
        str, typer.Option(help="è¦ä½¿ç”¨çš„ Hugging Face æ¨¡å‹ä»“åº“")
    ] = "mlx-community/parakeet-tdt-0.6b-v2",
    output_dir: Annotated[
        Path, typer.Option(help="ä¿å­˜è½¬å½•ç»“æœçš„ç›®å½•")
    ] = Path("."),
    output_format: Annotated[
        str, typer.Option(help="è¾“å‡ºæ–‡ä»¶æ ¼å¼ (txt, srt, vtt, json, all)")
    ] = "srt",
    output_template: Annotated[
        str,
        typer.Option(
            help="è¾“å‡ºæ–‡ä»¶åæ¨¡æ¿ï¼Œä¾‹å¦‚ '{filename}_{date}_{index}'"
        ),
    ] = "{filename}",
    timestamps: Annotated[
        bool,
        typer.Option(help="åœ¨ srt/vtt æ ¼å¼ä¸­è¾“å‡ºè¯çº§æ—¶é—´æˆ³"),
    ] = True,
    chunk_duration: Annotated[
        float,
        typer.Option(
            help="é•¿éŸ³é¢‘çš„åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ0 ç¦ç”¨åˆ†å—ï¼Œ-1 æ™ºèƒ½åˆ†å—ï¼ˆæ¨èï¼‰ã€‚æ³¨æ„ï¼šå½“è®¾ä¸ºæ­£æ•°æ—¶ï¼Œå°†ä½¿ç”¨å›ºå®šåˆ†å—è€Œé VAD æ™ºèƒ½åˆ†å—ã€‚"
        ),
    ] = -1,  # æ™ºèƒ½åˆ†å—ï¼šæ ¹æ®ç³»ç»Ÿæ€§èƒ½è‡ªåŠ¨ä¼˜åŒ–
    overlap_duration: Annotated[
        float, typer.Option(help="ä½¿ç”¨åˆ†å—æ—¶çš„é‡å æ—¶é•¿ï¼ˆç§’ï¼‰")
    ] = 30,  # ä¼˜åŒ–ï¼šå¢åŠ åˆ°30ç§’é‡å ï¼Œæé«˜åˆå¹¶æˆåŠŸç‡
    use_vad: Annotated[
        bool,
        typer.Option(
            "--vad/--no-vad",
            help="ä½¿ç”¨ VAD æ™ºèƒ½åˆ†å—ï¼Œåœ¨é™éŸ³å¤„åˆ†å‰²éŸ³é¢‘ï¼ˆæ¨èï¼‰ã€‚ä»…åœ¨ chunk_duration ä¸ºè´Ÿæ•°æ—¶å¯ç”¨ã€‚"
        ),
    ] = True,
    verbose: Annotated[
        bool,
        typer.Option("--verbose", "-v", help="æ‰“å°è¯¦ç»†çš„å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯"),
    ] = False,
    fp32: Annotated[
        bool, typer.Option("--fp32/--bf16", help="ä½¿ç”¨ FP32 ç²¾åº¦")
    ] = False,
    version: Annotated[
        bool, typer.Option("--version", help="æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯å¹¶é€€å‡º")
    ] = False,
):
    """ä½¿ç”¨ Parakeet MLX æ¨¡å‹è½¬å½•éŸ³é¢‘æ–‡ä»¶ã€‚"""
    # å¤„ç†ç‰ˆæœ¬ä¿¡æ¯è¯·æ±‚
    if version:
        from ..version_utils import get_simple_version_info
        print(get_simple_version_info())
        raise typer.Exit()
    
    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return
    
    # è·å–è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    audio_files = []
    
    # å¤„ç† -i å‚æ•°æŒ‡å®šçš„æ–‡ä»¶
    if input_files:
        for file_path_str in input_files.split(","):
            file_path = Path(file_path_str.strip())
            if not file_path.exists():
                print(f"[bold red]é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}[/bold red]")
                raise typer.Exit(code=1)
            audio_files.append(file_path)
    else:
        # å¤„ç†ä½ç½®å‚æ•°ï¼ˆå‰©ä½™å‚æ•°ï¼‰
        remaining_args = ctx.args
        if remaining_args:
            for file_path_str in remaining_args:
                file_path = Path(file_path_str)
                if not file_path.exists():
                    print(f"[bold red]é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}[/bold red]")
                    raise typer.Exit(code=1)
                audio_files.append(file_path)
    
    # å¦‚æœæ²¡æœ‰æä¾›éŸ³é¢‘æ–‡ä»¶ï¼Œå°è¯•æ‰«æå½“å‰ç›®å½•
    if not audio_files:
        print("[dim]æœªæŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼Œæ‰«æå½“å‰ç›®å½•...[/dim]")
        try:
            audio_files = _scan_media_files(Path.cwd())
        except typer.Exit as e:
            # å¦‚æœæ‰«æä¹Ÿæ²¡æ‰¾åˆ°æ–‡ä»¶ï¼Œä¼šæŠ›å‡ºExitå¼‚å¸¸
            raise e

    # å¦‚æœä»ç„¶æ²¡æœ‰éŸ³é¢‘æ–‡ä»¶ï¼ˆç†è®ºä¸Š_scan_media_filesä¼šå¤„ç†è¿™ç§æƒ…å†µï¼Œä½†ä¸ºäº†ä¿é™©èµ·è§ï¼‰
    if not audio_files:
        print("[bold red]é”™è¯¯: è¯·æä¾›è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶[/bold red]")
        print("\nğŸ’¡ [bold blue]ä½¿ç”¨ç¤ºä¾‹:[/bold blue]")
        print("   transcribe audio.mp3 audio2.wav                    # ç›´æ¥è½¬å½•å¤šä¸ªæ–‡ä»¶")
        print("   transcribe -i audio.mp3,audio2.wav                 # ä½¿ç”¨ -i å‚æ•°")
        print("   transcribe *.mp3 --output-format all              # è½¬å½•æ‰€æœ‰mp3æ–‡ä»¶")
        print("   transcribe model list                             # æŸ¥çœ‹å·²ç¼“å­˜çš„æ¨¡å‹")
        raise typer.Exit(code=1)
    
    # è°ƒç”¨è½¬å½•åŠŸèƒ½
    _transcribe_files(
        audios=audio_files,
        model=model,
        output_dir=output_dir,
        output_format=output_format,
        output_template=output_template,
        timestamps=timestamps,
        chunk_duration=chunk_duration,
        overlap_duration=overlap_duration,
        use_vad=use_vad,
        verbose=verbose,
        fp32=fp32
    )

def _scan_media_files(input_dir: Path) -> List[Path]:
    """æ‰«æç›®å½•ä¸‹çš„åª’ä½“æ–‡ä»¶ï¼Œæ’é™¤å·²æœ‰å­—å¹•çš„æ–‡ä»¶"""
    # åª’ä½“æ–‡ä»¶æ‰©å±•å
    MEDIA_EXTENSIONS = [
        # éŸ³é¢‘æ ¼å¼
        "*.mp3", "*.m4a", "*.wav", "*.flac", "*.aac",
        "*.ogg", "*.wma", "*.aiff", "*.opus",
        # è§†é¢‘æ ¼å¼
        "*.mp4", "*.avi", "*.mov", "*.mkv", "*.webm",
        "*.flv", "*.wmv", "*.m4v", "*.mpeg", "*.mpg",
        "*.3gp", "*.ts"
    ]

    # ç¡®ä¿input_diræ˜¯ç»å¯¹è·¯å¾„
    input_dir = input_dir.resolve()

    # æŸ¥æ‰¾æ‰€æœ‰åª’ä½“æ–‡ä»¶
    media_files = []
    for pattern in MEDIA_EXTENSIONS:
        media_files.extend(glob.glob(str(input_dir / pattern)))
    
    if not media_files:
        print(f"[bold red]{input_dir} ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„åª’ä½“æ–‡ä»¶ã€‚[/bold red]")
        raise typer.Exit(code=1)
    
    # è¿‡æ»¤æ‰å·²æœ‰å­—å¹•çš„æ–‡ä»¶
    files_to_process = []
    
    # æå–åŸºç¡€æ–‡ä»¶åå¹¶å»é‡æ’åº
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¿ç•™åŸå§‹æ–‡ä»¶è·¯å¾„ï¼Œæ‰€ä»¥ä¸èƒ½åƒtranslateé‚£æ ·åªå­˜basename
    # æˆ‘ä»¬ç”¨basenameæ¥æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„subtitleæ–‡ä»¶
    
    # æ’åºæ–‡ä»¶åˆ—è¡¨
    media_files.sort()
    
    for file_path in media_files:
        file = Path(file_path)
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯¹åº”çš„å­—å¹•æ–‡ä»¶ (.srt æˆ– .ass)
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªæ£€æŸ¥åŒåä¸åŒåç¼€çš„æƒ…å†µ
        # translateå‘½ä»¤ä¸­çš„é€»è¾‘æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œå…ˆåšæœ€åŸºç¡€çš„æ£€æŸ¥
        has_subtitle = False
        for sub_ext in ['.srt', '.ass', '.vtt']:
            if (file.parent / (file.stem + sub_ext)).exists():
                has_subtitle = True
                break
        
        if not has_subtitle:
            files_to_process.append(file)
    
    if not files_to_process:
        print("[bold yellow]ç›®å½•ä¸‹æ‰€æœ‰åª’ä½“æ–‡ä»¶å‡å·²æœ‰å­—å¹•ï¼Œæ²¡æœ‰éœ€è¦å¤„ç†çš„æ–°æ–‡ä»¶ã€‚[/bold yellow]")
        raise typer.Exit(code=0)
        
    print(f"[bold green]å‘ç° {len(files_to_process)} ä¸ªå¾…è½¬å½•æ–‡ä»¶ï¼š[/bold green]")
    for f in files_to_process[:5]:
        print(f"  - {f.name}")
    if len(files_to_process) > 5:
        print(f"  ... ç­‰å…± {len(files_to_process)} ä¸ªæ–‡ä»¶")
    print()
        
    return files_to_process


@app.command("model")
def model_cmd(
    ctx: typer.Context,
    action: str = typer.Argument(..., help="è¦æ‰§è¡Œçš„æ“ä½œ: list(åˆ—å‡ºå·²ç¼“å­˜æ¨¡å‹), info(æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯), download(é¢„ä¸‹è½½æ¨¡å‹), clean(æ¸…ç†ç¼“å­˜)"),
    model_id: Optional[str] = typer.Argument(None, help=f"æ¨¡å‹ID (downloadå’Œinfoæ“ä½œé»˜è®¤: {DEFAULT_TRANSCRIPTION_MODEL})")
):
    """è½¬å½•æ¨¡å‹ç®¡ç†å‘½ä»¤"""
    import os
    import shutil
    
    if action == "list":
        """åˆ—å‡ºå·²ç¼“å­˜çš„è½¬å½•æ¨¡å‹"""
        try:
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
            cache_dir = Path(cache_dir) / "hub"
            
            if not cache_dir.exists():
                console.print("[yellow]ğŸ“‚ è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•è½¬å½•æ¨¡å‹[/yellow]")
                return
            
            # æŸ¥æ‰¾æ¨¡å‹ç¼“å­˜ç›®å½•
            model_dirs = [d for d in cache_dir.iterdir() if d.is_dir() and d.name.startswith("models--")]
            
            if not model_dirs:
                console.print("[yellow]ğŸ“‚ è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•è½¬å½•æ¨¡å‹[/yellow]")
                return
            
            # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            table = Table(title="ğŸ¤ å·²ç¼“å­˜çš„è½¬å½•æ¨¡å‹åˆ—è¡¨")
            table.add_column("æ¨¡å‹ID", style="cyan")
            table.add_column("ç¼“å­˜å¤§å°", style="green")
            table.add_column("æœ€åä¿®æ”¹æ—¶é—´", style="dim")
            
            for model_dir in sorted(model_dirs):
                # è§£ææ¨¡å‹ID
                model_id = model_dir.name.replace("models--", "").replace("--", "/")
                
                # è®¡ç®—ç›®å½•å¤§å°
                total_size = sum(f.stat().st_size for f in model_dir.rglob('*') if f.is_file())
                size_mb = total_size / (1024 * 1024)
                
                # è·å–æœ€åä¿®æ”¹æ—¶é—´
                import datetime
                mtime = datetime.datetime.fromtimestamp(model_dir.stat().st_mtime)
                
                table.add_row(
                    model_id,
                    f"{size_mb:.1f} MB",
                    mtime.strftime("%Y-%m-%d %H:%M")
                )
            
            console.print(table)
            console.print(f"\nğŸ“ ç¼“å­˜ä½ç½®: [dim]{cache_dir}[/dim]")
            
        except Exception as e:
            console.print(f"[red]âŒ è·å–è½¬å½•æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}[/red]")
    
    elif action == "info":
        """æ˜¾ç¤ºæŒ‡å®šè½¬å½•æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = DEFAULT_TRANSCRIPTION_MODEL
            console.print(f"[dim]ä½¿ç”¨é»˜è®¤è½¬å½•æ¨¡å‹: {model_id}[/dim]")
        
        try:
            # å°è¯•æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜
            try:
                config_path, weight_path = _find_cached_model(model_id)
                console.print(f"âœ… [green]è½¬å½•æ¨¡å‹å·²ç¼“å­˜[/green]: [bold]{model_id}[/bold]")
                console.print(f"ğŸ“„ é…ç½®æ–‡ä»¶: [dim]{config_path}[/dim]")
                console.print(f"âš–ï¸  æƒé‡æ–‡ä»¶: [dim]{weight_path}[/dim]")
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                config_size = Path(config_path).stat().st_size / 1024
                weight_size = Path(weight_path).stat().st_size / (1024 * 1024)
                console.print(f"ğŸ“Š å¤§å°: é…ç½® {config_size:.1f} KB, æƒé‡ {weight_size:.1f} MB")
                
            except FileNotFoundError:
                console.print(f"[yellow]âš ï¸  è½¬å½•æ¨¡å‹æœªç¼“å­˜[/yellow]: [bold]{model_id}[/bold]")
                console.print("ğŸ’¡ ä½ å¯ä»¥ä½¿ç”¨ 'transcribe model download' å‘½ä»¤é¢„ä¸‹è½½æ¨¡å‹")
                
                # æ£€æŸ¥ç½‘ç»œè¿æ¥
                if _check_network_connectivity():
                    console.print("ğŸŒ ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œæ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½")
                else:
                    console.print("[red]ğŸŒ ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹[/red]")
                    
        except Exception as e:
            console.print(f"[red]âŒ è·å–è½¬å½•æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}[/red]")
    
    elif action == "download":
        """é¢„ä¸‹è½½æŒ‡å®šè½¬å½•æ¨¡å‹"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹IDï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = DEFAULT_TRANSCRIPTION_MODEL
            console.print(f"[dim]ä½¿ç”¨é»˜è®¤è½¬å½•æ¨¡å‹: {model_id}[/dim]")
        
        try:
            console.print(f"ğŸš€ å¼€å§‹é¢„ä¸‹è½½è½¬å½•æ¨¡å‹: [bold]{model_id}[/bold]")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ç¼“å­˜
            try:
                _find_cached_model(model_id)
                console.print(f"âœ… [green]è½¬å½•æ¨¡å‹å·²å­˜åœ¨äºæœ¬åœ°ç¼“å­˜[/green]")
                return
            except FileNotFoundError:
                pass
            
            # ä¸‹è½½æ¨¡å‹
            model = from_pretrained(model_id, show_progress=True)
            console.print(f"\nğŸ‰ [bold green]è½¬å½•æ¨¡å‹é¢„ä¸‹è½½å®Œæˆ![/bold green]")
            console.print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜ï¼Œåç»­ä½¿ç”¨æ—¶å°†ç›´æ¥åŠ è½½")
            
        except Exception as e:
            console.print(f"[red]âŒ è½¬å½•æ¨¡å‹ä¸‹è½½å¤±è´¥: {str(e)}[/red]")
    
    elif action == "clean":
        """æ¸…ç†è½¬å½•æ¨¡å‹ç¼“å­˜"""
        try:
            # è·å–ç¼“å­˜ç›®å½•
            cache_dir = os.environ.get("HF_HOME") or os.environ.get("HUGGINGFACE_HUB_CACHE") or Path.home() / ".cache" / "huggingface"
            cache_dir = Path(cache_dir) / "hub"
            
            if not cache_dir.exists():
                console.print("[yellow]ğŸ“‚ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†[/yellow]")
                return
            
            # è®¡ç®—ç¼“å­˜å¤§å°
            total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())
            size_mb = total_size / (1024 * 1024)
            
            # è¯¢é—®ç¡®è®¤
            if size_mb > 0:
                console.print(f"âš ï¸  [yellow]å³å°†æ¸…ç† {size_mb:.1f} MB çš„è½¬å½•æ¨¡å‹ç¼“å­˜[/yellow]")
                console.print(f"ğŸ“ ç¼“å­˜ä½ç½®: [dim]{cache_dir}[/dim]")
                
                confirm = typer.confirm("ç¡®å®šè¦æ¸…ç†æ‰€æœ‰è½¬å½•æ¨¡å‹ç¼“å­˜å—ï¼Ÿ")
                if not confirm:
                    console.print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return
                
                # æ¸…ç†ç¼“å­˜
                shutil.rmtree(cache_dir)
                console.print("âœ… [green]è½¬å½•æ¨¡å‹ç¼“å­˜æ¸…ç†å®Œæˆ[/green]")
            else:
                console.print("[yellow]ğŸ“‚ ç¼“å­˜ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†[/yellow]")
                
        except Exception as e:
            console.print(f"[red]âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}[/red]")
    
    else:
        console.print(f"[red]âŒ æœªçŸ¥æ“ä½œ: {action}[/red]")
        console.print("ğŸ’¡ æ”¯æŒçš„æ“ä½œ: list, info, download, clean, cache")
        console.print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        console.print("   transcribe model list                                    # åˆ—å‡ºå·²ç¼“å­˜è½¬å½•æ¨¡å‹")
        console.print("   transcribe model info                                    # æ˜¾ç¤ºé»˜è®¤è½¬å½•æ¨¡å‹ä¿¡æ¯")
        console.print("   transcribe model info mlx-community/parakeet-tdt-0.6b-v2  # æ˜¾ç¤ºæŒ‡å®šè½¬å½•æ¨¡å‹ä¿¡æ¯")
        console.print("   transcribe model download                                      # é¢„ä¸‹è½½é»˜è®¤è½¬å½•æ¨¡å‹")
        console.print("   transcribe model download mlx-community/parakeet-tdt-0.6b-v2  # é¢„ä¸‹è½½æŒ‡å®šè½¬å½•æ¨¡å‹")
        console.print("   transcribe model clean                                   # æ¸…ç†ç¼“å­˜")
        console.print("   transcribe model cache status                           # æŸ¥çœ‹ç¼“å­˜çŠ¶æ€")
        console.print("   transcribe model cache clear                            # æ¸…ç†å†…å­˜ç¼“å­˜")


@app.command("version") 
def version():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    from rich.console import Console
    from ..version_utils import display_version_info
    
    console = Console()
    display_version_info(console)


@app.command("cache")
def cache_cmd(
    ctx: typer.Context,
    action: str = typer.Argument(..., help="ç¼“å­˜æ“ä½œ: status(æŸ¥çœ‹çŠ¶æ€), clear(æ¸…ç†å†…å­˜ç¼“å­˜), optimize(æ¸…ç†å­˜å‚¨ä¼˜åŒ–ç¼“å­˜)")
):
    """æ¨¡å‹ç¼“å­˜ç®¡ç†å‘½ä»¤"""
    
    if action == "status":
        """æ˜¾ç¤ºç¼“å­˜çŠ¶æ€ä¿¡æ¯"""
        try:
            # è·å–å†…å­˜ç¼“å­˜ä¿¡æ¯
            cache_info = get_cache_info()
            
            # è·å–å­˜å‚¨ä¼˜åŒ–ç¼“å­˜ä¿¡æ¯
            storage_stats = _storage_optimizer.get_cache_stats()
            
            # åˆ›å»ºçŠ¶æ€è¡¨æ ¼
            table = Table(title="ğŸ§  æ¨¡å‹ç¼“å­˜çŠ¶æ€")
            table.add_column("ç¼“å­˜ç±»å‹", style="cyan")
            table.add_column("çŠ¶æ€", style="green")
            table.add_column("è¯¦ç»†ä¿¡æ¯", style="dim")
            
            # å†…å­˜ç¼“å­˜çŠ¶æ€
            if cache_info["status"] == "cached":
                table.add_row(
                    "å†…å­˜ç¼“å­˜",
                    "âœ… å·²ç¼“å­˜",
                    f"æ¨¡å‹: {cache_info['model_id']}, ç±»å‹: {cache_info['dtype']}, è®¿é—®: {cache_info['access_count']}æ¬¡"
                )
                if cache_info.get("batch_mode", False):
                    table.add_row("", "ğŸ”„ æ‰¹é‡æ¨¡å¼", f"å¼•ç”¨è®¡æ•°: {cache_info.get('batch_ref_count', 0)}")
            else:
                table.add_row("å†…å­˜ç¼“å­˜", "âŒ ç©ºé—²", "æ— æ¨¡å‹ç¼“å­˜")
            
            # å­˜å‚¨ä¼˜åŒ–ç¼“å­˜çŠ¶æ€
            if storage_stats["cached_models"] > 0:
                table.add_row(
                    "å­˜å‚¨ä¼˜åŒ–ç¼“å­˜",
                    "âœ… å¯ç”¨",
                    f"{storage_stats['cached_models']} ä¸ªæ¨¡å‹, {storage_stats['total_size_mb']:.1f} MB"
                )
            else:
                table.add_row("å­˜å‚¨ä¼˜åŒ–ç¼“å­˜", "âŒ ç©ºç™½", "æ— ä¼˜åŒ–ç¼“å­˜")
            
            console.print(table)
            
            # æ˜¾ç¤ºç¼“å­˜ä½ç½®ä¿¡æ¯
            if storage_stats.get("cache_dir"):
                console.print(f"\nğŸ“ å­˜å‚¨ä½ç½®: [dim]{storage_stats['cache_dir']}[/dim]")
                
        except Exception as e:
            console.print(f"[red]âŒ è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥: {str(e)}[/red]")
    
    elif action == "clear":
        """æ¸…ç†å†…å­˜ç¼“å­˜"""
        try:
            cache_info = get_cache_info()
            
            if cache_info["status"] == "cached":
                console.print(f"âš ï¸  [yellow]å³å°†æ¸…ç†å†…å­˜ä¸­çš„æ¨¡å‹ç¼“å­˜[/yellow]")
                console.print(f"æ¨¡å‹: [cyan]{cache_info['model_id']}[/cyan]")
                
                confirm = typer.confirm("ç¡®å®šè¦æ¸…ç†å†…å­˜ç¼“å­˜å—ï¼Ÿ")
                if not confirm:
                    console.print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return
                
                clear_model_cache()
                console.print("âœ… [green]å†…å­˜ç¼“å­˜å·²æ¸…ç†[/green]")
                console.print("ğŸ’¡ [dim]ä¸‹æ¬¡ä½¿ç”¨æ—¶å°†é‡æ–°ä»å­˜å‚¨ä¼˜åŒ–ç¼“å­˜æˆ–åŸå§‹æ–‡ä»¶åŠ è½½[/dim]")
            else:
                console.print("[yellow]ğŸ“‚ å†…å­˜ç¼“å­˜ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†[/yellow]")
                
        except Exception as e:
            console.print(f"[red]âŒ æ¸…ç†å†…å­˜ç¼“å­˜å¤±è´¥: {str(e)}[/red]")
    
    elif action == "optimize":
        """æ¸…ç†å­˜å‚¨ä¼˜åŒ–ç¼“å­˜"""
        try:
            storage_stats = _storage_optimizer.get_cache_stats()
            
            if storage_stats["cached_models"] > 0:
                console.print(f"âš ï¸  [yellow]å³å°†æ¸…ç†å­˜å‚¨ä¼˜åŒ–ç¼“å­˜[/yellow]")
                console.print(f"ç¼“å­˜æ¨¡å‹: {storage_stats['cached_models']} ä¸ª")
                console.print(f"å ç”¨ç©ºé—´: {storage_stats['total_size_mb']:.1f} MB")
                
                confirm = typer.confirm("ç¡®å®šè¦æ¸…ç†å­˜å‚¨ä¼˜åŒ–ç¼“å­˜å—ï¼Ÿ")
                if not confirm:
                    console.print("âŒ å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return
                
                _storage_optimizer.clear_all_optimized_cache()
                console.print("âœ… [green]å­˜å‚¨ä¼˜åŒ–ç¼“å­˜å·²æ¸…ç†[/green]")
                console.print("ğŸ’¡ [dim]ä¸‹æ¬¡ä½¿ç”¨æ—¶å°†ä»åŸå§‹æ–‡ä»¶é‡æ–°æ„å»ºä¼˜åŒ–ç¼“å­˜[/dim]")
            else:
                console.print("[yellow]ğŸ“‚ å­˜å‚¨ä¼˜åŒ–ç¼“å­˜ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†[/yellow]")
                
        except Exception as e:
            console.print(f"[red]âŒ æ¸…ç†å­˜å‚¨ä¼˜åŒ–ç¼“å­˜å¤±è´¥: {str(e)}[/red]")
    
    else:
        console.print(f"[red]âŒ æœªçŸ¥æ“ä½œ: {action}[/red]")
        console.print("ğŸ’¡ æ”¯æŒçš„æ“ä½œ: status, clear, optimize")
        console.print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        console.print("   transcribe cache status                           # æŸ¥çœ‹ç¼“å­˜çŠ¶æ€")
        console.print("   transcribe cache clear                            # æ¸…ç†å†…å­˜ç¼“å­˜")
        console.print("   transcribe cache optimize                         # æ¸…ç†å­˜å‚¨ä¼˜åŒ–ç¼“å­˜")


if __name__ == "__main__":
    app()
