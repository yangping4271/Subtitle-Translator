import datetime
import json
import os
import time
import glob
import re
from pathlib import Path
from typing import Any, Dict, List, Optional

import typer
from mlx.core import bfloat16, float32
from rich import print
from rich.console import Console

# æŠ‘åˆ¶ macOS MallocStackLogging è­¦å‘Šï¼ˆæ— å®³çš„ç³»ç»Ÿæ¶ˆæ¯ï¼‰
os.environ.setdefault('MallocStackLogging', '0')
from rich.progress import (
    BarColumn,
    Progress,
    SpinnerColumn,
    TextColumn,
    TimeElapsedColumn,
)
from rich.table import Table
from typing_extensions import Annotated

from ..logger import get_log_file_path, get_log_mode_info, setup_logger
from . import AlignedResult, AlignedSentence, AlignedToken, from_pretrained
from .model_cache import model_context

# åˆå§‹åŒ–æ§åˆ¶å°
console = Console()

# helpers
def format_timestamp(
    seconds: float, always_include_hours: bool = True, decimal_marker: str = ","
) -> str:
    assert seconds >= 0
    milliseconds = round(seconds * 1000.0)

    hours = milliseconds // 3_600_000
    milliseconds %= 3_600_000

    minutes = milliseconds // 60_000
    milliseconds %= 60_000

    seconds = milliseconds // 1_000
    milliseconds %= 1_000

    hours_marker = f"{hours:02d}:" if always_include_hours or hours > 0 else ""
    return (
        f"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}"
    )


def to_txt(result: AlignedResult) -> str:
    """Format transcription result as plain text."""
    return result.text.strip()


def to_srt(result: AlignedResult, timestamps: bool = False) -> str:
    """
    Format transcription result as an SRT file.
    """
    srt_content = []
    entry_index = 1
    if timestamps:
        words = result.words
        for word in words:
            if not word.text.strip():
                continue
            start_time = format_timestamp(word.start, decimal_marker=",")
            end_time = format_timestamp(word.end, decimal_marker=",")
            text = word.text.strip()

            srt_content.append(f"{entry_index}")
            srt_content.append(f"{start_time} --> {end_time}")
            srt_content.append(text)
            srt_content.append("")
            entry_index += 1
    else:
        for sentence in result.sentences:
            start_time = format_timestamp(sentence.start, decimal_marker=",")
            end_time = format_timestamp(sentence.end, decimal_marker=",")
            text = sentence.text.strip()

            srt_content.append(f"{entry_index}")
            srt_content.append(f"{start_time} --> {end_time}")
            srt_content.append(text)
            srt_content.append("")
            entry_index += 1

    return "\n".join(srt_content)


def to_vtt(result: AlignedResult, timestamps: bool = False) -> str:
    """
    Format transcription result as a VTT file.
    """
    vtt_content = ["WEBVTT", ""]
    if timestamps:
        words = result.words
        for word in words:
            if not word.text.strip():
                continue
            start_time = format_timestamp(word.start, decimal_marker=".")
            end_time = format_timestamp(word.end, decimal_marker=".")
            text = word.text.strip()

            vtt_content.append(f"{start_time} --> {end_time}")
            vtt_content.append(text)
            vtt_content.append("")
    else:
        for sentence in result.sentences:
            start_time = format_timestamp(sentence.start, decimal_marker=".")
            end_time = format_timestamp(sentence.end, decimal_marker=".")
            text_line = sentence.text.strip()

            vtt_content.append(f"{start_time} --> {end_time}")
            vtt_content.append(text_line)
            vtt_content.append("")

    return "\n".join(vtt_content)


def _aligned_token_to_dict(token: AlignedToken) -> Dict[str, Any]:
    return {
        "text": token.text,
        "start": round(token.start, 3),
        "end": round(token.end, 3),
        "duration": round(token.duration, 3),
    }


def _aligned_sentence_to_dict(sentence: AlignedSentence) -> Dict[str, Any]:
    return {
        "text": sentence.text,
        "start": round(sentence.start, 3),
        "end": round(sentence.end, 3),
        "duration": round(sentence.duration, 3),
        "tokens": [_aligned_token_to_dict(token) for token in sentence.tokens],
    }


def to_json(result: AlignedResult) -> str:
    output_dict = {
        "text": result.text,
        "sentences": [
            _aligned_sentence_to_dict(sentence) for sentence in result.sentences
        ],
    }
    return json.dumps(output_dict, indent=2, ensure_ascii=False)


app = typer.Typer(
    help="ä½¿ç”¨ Parakeet MLX æ¨¡å‹è¿›è¡ŒéŸ³é¢‘è½¬å½•çš„å‘½ä»¤è¡Œå·¥å…·"
)


def _transcribe_files(
    audios: List[Path],
    model: str,
    output_dir: Path,
    output_format: str,
    output_template: str,
    timestamps: bool,
    chunk_duration: float,
    overlap_duration: float,
    use_vad: bool,
    verbose: bool,
    fp32: bool
):
    """æ‰§è¡ŒéŸ³é¢‘è½¬å½•çš„æ ¸å¿ƒé€»è¾‘"""
    # è®¾ç½®æ—¥å¿—è®°å½•å™¨
    logger = setup_logger(__name__)

    # ä¸å†åœ¨è¿™é‡Œç«‹å³åŠ è½½æ¨¡å‹ï¼Œè€Œæ˜¯å»¶è¿Ÿåˆ°å®é™…è½¬å½•æ—¶åŠ è½½
    if verbose:
        print(f"å‡†å¤‡ä½¿ç”¨æ¨¡å‹: [bold cyan]{model}[/bold cyan]")
        print("ğŸš€ [dim]æ¨¡å‹å°†åœ¨å¼€å§‹è½¬å½•æ—¶åŠ è½½ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†ä¼˜åŒ–[/dim]")

    try:
        output_dir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        print(f"[bold red]åˆ›å»ºè¾“å‡ºç›®å½• {output_dir} æ—¶å‡ºé”™:[/bold red] {e}")
        raise typer.Exit(code=1)

    if verbose:
        print(f"è¾“å‡ºç›®å½•: [bold cyan]{output_dir.resolve()}[/bold cyan]")
        print(f"è¾“å‡ºæ ¼å¼: [bold cyan]{output_format}[/bold cyan]")
        if output_format in ["srt", "vtt", "all"] and timestamps:
            print("æ—¶é—´æˆ³: [bold cyan]å·²å¯ç”¨[/bold cyan]")

    formatters = {
        "txt": to_txt,
        "srt": lambda r: to_srt(r, timestamps=timestamps),
        "vtt": lambda r: to_vtt(r, timestamps=timestamps),
        "json": to_json,
    }

    formats_to_generate = []
    if output_format == "all":
        formats_to_generate = list(formatters.keys())
    elif output_format in formatters:
        formats_to_generate = [output_format]
    else:
        print(
            f"[bold red]é”™è¯¯: æ— æ•ˆçš„è¾“å‡ºæ ¼å¼ '{output_format}'ã€‚è¯·ä» {list(formatters.keys()) + ['all']} ä¸­é€‰æ‹©ã€‚[/bold red]"
        )
        raise typer.Exit(code=1)

    total_files = len(audios)
    if verbose:
        print(f"æ­£åœ¨è½¬å½• {total_files} ä¸ªæ–‡ä»¶...")

    # ä½¿ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼çš„æ¨¡å‹ç¼“å­˜ç®¡ç†
    batch_mode = total_files > 1
    
    with model_context(batch_mode=batch_mode):
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeElapsedColumn(),
            transient=True,
        ) as progress:
            task = progress.add_task("æ­£åœ¨è½¬å½•...", total=total_files)
            loaded_model = None  # å»¶è¿Ÿåˆå§‹åŒ–
            
            for i, audio_path in enumerate(audios):
                if verbose:
                    print(
                        f"\næ­£åœ¨å¤„ç†æ–‡ä»¶ {i + 1}/{total_files}: [bold cyan]{audio_path.name}[/bold cyan]"
                    )
                else:
                    progress.update(
                        task, description=f"æ­£åœ¨å¤„ç† [cyan]{audio_path.name}[/cyan]..."
                    )

                try:
                    # æ‡’åŠ è½½æ¨¡å‹ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡éœ€è¦æ—¶åŠ è½½ï¼Œåç»­å¤ç”¨ç¼“å­˜ï¼‰
                    if loaded_model is None:
                        if verbose:
                            print(f"ğŸ¤– [bold blue]æ­£åœ¨åŠ è½½æ¨¡å‹...[/bold blue] [cyan]{model}[/cyan]")

                        loaded_model = from_pretrained(
                            model,
                            dtype=bfloat16 if not fp32 else float32,
                            use_cache=True
                        )

                        if verbose:
                            if batch_mode:
                                print("âœ… [green]æ¨¡å‹åŠ è½½å®Œæˆï¼Œæ‰¹é‡å¤„ç†æ¨¡å¼å·²å¯ç”¨[/green]")
                            else:
                                print("âœ… [green]æ¨¡å‹åŠ è½½å®Œæˆ[/green]")

                    # è®°å½•è½¬å½•å¼€å§‹æ—¶é—´
                    transcribe_start_time = time.time()

                    result: AlignedResult = loaded_model.transcribe(
                        audio_path,
                        dtype=bfloat16 if not fp32 else float32,
                        chunk_duration=chunk_duration if chunk_duration != 0 else None,
                        overlap_duration=overlap_duration,
                        use_vad=use_vad,
                        chunk_callback=lambda current, full: progress.update(
                            task, total=total_files * full, completed=full * i + current
                        ),
                    )

                    # è®¡ç®—è½¬å½•è€—æ—¶
                    transcribe_elapsed = time.time() - transcribe_start_time

                    if verbose:
                        for sentence in result.sentences:
                            start, end, text = sentence.start, sentence.end, sentence.text
                            line = f"[blue][{format_timestamp(start)} --> {format_timestamp(end)}][/blue] {text.strip()}"
                            print(line)

                    # ç»Ÿè®¡å­—å¹•æ•°é‡å¹¶æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
                    sentence_count = len(result.sentences)
                    logger.info(f"â±ï¸  è½¬å½•è€—æ—¶: {transcribe_elapsed:.1f}ç§’")
                    if not verbose:
                        print(f"âœ… [bold green]è½¬å½•å®Œæˆ[/bold green] (å…± [cyan]{sentence_count}[/cyan] æ¡å­—å¹•) - è€—æ—¶: [cyan]{transcribe_elapsed:.1f}ç§’[/cyan]")

                    base_filename = audio_path.stem
                    template_vars = {
                        "filename": base_filename,
                        "date": datetime.datetime.now().strftime("%Y%m%d"),
                        "index": str(i + 1),
                    }

                    output_basename = output_template.format(**template_vars)

                    for fmt in formats_to_generate:
                        formatter = formatters[fmt]
                        output_content = formatter(result)
                        
                        # å¯¹äºSRTæ ¼å¼ï¼Œæ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
                        if fmt == "srt":
                            srt_content_trimmed = output_content.strip()
                            if not srt_content_trimmed:
                                print(f"[yellow]âš ï¸  æœªæ£€æµ‹åˆ°è¯­éŸ³å†…å®¹ï¼Œè·³è¿‡ä¿å­˜ {fmt.upper()} æ–‡ä»¶[/yellow]")
                                continue
                            
                            # æ£€æŸ¥æ˜¯å¦åªåŒ…å«ç©ºçš„æ—¶é—´æˆ³æ¡ç›®ï¼ˆæ²¡æœ‰å®é™…æ–‡æœ¬å†…å®¹ï¼‰
                            import re
                            # ç§»é™¤åºå·å’Œæ—¶é—´æˆ³è¡Œï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰å®é™…å†…å®¹
                            lines = srt_content_trimmed.split('\n')
                            content_lines = []
                            for line in lines:
                                line = line.strip()
                                # è·³è¿‡åºå·è¡Œ
                                if line.isdigit():
                                    continue
                                # è·³è¿‡æ—¶é—´æˆ³è¡Œ
                                if re.match(r'\d{2}:\d{2}:\d{2}[,\.]\d{3}\s*-->\s*\d{2}:\d{2}:\d{2}[,\.]\d{3}', line):
                                    continue
                                # è·³è¿‡ç©ºè¡Œ
                                if not line:
                                    continue
                                content_lines.append(line)
                            
                            if not content_lines:
                                print(f"[yellow]âš ï¸  è½¬å½•ç»“æœä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜ {fmt.upper()} æ–‡ä»¶[/yellow]")
                                continue
                        
                        output_filename = f"{output_basename}.{fmt}"
                        output_filepath = output_dir / output_filename

                        try:
                            with open(output_filepath, "w", encoding="utf-8") as f:
                                f.write(output_content)
                            if verbose:
                                print(
                                    f"[green]å·²ä¿å­˜ {fmt.upper()}:[/green] {output_filepath.absolute()}"
                                )
                        except Exception as e:
                            print(
                                f"[bold red]å†™å…¥è¾“å‡ºæ–‡ä»¶ {output_filepath} æ—¶å‡ºé”™:[/bold red] {e}"
                            )

                except Exception as e:
                    # åŒºåˆ†æ¨¡å‹åŠ è½½é”™è¯¯å’Œè½¬å½•é”™è¯¯
                    if loaded_model is None:
                        print(f"[bold red]åŠ è½½æ¨¡å‹ {model} æ—¶å‡ºé”™:[/bold red] {e}")
                        # æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢æ•´ä¸ªæ‰¹æ¬¡
                        raise typer.Exit(code=1)
                    else:
                        print(f"[bold red]è½¬å½•æ–‡ä»¶ {audio_path} æ—¶å‡ºé”™:[/bold red] {e}")
                        # å•ä¸ªæ–‡ä»¶è½¬å½•å¤±è´¥ï¼Œç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶

                progress.update(task, total=total_files, completed=i + 1)

        # æ‰¹é‡å¤„ç†å®Œæˆåï¼Œæ¨¡å‹ç¼“å­˜å°†è‡ªåŠ¨é‡Šæ”¾
        if verbose and batch_mode:
            print("ğŸ¯ [dim]æ‰¹é‡å¤„ç†å®Œæˆï¼Œæ¨¡å‹ç¼“å­˜å·²è‡ªåŠ¨é‡Šæ”¾[/dim]")

    print(
        f"\n[bold green]è½¬å½•å®Œæˆã€‚[/bold green] è¾“å‡ºå·²ä¿å­˜åœ¨ '{output_dir.resolve()}'"
    )


@app.callback(invoke_without_command=True)
def main_callback(
    ctx: typer.Context,
    audios: Annotated[
        Optional[List[str]],
        typer.Argument(help="è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶")
    ] = None,
    input_files: Annotated[
        Optional[str],
        typer.Option(
            "--input-files", "-i",
            help="è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆç”¨é€—å·åˆ†éš”å¤šä¸ªæ–‡ä»¶ï¼‰ï¼Œå¦‚ä¸æŒ‡å®šåˆ™ä½¿ç”¨ä½ç½®å‚æ•°"
        )
    ] = None,
    model: Annotated[
        Optional[str], typer.Option(help="è½¬å½•æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ TRANSCRIPTION_MODEL_PATH æˆ– HF ç¼“å­˜ï¼‰")
    ] = None,
    output_dir: Annotated[
        Path, typer.Option(help="ä¿å­˜è½¬å½•ç»“æœçš„ç›®å½•")
    ] = Path("."),
    output_format: Annotated[
        str, typer.Option(help="è¾“å‡ºæ–‡ä»¶æ ¼å¼ (txt, srt, vtt, json, all)")
    ] = "srt",
    output_template: Annotated[
        str,
        typer.Option(
            help="è¾“å‡ºæ–‡ä»¶åæ¨¡æ¿ï¼Œä¾‹å¦‚ '{filename}_{date}_{index}'"
        ),
    ] = "{filename}",
    timestamps: Annotated[
        bool,
        typer.Option(help="åœ¨ srt/vtt æ ¼å¼ä¸­è¾“å‡ºè¯çº§æ—¶é—´æˆ³"),
    ] = True,
    chunk_duration: Annotated[
        float,
        typer.Option(
            help="é•¿éŸ³é¢‘çš„åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ0 ç¦ç”¨åˆ†å—ï¼Œ-1 æ™ºèƒ½åˆ†å—ï¼ˆæ¨èï¼‰ã€‚æ³¨æ„ï¼šå½“è®¾ä¸ºæ­£æ•°æ—¶ï¼Œå°†ä½¿ç”¨å›ºå®šåˆ†å—è€Œé VAD æ™ºèƒ½åˆ†å—ã€‚"
        ),
    ] = -1,  # æ™ºèƒ½åˆ†å—ï¼šæ ¹æ®ç³»ç»Ÿæ€§èƒ½è‡ªåŠ¨ä¼˜åŒ–
    overlap_duration: Annotated[
        float, typer.Option(help="ä½¿ç”¨åˆ†å—æ—¶çš„é‡å æ—¶é•¿ï¼ˆç§’ï¼‰")
    ] = 30,  # ä¼˜åŒ–ï¼šå¢åŠ åˆ°30ç§’é‡å ï¼Œæé«˜åˆå¹¶æˆåŠŸç‡
    use_vad: Annotated[
        bool,
        typer.Option(
            "--vad/--no-vad",
            help="ä½¿ç”¨ VAD æ™ºèƒ½åˆ†å—ï¼Œåœ¨é™éŸ³å¤„åˆ†å‰²éŸ³é¢‘ï¼ˆæ¨èï¼‰ã€‚ä»…åœ¨ chunk_duration ä¸ºè´Ÿæ•°æ—¶å¯ç”¨ã€‚"
        ),
    ] = True,
    verbose: Annotated[
        bool,
        typer.Option("--verbose", "-v", help="æ‰“å°è¯¦ç»†çš„å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯"),
    ] = False,
    fp32: Annotated[
        bool, typer.Option("--fp32/--bf16", help="ä½¿ç”¨ FP32 ç²¾åº¦")
    ] = False,
    version: Annotated[
        bool, typer.Option("--version", help="æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯å¹¶é€€å‡º")
    ] = False,
):
    """ä½¿ç”¨ Parakeet MLX æ¨¡å‹è½¬å½•éŸ³é¢‘æ–‡ä»¶ã€‚"""
    # å¤„ç†ç‰ˆæœ¬ä¿¡æ¯è¯·æ±‚
    if version:
        from ..version_utils import get_simple_version_info
        print(get_simple_version_info())
        raise typer.Exit()

    # å¦‚æœè°ƒç”¨äº†å­å‘½ä»¤ï¼Œå°±ä¸æ‰§è¡Œä¸»é€»è¾‘
    if ctx.invoked_subcommand is not None:
        return

    # è·å–è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    audio_files = []

    # å¤„ç†ä½ç½®å‚æ•°
    if audios:
        for file_path_str in audios:
            file_path = Path(file_path_str)
            if not file_path.exists():
                print(f"[bold red]é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}[/bold red]")
                raise typer.Exit(code=1)
            audio_files.append(file_path)

    # å¤„ç† -i å‚æ•°æŒ‡å®šçš„æ–‡ä»¶
    if input_files:
        for file_path_str in input_files.split(","):
            file_path = Path(file_path_str.strip())
            if not file_path.exists():
                print(f"[bold red]é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}[/bold red]")
                raise typer.Exit(code=1)
            audio_files.append(file_path)

    # å¦‚æœæ²¡æœ‰æä¾›éŸ³é¢‘æ–‡ä»¶ï¼Œå°è¯•æ‰«æå½“å‰ç›®å½•
    if not audio_files:
        print("[dim]æœªæŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼Œæ‰«æå½“å‰ç›®å½•...[/dim]")
        try:
            audio_files = _scan_media_files(Path.cwd())
        except typer.Exit as e:
            # å¦‚æœæ‰«æä¹Ÿæ²¡æ‰¾åˆ°æ–‡ä»¶ï¼Œä¼šæŠ›å‡ºExitå¼‚å¸¸
            raise e

    # å¦‚æœä»ç„¶æ²¡æœ‰éŸ³é¢‘æ–‡ä»¶ï¼ˆç†è®ºä¸Š_scan_media_filesä¼šå¤„ç†è¿™ç§æƒ…å†µï¼Œä½†ä¸ºäº†ä¿é™©èµ·è§ï¼‰
    if not audio_files:
        print("[bold red]é”™è¯¯: è¯·æä¾›è¦è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶[/bold red]")
        print("\nğŸ’¡ [bold blue]ä½¿ç”¨ç¤ºä¾‹:[/bold blue]")
        print("   transcribe audio.mp3 audio2.wav                    # ç›´æ¥è½¬å½•å¤šä¸ªæ–‡ä»¶")
        print("   transcribe -i audio.mp3,audio2.wav                 # ä½¿ç”¨ -i å‚æ•°")
        print("   transcribe *.mp3 --output-format all              # è½¬å½•æ‰€æœ‰mp3æ–‡ä»¶")
        raise typer.Exit(code=1)
    
    # è°ƒç”¨è½¬å½•åŠŸèƒ½
    _transcribe_files(
        audios=audio_files,
        model=model,
        output_dir=output_dir,
        output_format=output_format,
        output_template=output_template,
        timestamps=timestamps,
        chunk_duration=chunk_duration,
        overlap_duration=overlap_duration,
        use_vad=use_vad,
        verbose=verbose,
        fp32=fp32
    )

def _scan_media_files(input_dir: Path) -> List[Path]:
    """æ‰«æç›®å½•ä¸‹çš„åª’ä½“æ–‡ä»¶ï¼Œæ’é™¤å·²æœ‰å­—å¹•çš„æ–‡ä»¶"""
    # åª’ä½“æ–‡ä»¶æ‰©å±•å
    MEDIA_EXTENSIONS = [
        # éŸ³é¢‘æ ¼å¼
        "*.mp3", "*.m4a", "*.wav", "*.flac", "*.aac",
        "*.ogg", "*.wma", "*.aiff", "*.opus",
        # è§†é¢‘æ ¼å¼
        "*.mp4", "*.avi", "*.mov", "*.mkv", "*.webm",
        "*.flv", "*.wmv", "*.m4v", "*.mpeg", "*.mpg",
        "*.3gp", "*.ts"
    ]

    # ç¡®ä¿input_diræ˜¯ç»å¯¹è·¯å¾„
    input_dir = input_dir.resolve()

    # æŸ¥æ‰¾æ‰€æœ‰åª’ä½“æ–‡ä»¶
    media_files = []
    for pattern in MEDIA_EXTENSIONS:
        media_files.extend(glob.glob(str(input_dir / pattern)))
    
    if not media_files:
        print(f"[bold red]{input_dir} ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„åª’ä½“æ–‡ä»¶ã€‚[/bold red]")
        raise typer.Exit(code=1)
    
    # è¿‡æ»¤æ‰å·²æœ‰å­—å¹•çš„æ–‡ä»¶
    files_to_process = []
    
    # æå–åŸºç¡€æ–‡ä»¶åå¹¶å»é‡æ’åº
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¿ç•™åŸå§‹æ–‡ä»¶è·¯å¾„ï¼Œæ‰€ä»¥ä¸èƒ½åƒtranslateé‚£æ ·åªå­˜basename
    # æˆ‘ä»¬ç”¨basenameæ¥æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„subtitleæ–‡ä»¶
    
    # æ’åºæ–‡ä»¶åˆ—è¡¨
    media_files.sort()
    
    for file_path in media_files:
        file = Path(file_path)
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯¹åº”çš„å­—å¹•æ–‡ä»¶ (.srt æˆ– .ass)
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªæ£€æŸ¥åŒåä¸åŒåç¼€çš„æƒ…å†µ
        # translateå‘½ä»¤ä¸­çš„é€»è¾‘æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œå…ˆåšæœ€åŸºç¡€çš„æ£€æŸ¥
        has_subtitle = False
        for sub_ext in ['.srt', '.ass', '.vtt']:
            if (file.parent / (file.stem + sub_ext)).exists():
                has_subtitle = True
                break
        
        if not has_subtitle:
            files_to_process.append(file)
    
    if not files_to_process:
        print("[bold yellow]ç›®å½•ä¸‹æ‰€æœ‰åª’ä½“æ–‡ä»¶å‡å·²æœ‰å­—å¹•ï¼Œæ²¡æœ‰éœ€è¦å¤„ç†çš„æ–°æ–‡ä»¶ã€‚[/bold yellow]")
        raise typer.Exit(code=0)
        
    print(f"[bold green]å‘ç° {len(files_to_process)} ä¸ªå¾…è½¬å½•æ–‡ä»¶ï¼š[/bold green]")
    for f in files_to_process[:5]:
        print(f"  - {f.name}")
    if len(files_to_process) > 5:
        print(f"  ... ç­‰å…± {len(files_to_process)} ä¸ªæ–‡ä»¶")
    print()
        
    return files_to_process


@app.command("version")
def version():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    from rich.console import Console
    from ..version_utils import display_version_info

    console = Console()
    display_version_info(console)


if __name__ == "__main__":
    app()
