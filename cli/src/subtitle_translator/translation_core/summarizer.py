from typing import Dict, Optional
from pathlib import Path
from openai import OpenAI
from .prompts import SUMMARIZER_PROMPT
from .config import SubtitleConfig
from .utils.json_repair import parse_llm_response
from ..logger import setup_logger

logger = setup_logger("subtitle_summarizer")


class SubtitleSummarizer:
    def __init__(
        self,
        config: Optional[SubtitleConfig] = None
    ):
        self.config = config or SubtitleConfig()
        self.client = OpenAI(
            base_url=self.config.openai_base_url,
            api_key=self.config.openai_api_key
        )

    def summarize(self, subtitle_content: str, input_file: str) -> Dict:
        """
        æ€»ç»“å­—å¹•å†…å®¹
        Args:
            subtitle_content: å­—å¹•å†…å®¹
            input_file: è¾“å…¥çš„å­—å¹•æ–‡ä»¶è·¯å¾„
        Returns:
            Dict: åŒ…å«æ€»ç»“ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # ä½¿ç”¨ pathlib å¤„ç†æ–‡ä»¶å
            path = Path(input_file)
            # è·å–ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
            readable_filename = path.stem.replace('_', ' ').replace('-', ' ')

            logger.info(f"ğŸ“‹ å¯è¯»æ€§æ–‡ä»¶å: {readable_filename}")            
            # æ›´æ–°æç¤ºè¯ï¼Œå¼ºè°ƒæ–‡ä»¶åçš„æƒå¨æ€§
            message = [
                {"role": "system", "content": (
                    "You are a precise subtitle summarizer. "
                    "When processing proper nouns and product names:"
                    "1. Use the filename as reference for product names"
                    "2. Only correct terms that appear to be ASR errors based on:"
                    "   - Similar pronunciation"
                    "   - Context indicating they refer to the same thing"
                    "3. Do not modify other technical terms or module names that are clearly different"
                    f"{SUMMARIZER_PROMPT}"
                )},
                {"role": "user", "content": f"Filename: {readable_filename}\n\nContent:\n{subtitle_content}"}
            ]
            
            response = self.client.chat.completions.create(
                model=self.config.summary_model,
                messages=message,
                temperature=0.7,
                timeout=80
            )
            
            # æ·»åŠ ç±»å‹æ£€æŸ¥å’Œé”™è¯¯å¤„ç†
            if isinstance(response, str):
                # å¦‚æœresponseæ˜¯å­—ç¬¦ä¸²ï¼Œè¯´æ˜APIè°ƒç”¨å‡ºé”™
                logger.error(f"âŒ APIè°ƒç”¨è¿”å›é”™è¯¯: {response}")
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response}")
            
            # æ£€æŸ¥responseæ˜¯å¦æœ‰choiceså±æ€§
            if not hasattr(response, 'choices') or not response.choices:
                logger.error("âŒ APIå“åº”æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘choiceså±æ€§")
                raise Exception("APIå“åº”æ ¼å¼å¼‚å¸¸")
            
            summary = response.choices[0].message.content
            return {
                "summary": summary
            }
            
        except Exception as e:
            from .spliter import SummaryError
            from .split_by_llm import _extract_error_message, _get_error_suggestions
            
            error_msg = _extract_error_message(str(e))
            logger.error(f"âŒ å†…å®¹åˆ†æå¤±è´¥: {error_msg}")
            
            # æ ¹æ®é”™è¯¯ç±»å‹ç»™å‡ºé’ˆå¯¹æ€§å»ºè®®
            suggestions = _get_error_suggestions(str(e), self.config.summary_model)
            
            raise SummaryError(error_msg, suggestions)
